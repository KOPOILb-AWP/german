МИНОБРНАУКИ РОССИИ
Федеральное государственное бюджетное образовательное учреждение
высшего образования
«САРАТОВСКИЙ НАЦИОНАЛЬНЫЙ ИССЛЕДОВАТЕЛЬСКИЙ
ГОСУДАРСТВЕННЫЙ УНИВЕРСИТЕТ ИМЕНИ Н.Г. ЧЕРНЫШЕВСКОГО»

Кафедра

Математического и компьютерного моделирования

ОТЧЕТ ПО УЧЕБНОЙ (ОЗНАКОМИТЕЛЬНОЙ) ПРАКТИКЕ
студента
направления

1

курса

147

группы

09.04.03 Прикладная информатика
механико-математического факультета
Норкина Павла Владимировича


ВВЕДЕНИЕ
Сети передачи данных сегодня служат основой для развертывания современных форм связи. В зависимости от своего назначения и сложности, более
простой или более сложной реализации, сети становятся более сложными и
могут гарантировать различный уровень качества обслуживания, предлагать
большую степень избыточности или устойчивости к ошибкам. В этом случае
надежность самой сети является решающим фактором для предоставления
сервисов конечным пользователям. В этой работе описывается, проектируется и внедряется оптимизация для лабораторной сети с акцентом на изучение
сетевых технологий.
Первая часть работы посвящена анализу и оценке возможностей реализации сети передачи данных в лабораторной среде организации. Последующий анализ сети начинается с описания текущего состояния с точки зрения
пользователя и администратора такой сети. Затем описываются возможности реализации этой сети с использованием приемов разбиения виртуальной
сети, сегментации подсетей и их безопасности, а также реализации поддерживающих элементов, обеспечивающих не только функционирование самой
инфраструктуры, но и работу оборудования, необходимого для выполнения
лабораторных заданий.
Реализация новой инфраструктуры идет параллельно с существующей сетью, описанной в первой части. Происходит настройка этой «новой» сети в
соответствии с требованиями и возможностями, описанными в первой части.
В лаборатории работает большое количество устройств различных типов от
Cisco, HP, Mikrotik и других. Поэтому конфигурация каждого устройства использует стандартизированные протоколы, что обеспечивает переносимость
конфигурации и работу инфраструктуры на других устройствах того же типа.
Одновременно с реструктуризацией лабораторной сети развертываются
новые услуги серверной инфраструктуры. В то же время, развернутые в настоящее время сервисы переносятся на вновь установленное оборудование. Результатом работы является пересмотренная концепция сетевой инфраструктуры, включая ее часть, предназначенную для работы с устройствам. Эта
4

сетевая единица впоследствии будет введена в эксплуатацию и станет вдальнейшем основовной. Работа будет служить, помимо прочего, описанием практики, которая привела к вводу сети в эксплуатацию, и послужит ориентиром
для будущих сетевых администраторов в управлении и обслуживании этой
инфраструктуры.

5

1

Корпоративные сети передачи данных

Корпоративная сеть - это среда для реализации базовых сетевых служб
передачи данных и других расширенных сервисов, характерных для корпоративной среды. Такая сеть, независимо от ее размера и сложности, должна
гарантировать определенный уровень надежности, безопасности, доступности услуг и, наконец, возможности для ее эффективного управления. С ростом числа сервисов растут и требования к ее проектированию и управлению.
Требование взаимной интеграции сервисов и их объединения через единый
элемент управления доступом также характерно для среды предприятия.
В большинстве случаев корпоративная сеть управляется одной организацией. Если необходимо реализовать сеть передачи данных между географически разделенными местами (например, главный офис и удаленный филиал),
то для обеспечения взаимосвязи и безопасной передачи данных между этими
сетями принято использовать, например, IP-туннели. Они могут соединять
эти удаленные сети в одну большую, кажущуюся «локальной» сеть. Однако для целей данной работы ограничимся одной географически разделенной
сетью, которая реализована в одном месте.
Структура любой локальной сети может быть разделена на уровни в соответствии со свойствами, которые реализует соответствующий уровень и его
сетевые элементы. В такой структурированной модели представлены уровень
основной сети, уровень распределения и уровень доступа. Хотя это общепринятая практика, реализация каждого свойства для каждого уровня не является строгой. В небольших сетях, таких как наша, роль уровня распределения
может быть разделена между уровнем доступа и уровнем основной сети, а
сама сеть может не содержать специального оборудования для реализации
этого уровня. Такая топология называется свернутой иерархией. Многоуровневый подход также выгоден с точки зрения модульности всей архитектуры и
возможности разделения сетевого оборудования в зависимости от требуемых
функций (например, PoE на коммутаторе, являющемся ядром сети, не дает
никаких преимуществ и неоправданно увеличивает цену элемента).
Уровень доступа обеспечивает пограничные функции между сетью и конечными устройствами, такими как компьютеры, телефоны, камеры и т.д.
Устройства, предназначенные для этого уровня, обычно предлагают боль6

шее количество сетевых интерфейсов для подключения конечных устройств
и включают, например, функции безопасности для взаимодействующих узлов
(проверка ARP, DHCP snooping, функции IEEE 802.1X), функции безопасности для сетевой инфраструктуры (STP, фильтрация кадров BPDU) или PoE
для облегчения развертывания конечных узлов (телефонов, камер и т.д.).
Уровень распределения является точкой агрегации сетевой связи между
маршрутизаторами доступа и ядром сети, где обычно располагаются ключевые службы, обеспечивающие работу сетевой инфраструктуры. Резервирование и агрегирование каналов связи и соответствующая защита от сбоев
отдельных каналов также является общей функцией. Также может присутствовать маршрутизация между виртуальными сетями, которая может обеспечить разделение трафика между логическими топологиями, реализованными на втором уровне RM ISO/OSI. Преимуществом реализации уровня
распределения с использованием дополнительного оборудования в сетевой
топологии является, прежде всего, высокая доступность сетевых служб и
модульность конструкции.
Уровень ядра сети состоит из мощных коммутаторов и маршрутизаторов,
которые обеспечивают связь с внешними сетями и доступ в Интернет. Ядро
сети является точкой агрегации для большей части сетевых коммуникаций,
поэтому существует требование не только к максимальной доступности, избыточности, но и к высокоскоростным сетевым элементам. Таким образом,
большинство каналов резервируется и подкрепляется другими сетевыми элементами, физические каналы распределяются между большим количеством
активных элементов, а каналы группируются в логические каналы со скоростью порядка десятков гигабит в секунду.
1.1

Разделение сетей передачи данных

В сетях передачи данных любого масштаба обычно сталкиваются с активными элементами, которые обеспечивают взаимосвязь взаимодействующих
узлов как на физическом, так и на логическом уровне. К элементам, обеспечивающим физическое соединение, относятся в основном коммутаторы и точки
доступа для беспроводных сетей. Эти элементы работают в большинстве сво7

ем с адресами канального уровня и поэтому коммутируют только единицы
данных. Взаимосвязь логических сетей обеспечивается маршрутизаторами,
интерфейсы которых в основном принадлежат этим взаимосвязанным сетям,
между которыми пакеты направляются на сетевом уровне, в настоящее время
в большей степени исключительно на уровне IP пакета протоколов TCP/IP.
Очень часто используемым методом разделения сетей передачи данных
по их назначению является их взаимная изоляция на канальном уровне. Это
приводит к значительному сокращению всенаправленной широковещательной области, а также к желаемой необходимости внедрения маршрутизации
на уровне сетевого уровня. Возможности взаимной маршрутизации между сетями избирательно ограничиваются методами фильтрации сетевого трафика.
В следующих двух главах описываются принципы разделения физической топологии с помощью маркировки кадров и реализации отдельных подсетей в
возникающих виртуальных сетях. Эти методы необходимы для разделения
различных типов устройств (серверов, рабочих станций, VoIP-устройства) и
для последующей реализации механизмов QoS.
1.1.1

Разделение физической топологии с помощью VLAN

Коммутаторы устраняют недостатки хабов путем развертывания процессов или схем, которые обеспечивают коммутацию на основе информации, содержащейся в заголовке коммутируемых кадров. Заголовок каждого кадра
содержит, помимо прочего, адрес отправителя и адрес получателя, обеспечивая тем самым возможность адресации коммутируемых устройств между
двумя связывающимися узлами. Коммутация кадров от одного отправителя
к нескольким получателям также очень распространена в локальных сетях.
Сегодня в локальных сетях, реализующих многоточечные каналы связи,
часто сталкиваемся с блоками (кадрами) типа Ethernet II. В соответствии с
рисунком 1.1 , представлена структура этого кадра.

8

Рисунок 1.1 — Структура кадра Ethernet II
Структура этого кадра, показывает, среди прочего, поле, определяющее
длину или тип передаваемого протокола ( поле «управление»). Поле, определяющее тип передаваемого протокола, может содержать заголовок протокола
802.1Q, который в основном используется для указания принадлежности кадра к VLAN. Из заголовка 802.1Q коммутатор может определить, в том числе, определения параметров QoS канального уровня. Если кадр не содержит
этого значения, коммутатор может добавить его на основе заранее определенных правил, перемаркировать кадр или вообще удалить метку. В простейшем
случае установка принадлежности устройств к VLAN задается на определенном порту коммутатора. Если интерфейс используется для доступа только к
одной VLAN, его называют портом доступа (Access port), и наоборот, если
через этот интерфейс можно передавать кадры, принадлежащие нескольким
VLAN, то такой интерфейс называется магистральным портом (Trunk port).
В случае использования идентификатора VLAN в кадрах говорят о тегированных кадрах (Tagged Frame). Тегированные кадры обычно не встречаются на интерфейсе конечной станции, так как идентификаторы чаще используются на интерфейсах, соединяющих элементы сети. Большинство драйверов
сетевых карт поддерживают добавление идентификатора VLAN непосредственно в процессор сетевой карты, однако коммутаторы, на входе которых
настроен порт доступа, ожидают нетегированные кадры и аналогичным образом удаляют идентификатор VLAN из тегированного кадра перед отправкой
его на конечную станцию. На некоторых типах коммутаторов можно влиять
на реакцию коммутатора на «неожиданный» тегированный кадр на его входе - коммутатор может принять тегированный кадр, повторно тегировать его
или отбросить.

9

Поле заголовка протокола 802.1Q далее делится на две записи - первые 16 бит относятся к идентификатору протокола тега TPID (Tag protocol
identifier), а младшие 16 бит - к информационным полям управляющей информации тега TCI (Tag control information). Значение TPID предварительно установлено на 0x8100. Поскольку в этом месте указывается тип кадра
(биты поля TPID соответствуют положению битов поля EtherType в нетегированных кадрах), это значение сигнализирует об использовании протокола
тегирования.
Оставшиеся 16 битов коммутатора указывают на три части информации о
том, как работать с кадром. Эти три бита служат так называемым идентификатором кодовой точки приоритета PCP (Priority code point) и используются
в основном для обеспечения качества обслуживания на канальном уровне.
Значение поля может принимать до 8 значений, определяющих приоритет
единицы данных, причем 0 означает самый низкий приоритет (best effort), а
7 - самый высокий приоритет, обычно управляющий сетевым трафиком. Четвертый бит устанавливает значение индикатора возможности сброса (Drop
Eligible Indicator - DEI), на основании которого коммутатор может принять
решение о сбросе кадра в случае нехватки коммутационной мощности в качестве меры предосторожности против перегрузки сети. Оставшиеся 12 битов
в TCI представляют собой идентификатор VLAN (VLAN identifier), который
определяет принадлежность кадра к данной виртуальной сети канального
уровня.
1.1.2

Сегментация на сетевом уровне

Логические адреса IP используются для адресации коммуникаций на
интернет-уровне TCP/IP. Поскольку устройства не являются членами одного и того же домена L2 после сегментации канального уровня, необходима
маршрутизация. Хотя коммутаторы L3, которые способны маршрутизировать кадры на основе данных, содержащихся в IP-пакете, сейчас устанавливаются в качестве стандарта для больших сетей, в небольших сетях необходимо использовать маршрутизаторы. Работа с блоками данных сетевого уровня
предоставляет несколько возможностей для выборочной фильтрации трафи10

ка, трансляции логических адресов или реализации механизмов обеспечения
качества обслуживания.
Для логически сегментированных сетей L2 рекомендуется реализовать
схему адресации с эффективным использованием адресного пространства.
Если трафик данных из внешних сетей будет направляться в эти подсети без
преобразования адресов, целесообразно сегментировать адресное пространство с учетом возможности обратного объединения (supernetting) подсетей в
одну большую сеть. Это позволит уменьшить количество записей в таблицах
маршрутизации внешних маршрутизаторов для обеспечения маршрутизации
во внутренние подсети и потенциально сэкономить вычислительные мощности маршрутизаторов.
1.2

Отдельные службы в локальной сети

В следующей главе описываются основные службы, которые развертываются в локальных сетях передачи данных. В частности, это службы DHCP и
DNS, которые предоставляют функции для связи с использованием интернетпротокола IP версии 4 и версии 6. Корпоративные сети также обычно развертывают функции и механизмы NAT для защиты абонентов как на граничных
элементах, так и на конечных точках.
1.2.1

Функции DHCP

DHCP основан на RFC 1531 и считается преемником BOOTP. Связь
DHCP основана на модели сервер-клиент, т.е. сервер отвечает на запросы
клиентов о передаче параметров конфигурации сети. Наиболее распространенными параметрами являются параметры IP-адреса запрашивающего узла,
маска сети, адрес шлюза по умолчанию этой сети и IP-адреса серверов разрешения имен DNS. Однако протокол DHCP предлагает и более продвинутые
возможности, в частности, передачу сетевой информации узлу и наоборот.
Эта информация передается через сообщения DHCP Options, которые представляют собой отдельные параметры, устанавливаемые с помощью прото11

кола DHCP. В соответствии с рисунком 1.2, представлены параметры DHCP
Options.

Рисунок 1.2 — Основные параметры DHCP Options
Помимо основных параметров для реализации сетевого взаимодействия,
существует также возможность отправки параметров загрузчика операционной системы клиентам из сетевого расположения. Эта функция необходима
для реализованной позже службы Windows Deployment Service, которая может использоваться для выполнения неуправляемой установки и настройки
образа операционной системы на рабочих станциях. Помимо описанных выше, многие другие функции сетевых устройств могут быть настроены с помощью протокола DHCP, например, WINS-адреса, IRC, SMTP и т.д. Некоторые
производители конкретных HW (VoIP/SIP-устройств) предоставляют список
используемых ими параметров DHCP для массовой передачи управляющей
информации (адреса TFTP для загрузки прошивки, адреса регистраторов
SIP).
Поскольку IP-адреса и другие параметры «одалживаются» только на заранее определенный период времени, во время связи необходимо обрабатывать состояние, когда срок действия одалживания подходит к концу. Поэтому
клиентская станция обычно работает с таймерами T1 и T2. Когда истекает
половина срока действия займа (время T1), клиент DHCP пытается возобновить заем, отправляя сообщение DHCP Request на исходный сервер DHCP,
который предоставил заем. Если клиент не добился успеха, после истечения
87,5% времени аренды (время T2) он снова отправляет запрос на продление
аренды. Это сообщение уже адресовано всенаправленно, и если какой-либо
сервер DHCP отклоняет запрос (клиент получает сообщение DHCP Nack),

12

клиент должен немедленно прекратить использование адреса и начать процесс конфигурирования сети заново.
При опросе некоторые сообщения адресуются всем получателям (широковещательные пакеты). Широковещательные сообщения необходимы, в частности, для определения местонахождения сервера DHCP в сети, что показывает, что если сервер DHCP и клиент находятся в разных доменах широковещательной рассылки, необходимо использовать другой элемент, который перехватывает сообщение на интерфейсе домена широковещательной рассылки
и перенаправляет его на адрес сервера DHCP.
На первом этапе клиент обнаруживает серверы DHCP, отправляя сообщение DHCP Discover на всенаправленный адрес. Все доступные DHCP-серверы
в данном домене L2 отвечают на запрос, но только если в их базе данных
есть свободный адрес, который можно предоставить клиенту. Хотя у клиента в данный момент нет назначенного логического адреса, это сообщение
адресуется всенаправленно. Клиент DHCP может получить несколько предложений, поэтому он выбирает наиболее подходящий сервер на основе предпочтений и отправляет сообщение DHCP Request на всенаправленный адрес.
Это сообщение снова перехватывается всеми серверами DHCP - единственный выбранный сервер, который идентифицируется с запросом, затем подтверждает заем сообщением DHCP Ack, для других серверов запрос DHCP
Request является признаком того, что клиент выбрал другой сервер. После
успешной настройки конфигурации на клиенте запускаются таймеры T1 и
T2.
Если сетевая подсистема клиента перезапускается (перезагрузка ОС, отключение и повторное подключение к сети), а договор аренды все еще действителен согласно таймеру клиента, клиент может использовать IP-адрес без
необходимости повторять процесс автоконфигурации. Такая ситуация обычно не возникает во время запланированного выхода из сети (остановка программного обеспечения ОС) - в этом случае клиент DHCP обычно отправляет сообщение DHCP Release, информируя клиентский серверу о том, что он
больше не желает использовать заем.

13

1.2.2

Функции DNS

DNS занимает важное место в современных локальных и публичных сетях. Ведение полной базы данных сетевых узлов в их естественном, т.е. числовом, виде сегодня практически невозможно. Однако связь в компьютерных сетях осуществляется исключительно посредством IP-адресов, то есть
32- или 128-битных числовых идентификаторов, и поэтому система DNS с
точки зрения пользователя служит скорее инструментом, помогающим узлам сети присвоить легко запоминающееся имя.
DNS - это прикладной протокол, который использует транспортные протоколы UDP 53 и TCP 53 на стороне сервера. Он использует модели связи
клиент-сервер и сервер-сервер. Транспортный протокол UDP используется
для «нормальной передачи» клиентских запросов, в основном из-за его быстрого времени отклика. Надежность передачи здесь обычно не требуется, возможная ошибка передачи DNS обычно компенсируется клиентом путем отправки нескольких запросов к нескольким DNS-серверам за очень короткое
время. Напротив, связь, ориентированная на соединение, с использованием
протокола TCP требуется при так называемой передаче зон, то есть передаче
и синхронизации информационной базы между самими DNS-серверами, где,
наоборот, надежность передачи желательнее скорости передачи.
Поскольку подробный анализ взаимодействия DNS-сервера с клиентами
выходит за рамки данной работы, ниже перечислены только наиболее распространенные типы используемых записей DNS. Эти записи бывают следующих
типов:
- A, или AAAA - запись сопоставляющая доменное имя с IPv4, или IPv6
адресом.
- CNAME - каноническое имя (псевдоним), ссылающееся на другую запись.
- MX - запись, указывающая на IP почтового сервера для домена.
- PTR - запись, сопоставляющая IP-адрес с доменным именем (обратный
поиск)
Точность и своевременность информации, предоставляемой DNSсервером, является одним из необходимых условий для функционирования
14

корпоративной сети, основанной на службах Active Directory. DNS-серверы
также могут быть настроены для обеспечения балансировки нагрузки на
нужную станцию или сервер. По запросу клиента для «перевода» имени в
IP-адрес оно может быть выбрано из нескольких узлов, доступных под одним
и тем же именем. В этой работе используются только номинальные названия
для идентификации станций.
1.3

Безопасность и надежность в локальной сети

В современных установках сетей передачи данных довольно часто можно увидеть множественные соединения двух сетевых объектов, то есть метод, при котором несколько физических соединений создают одно логическое.
Аналогичным образом, сегодня довольно распространено внедрение механизмов безопасности для защиты сети передачи данных и ее участников. Следующий раздел служит кратким описанием метода объединения физических
линий и описанием выбранных методов обеспечения безопасности логической
топологии сети. Поскольку описание других доступных механизмов выходит
за рамки данного текста, я привожу здесь лишь краткий список тех, конфигурация которых предпочтительна в диссертации. В основном это функции,
настроенные на коммутаторах доступа. Это функции защиты от атаки переполнения, защиты от фальсификации записей ARP-таблиц участников сети
и фильтрации сообщений неавторизованного DHCP-сервера в сети. Примеры
настройки и маркировки отдельных функций могут варьироваться в зависимости от производителя устройства, в данной работе приведены примеры
настройки для устройств Cisco, работающих под управлением операционной
системы Cisco IOS.
1.3.1

Агрегация соединений согласно IEEE 802.1AX

Агрегирование интерфейсов стало распространенной практикой для эффективного использования нескольких доступных каналов между двумя точками сети. Хотя эта техника чаще всего используется между сетевыми эле15

ментами, образующими сетевую инфраструктуру, сегодня принцип агрегации
нескольких сетевых интерфейсов также применяется на конечных устройствах сети передачи данных, обычно серверах, требующих более высокой
пропускной способности для доступа к сети передачи данных.
Для агрегации нескольких доступных интерфейсов в современные операционные системы интегрирована так называемая функция «NIC Teaming»,
которая часто может агрегировать соединения без прямой поддержки со стороны коммутатора. Однако в своей работе я использую исключительно «агрегацию с помощью коммутатора». агрегацию с помощью протокола LACP
(Link Aggregation Control Protocol).
Первоначально этот протокол был определен в рекомендации IEEE 802.3
ad, но сегодня он является частью пересмотренной рекомендации IEEE 802.1
AX. В отличие от фирменных протоколов отдельных производителей, таких
как Cisco PAgP или Juniper Aggregated Ethernet, этот стандарт IEEE реализуется независимо от производителя устройства, даже на активных элементах от производителей, предлагающих собственные решения по агрегации.
По этой причине его использование целесообразно в средах, где развернуто
несколько устройств от разных производителей.
Рассмотрим коммутаторы SW1 и SW2, пусть каждый из них сможет назначить два физических соединения со скоростью 1 Гбит/с для объединенного канала. Таким образом, максимальная теоретически достижимая пропускная способность в результирующем соединении составляет V = 2 Гбит/с,
поскольку
V =n∗υ
(1.1)
где n - количество физических портов в канале, а υ - скорость каждого отдельного порта. Число n связанных портов обычно составляет от 1 до 8, а
скорость каждого интерфейса должна быть одинаковой для всех участников логического канала. Этот метод также обеспечивает определенную степень устойчивости к сбоям канала, поскольку в случае отказа любого из интерфейсов, участвующих в логическом канале, агрегированный канал может
продолжать работать, даже если он состоит из одного физического канала.

16

LACP обычно настраивается в активном или пассивном режиме на сетевом устройстве. Когда вспомогательный интерфейс настроен как активный,
устройство повторно транслирует кадры LACPDU и активно запрашивает
контрагента для согласования логического канала. Противоположностью активного режима является пассивный режим – в этом режиме устройство принимает только управляющие кадры LACP, и согласование логического канала происходит только тогда, когда принимается вызов от устройства, передающего в активном режиме. В течение периода обнаружения, т.е. времени,
когда ни один логический канал не согласован на данном интерфейсе, кадры
LACP транслируются с периодом в 1 секунду, а затем так называемые кадры
«обслуживания» транслируются с периодом в 30 секунд для поддержания
логического канала.
1.3.2

Предотвращение атаки переполнения

Коммутаторы создают таблицы привязки MAC-адресов и членства в
VLAN для устройств, подключенных к портам коммутатора, в зависимости
от полученных кадров. Это позволяет адресовать кадры только назначенным станциям. Атака переполнения использует ограниченный объем памяти
коммутатора путем отправки большого количества кадров с поддельными
MAC-адресами источников, которые коммутатор последовательно записывает в свою таблицу коммутации [6]. Эти записи хранятся в течение ограниченного периода времени - обычно 300 секунд. По истечении этого периода
времени или при перезагрузке коммутатора эта информация удаляется. В тот
момент, когда память коммутатора исчерпана и, следовательно, больше нет
возможности хранить записи в таблице MAC-адресов, коммутатор переходит
в состояние полной пересылки, где его функция близка к функции хаба. Чтобы не прерывать связь, коммутатор посылает кадры даже на интерфейсы, где
нет целевого устройства. Таким образом, кадры, адресованные другому узлу
сети, пересылаются на станцию злоумышленника. Защита от этого типа атак
заключается в установке ограничения на количество активных MAC-адресов,
которые могут быть зарегистрированы на одном интерфейсе коммутатора,
или в прямом указании значений MAC-адресов, которые могут быть зареги17

стрированы на данном интерфейсе в таблице коммутатора. В соответствии с
рисунком 1.3, показан пример конфигурации доступа для интерфейса F a0/1
коммутатора SW1, которая не допускает более 2 MAC-адресов, связанных с
этим интерфейсом, и отключает интерфейс при нарушении этой политики:

Рисунок 1.3 — Политика ограничения MAC-адресов
Опционально можно указать исходные MAC-адреса, которые будут внесены в базу данных коммутации коммутатора, если они встречаются на данном интерфейсе. Оставшиеся или неуказанные адреса будут добавлены в базу
данных коммутации при условии, что не будет нарушен установленный выше предел активных MAC-адресов на интерфейсе. Эта функция подходит,
например, для соединения телефонного устройства и компьютера на одном
интерфейсе коммутатора, или может быть использована для предотвращения возможности соединения, например, небезопасной виртуальной станции
с мостовым сетевым интерфейсом.
1.3.3

Проверка достоверности блоков данных протокола ARP

Для того чтобы обеспечить связь между двумя клиентами в локальных
сетях Ethernet на основе их IP-адресов, необходимо развернуть механизмы
сопоставления физических адресов (MAC-адрес интерфейса) с логическими
адресами сетевого уровня (IP-адресами). Чтобы эту таблицу привязки не
приходилось настраивать вручную на каждой станции и сетевом элементе,
особенно в больших сетях передачи данных, она опирается на поддерживающие протоколы ARP ((Address Resolution Protocol)) или ICMPv6 (Neighbor
Discovery). ARP - это протокол без статических данных, определенный в RFC
826 и обеспечивающий «преобразование» IP-адреса станции в ее MAC-адрес.
Станция обычно регистрирует и обрабатывает ARP-ответы, даже если
она сама не посылала ARP-запрос. Это позволяет контролируемым обра18

зом внести нелегитимную (ложную) информацию в таблицу привязки адресов каналов и сетей на станции-жертве. Затем связь жертвы в данной сети
Ethernet переключается на интерфейс коммутатора, имеющего соответствующий MAC-адрес целевой станции.
Способом защиты от этого типа атак является функция сетевого элемента,
создающая таблицу привязки только реальных, т. е. легитимных IP-адресов и
легитимных MAC-адресов. Эта функция обеспечивается механизмом под названием Dynamic ARP Inspection, сокращенно DAI. Все кадры, содержащие
запрос или ответ ARP, перехватываются и анализируются блоком управления коммутатора. В частности, это проверка информации, содержащейся в
блоке данных протокола ARP. Эта проверка производится коммутатором по
собственной доверенной базе данных, которую он динамически наполняет
информацией (на основе работы механизма DHCP Snooping) или в которую
администратор данного сетевого элемента вводит статические данные. Метод
ввода статических данных особенно удобен, если в данной сети есть элементы
со статической конфигурацией протокола IP. Как правило, настройка DHCP
для этих станций не производится, и коммутатор не сможет захватить эту
связь между линией и сетевым адресом с помощью функций DHCP Snooping.
Если коммутатор оценивает информацию в блоках данных протокола
ARP как достоверную, он использует ее для обновления своей собственной
таблицы коммутации, а затем пересылает кадр на соответствующий выходной интерфейс. В противном случае кадр, содержащий блок протокола ARP,
уничтожается. В соответствии с рисунком 1.4, приведен пример конфигурации DAI на коммутаторе SW1 для проверки пакетов ARP, распространяемых
в VLAN с VID 10.

Рисунок 1.4 — Конфигурация DAI на коммутаторе SW1

19

Приведенная выше конфигурация устанавливает проверку достоверности
распространяемой информации ARP глобально для VLAN 10. Впоследствии
доверие устанавливается для интерфейса GigabitEthernet 0/1, поэтому проверка единиц данных протокола ARP на этом интерфейсе не производится.
1.3.4

Проверка валидности сервера DHCP

В корпоративных сетях централизованно управляется не только частное
адресное пространство. В то же время необходимо предотвратить подключение неавторизованного DHCP-сервера к компьютерной сети, чтобы избежать
раздачи недействительных или конфликтующих IP-адресов клиентам сети. С
этой целью вводятся функции, особенно на коммутаторах доступа, для ограничения распространения определенных типов сообщений DHCP. Функция,
контролирующая или ограничивающая распространение сообщений DHCP в
соответствии с интерфейсом источника, на современных сетевых элементах
называется DHCP snooping.
Администратор сетевого элемента указывает порты коммутатора, через
которые пакет DHCP Offer может распространяться в сети Ethernet (для конкретной сети VLAN это может быть указано по-другому). Опять же, в упрощенном виде, сообщение DHCP Offer от неавторизованного DHCP-сервера
отбрасывается на входном порту коммутатора и никогда не переключается
на выходной интерфейс к станции, которая сгенерировала сообщение DHCP
Discover. Настройка уровня доверия порта коммутатора показаны в соответствии с рисунком 1.5.

20

Рисунок 1.5 — Обозначения интерфейсов коммутатора для DHCP Snooping
Пусть интерфейсы F a0/1 коммутаторов SW1 и SW2 являются интерфейсами доступа для рабочих станций в сети. Эти интерфейсы настроены администратором коммутатора как недоверенные. И наоборот, интерфейсы, к которым подключен авторизованный DHCP-сервер, или интерфейсы, которые
подключаются к DHCP-серверу через промежуточный элемент, помечаются
как доверенные. Если поддельный DHCP-сервер на станции злоумышленника
перехватывает всенаправленное сообщение DHCP Discover и генерирует ответ
DHCP Offer, коммутатор SW2 выполняет настроенное действие на интерфейсе F a0/1, например, отсоединяет (выключает) интерфейс коммутатора.
Пример конфигурации коммутатора SW2, который активирует DHCP
snooping глобально, то есть на всех интерфейсах и виртуальной сети представлен в соответствии с рисунком 1.6 .

Рисунок 1.6 — Глобальная активация DHCP snooping
Затем, в соответствии с рисунком 1.7, необходимо указать доверенные
интерфейсы, например Gi0/2:

Рисунок 1.7 — Указание доверенного интерфейса
21

Правильная настройка механизма DHCP snooping на коммутаторах доступа является необходимым условием для эффективной защиты с помощью
механизмов Dynamic ARP Inspection. Эти функции обычно настраиваются
на интерфейсах доступа коммутатора, к портам которого подключаются конечные устройства клиентов.
1.3.5

Фильтрация единиц данных с помощью ACL

Очень часто в сетях передачи данных требуется контролировать трафик
между определенными IP-подсетями. В случае с лабораторной сетью, например, доступ к сети, в которой расположен административный интерфейс, со
станций на рабочих местах сотрудников крайне нежелателен. По этой причине современные сетевые элементы, например, коммутаторы и маршрутизаторы, позволяют создавать так называемые «списки контроля доступа»,
которые в простейшем случае определяют исходную сеть, целевую сеть (возможно, также протоколы транспортного уровня) и правила, в соответствии
с которым устройство обрабатывает данные. В случае нашей сети передачи данных это простейшие правила для разрешения или отказа в доступе, то
есть для определения того, будет ли пакет принят и направлен по интерфейсу
или будет уничтожен.
Обычно на устройствах Cisco IOS можно создавать ACL двух типов: стандартные и расширенные. Стандартный ACL учитывает только адрес станцииисточника и выполняет определенное действие. С другой стороны, так называемый расширенный ACL может использоваться для более «конкретной»
спецификации единиц данных, т.е., например, для предотвращения трафика
по определенным транспортным адресам и т.д. Списки контроля доступа применяются к определенному интерфейсу и в определенном направлении (вход
или выход), их правила проходят последовательно от первого к последнему,
а последнее правило каждого ACL - это правило уничтожения трафика, который не был разрешен или уничтожен на основании любого предыдущего
правила.

22

1.4

Серверные и сетевые службы Microsoft

Следующие главы посвящены описанию избранных технологий и серверных служб Microsoft, которые в настоящее время реализованы в лабораторной среде. Продукты этой компании выбирают в основном из-за их надежности, производительности и возможностей администрирования. Существуют
также альтернативы для отдельных продуктов, например, для виртуализации серверов предлагаются продукты из серии vSphere конкурирующей компании VMware. Службы каталогов также могут быть реализованы с использованием свободно доступных альтернатив, таких как сервер OpenLDAP.
1.4.1

Виртуализация серверов Hyper-V

Hyper-V — это роль операционной системы Windows Server в версии 2008
R2 и более поздних. Эта роль дает возможность управлять несколькими виртуальными системами на одном физическом сервере, который называется
хостом виртуализации. Аппаратное обеспечение хост-сервера обычно полностью предназначено для работы только роли виртуализации, и никакая другая роль не развертывается. Целью виртуализации серверов часто является
создание уровня, который предлагает определенную абстракцию оборудования, на котором работает виртуальная машина (сокращенно VM от англ.
Virtual Machine), и ее операционной системы, которая является посредником
в требуемой службе — например, контроллере домена, веб-сервере и т. д. Таким образом, физический сервер де-факто становится многоцелевым устройством, на котором могут работать серверные сетевые службы, веб-сайты или
службы файлового сервера. Хотя можно было бы запускать эти роли в одном
экземпляре операционной системы, разделение этих ролей является рекомендуемой практикой как с точки зрения производительности, так и с точки
зрения безопасности серверной инфраструктуры.
После установки роли Hyper-V на физическом сервере реализуется архитектура, которая показана в соответствии с рисунком 1.8.

23

Рисунок 1.8 — Многоуровневая архитектура хоста Hyper-V
На схеме архитектуры виртуализации показано развертывание уровня гипервизора непосредственно на физическом оборудовании и его соединение через шину виртуализации VMBus, которая опосредует доступ операционных
систем к аппаратному обеспечению хоста. Этот принцип аналогичен общей
многоуровневой архитектуре операционных систем. Операционная система,
выполняющая роль сервера Hyper-V, становится поставщиком всех необходимых операционных процессов и служб для запуска виртуальных машин
(поставщик объектов WMI, запуск процессов и служб) и становится так называемым родительским разделом. Затем отдельные виртуальные машины
устанавливаются в так называемые дочерние разделы. В зависимости от способности операционной системы работать в виртуализированном режиме, доступ и взаимодействие отдельных виртуальных машин через шину виртуализации VMBus различаются. Доступ к этой шине обычно обеспечивается интеграционными компонентами Hyper-V, который доступен для большинства
современных операционных систем.

24

Перед установкой сервера Hyper-V необходимо учитывать не только требования самой операционной системы, но и требования работающих в ней
виртуальных систем. Из модели уровня видно, что работающие в ней виртуальные машины также конкурируют за ресурсы физического сервера, и
для оптимальной работы необходимо обеспечить зарезервированный доступ
к физическим ресурсам. Этого можно добиться в Hyper-V за счет резервирования ядер ЦП, предоставления минимального и максимального объема
памяти, доступной для ВМ, и возможности распределять дисковые контейнеры по нескольким физическим дискам или дисковому массиву.
Помимо общих требований операционной системы (в нашем случае
Windows Server 2016), поддержки 64-битных процессорных инструкций, поддержки технологий виртуализации Intel VT или AMD-V и поддержки защиты
сегментов данных в машинном коде, т.е. Предотвращение выполнения, реализованное с использованием битовой технологии Intel XD, требуется бит AMD
NX или.
1.4.2

Доменные службы Active Directory

Доменные службы и службы каталогов, как правило, являются основой
инфраструктуры предприятий любого размера. В нашем случае речь идет о
реализации службы каталогов Microsoft, которая основана на стандарте X.500
и протоколе LDAP. Эта служба (Active Directory Domain Services, сокращенно
AD DS) выступает в качестве централизованного хранилища объектов, содержащихся в базе данных AD DS. Эта база данных содержит информацию о
пользователях, группах, компьютерах, топологии сети, а также записи DNS
и аренды DHCP. Однако основной целью является аутентификация личности
(пользователей и компьютеров), авторизация (контроль доступа к) ресурсам
и их извлечение.
Роль AD DS предоставляет основные службы домена и каталогов, но вы
можете установить множество других ролей в структуре Active Directory, которые используют структуры, реализованные ролью AD DS. К ним относятся
службы AD CA, службы федерации, службы разрешений и другие. В нашем
случае, однако, будут использоваться только «базовые» роли AD DS, осо25

бенно для хранения идентификационных данных, управления объектами и
совместного использования ресурсов.
Active Directory представляет несколько логических компонентов в сетевой инфраструктуре. Это домены, деревья, леса, OUs и местоположения.
Упрощенно эти компоненты можно охарактеризовать как области действия
определенных правил. Разработка доменной структуры требует значительного объема планирования, особенно когда речь идет об определении групповых
политик (массовая и централизованная настройка ОС Windows), назначении
членства в группах безопасности (авторизация), а также о более сложных
задачах, таких как установление так называемых доверительных отношений
с другими доменами.
Доменные службы Active Directory развертываются в существующей сети
передачи данных, включая интеграцию рабочих станций в доменную структуру. Любое вмешательство в конфигурацию рабочих станций выходит за
рамки данного текста и не рассматривается при проектировании сети передачи данных. Более подробное описание выходит за рамки данной работы, и
в следующих главах будут только описаны и обоснованы конкретные конфигурации.
1.4.3

Удаленное администрирование ОС Windows

И серверные, и компьютерные версии ОС Windows поставляются в стандартной комплектации с множеством инструментов и опций для эффективного и удаленного управления. Поскольку, начиная с версии 2012, рекомендуется использовать серверные версии без графических интерфейсов, необходимо развернуть методы удаленного администрирования операционной системы и ее ролей в ОС. Для этого можно использовать несколько инструментов
для подключения через «службу терминалов», или Remote Desktop. Однако на серверах, где не установлены графические инструменты, администратору обычно предлагается только командный интерпретатор или Windows
Powershell, что делает Remote Desktop относительно ненужным для этих
нужд.
26

По описанной выше причине ОС Windows снабжена набором инструментов, которые в совокупности образуют службу удаленного управления ОС
Windows (WinRM). В основе этих инструментов лежит так называемый протокол WS-Management. Этот текстовый протокол основан на реализации модели SOAP для передачи информации в формате данных XML. В отличие от
типа объекта, например, при использовании WMI. WS Management Protocol
также может использоваться в сторонних приложениях, т.е. не только в средствах администрирования, входящих в состав ОС Windows. Источником его
данных может быть уже упомянутый провайдер WMI, с помощью которого
можно получить доступ к ряду сведений о самом аппаратном обеспечении,
таких как версия BIOS, производственные и серийные номера и другая информация. Эти данные в основном собираются потенциальными клиентами
систем наблюдения.
Однако с точки зрения администратора операционной системы Windows
наиболее удобным методом удаленного администрирования является возможность удаленного подключения к сеансу командного интерпретатора
Windows Powershell. Это достигается путем включения функции «Powershell
Remoting», которая автоматически включается при включении компонента Windows Remote Management. Это позволяет администратору не только
обращаться к удаленным операционным системам в командах и сценариях
Windows Powershell, но и получать доступ к экземпляру самого командного
интерпретатора, запущенного на удаленной операционной системе.

27

2

Лабораторная сетевая среда

Следующая глава посвящена описанию текущей топологии и представленных в ней устройств. Также оцениваются преимущества и недостатки логической структуры сети и функционирующих в ней сервисов. Лабораторная сеть обеспечивает передачу блоков данных в отдельных сетях VLAN,
специфичных для каждого рабочего места. Затем эти VLAN передаются на
коммутатор, соединяющий физические экспериментальные устройства. Экспериментальные VLAN с VID в диапазоне 330–360 передаются только с использованием тегированных кадров. Таким образом, экспериментальные сети представляют собой совершенно отдельную часть лабораторной сети, и их
взаимосвязь обычно нежелательна. Эти сети могут содержать большое количество неправильно защищенных рабочих станций, неправильно настроенных
сетевых устройств, а их взаимосвязь может нарушить работу лабораторной
сети (например, неправильно настроенный STP).
Поскольку коммутатор в стойке экспериментального оборудования обеспечивает только коммутацию кадров между элементами лабораторных заданий, его конфигурация должна обеспечивать полностью прозрачную передачу без каких-либо помех для передаваемых данных. Поэтому не должно
быть никаких механизмов фильтрации, QoS и т.д. Выполнение экспериментальных заданий и возможность их выполнения - главное требование к вновь
проектируемой сети передачи данных.
2.1

Инфраструктура лабораторной сети

В настоящее время в сети передачи данных используется один маршрутизатор и четыре коммутатора. Для простоты будем использовать символическую маркировку элементов сети и подключенных физических и виртуальных станций.
Пусть R1 формирует граничный маршрутизатор лабораторной подсети,
выполняет трансляцию адресов сетевого уровня и выборочную трансляцию
адресов транспортного уровня. На маршрутизаторе определена только одна локальная сеть, которая распространяется на первый коммутатор SW1 с
использованием нетегированных кадров. На этом коммутаторе уже опреде28

лены определенные виртуальные сети (VLAN), которые выборочно назначаются отдельным интерфейсам. Однако отделение так называемых обучающих VLAN от экспериментальных, т.е. виртуальных сетей, между которыми
маршрутизация не происходит и зарезервированы для нужд лабораторных
задач, здесь реализовано не оптимально. На SW1 VLAN по умолчанию с
VID 1 практически не используется, а все устройства, которые подключаются к лабораторной сети (не конкретной экспериментальной), подключаются к интерфейсу, который служит точкой доступа для VLAN с VID 310.
Затем эти устройства члены одной IP-подсети, чей адресуемый интерфейс
шлюза по умолчанию находится на граничном маршрутизаторе R1 член сети
Ethernet по умолчанию с VLAN VID 1. По этой причине необходимо удалить
тег VLAN из заголовков кадров переключается на исходящий интерфейс на
R1, а в обратном направлении, то есть при передаче от R1 на SW1, все кадры
маркируются согласно 802.1Q и указывают поле VID со значением 310.
Другой коммутатор, SW2, напрямую подключен к SW1. Интерфейс, соединяющий второй коммутатор с SW1, настроен так же, как и связь между
R1 и SW1. Кадры, назначенные VLAN с VID 310 на SW1, снова лишаются
этой метки и отправляются на интерфейс, соединяющий SW2, где они больше
не включаются в какой-либо конкретный VLAN и остаются в родном VLAN.
Учитывая этот факт, можно сделать вывод, что одна IP-подсеть неэффективно распределена между отдельными виртуальными локальными сетями и определена на R1, SW1 и SW2 с несогласованными идентификаторами
VLAN. Когда станция, подключенная к коммутатору SW2, передает кадр,
который коммутируется на интерфейсе между SW2 и SW1, а затем на R1
(обычно, когда инкапсулированный пакет направляется за пределы подсети лаборатории), происходит тройная маркировка кадра IEEE 802.1Q. Относительно ненужная повторная маркировка кадра вызывает необходимость
вычисления новой контрольной суммы в поле FCS кадра, расходуя вычислительную мощность всех участвующих коммутаторов. IP-подсеть, управляемая таким образом, является единственной обучающей подсетью, а также
служит для доступа к интерфейсам конфигурации всех сетевых элементов,
KVM-устройств, встроенных интерфейсов управления серверами и других

29

устройств, использующих протокол IP. В соответствии с рисунком 2.1, показана полная символическая схема элементов лаборатории.

Рисунок 2.1 — Полная символическая схема элементов лаборатории
Здесь показано подключение нескольких виртуальных рабочих станций,
которые виртуализируются как на конечных рабочих станциях, так и на выделенном сервере виртуализации. Эти виртуальные машины включены почти
исключительно в экспериментальные виртуальные локальные сети. Для доступа к экспериментальным виртуальным сетям рабочие станции используют комбинацию тегированного и нетегированного трафика, принимаемого на
соответствующем интерфейсе коммутатора. Нетегированные кадры интегрируются в обучающую VLAN с VID 310 и VID 1, соответственно, а тегированные кадры интегрируются непосредственно в VLAN, для которой коммутатор
ожидает кадры на этом интерфейсе.
В случае виртуализации на выделенном сервере используется выделенная
сетевая карта, подключенная к интерфейсу, на котором коммутатор ожидает
тегированные кадры для виртуальных локальных сетей.

30

2.1.1

Доступность виртуальных сетей

Как упоминалось в предыдущем разделе, рабочие станции обеспечивают,
помимо прочего, доступ виртуальных машин к экспериментальным VLAN,
которые направляются на коммутатор SW4 через тегированные кадры на
магистральных интерфейсах. Рисунок 2.1 показывает циклическое соединение коммутаторов SW1 - SW4, что создает риск переполнения кадров. Однако
такая ситуация не возникает по следующим причинам:
- VLAN с VID 1 не распространяется между SW2 и SW4.
- на канале между SW1 и SW3 VLAN с VID 310 и другие экспериментальные VLAN распространяются с помощью тегированных кадров.
- VLAN 310 распространяется с помощью нетегированных кадров на интерфейсе доступа между SW3 и SW4, где ей назначается действительный IP-адрес.
- Только экспериментальные VLAN передаются между SW2 и SW4 с использованием тегированных кадров.
В то время как вышеизложенное может быть простым решением для
устранения петли в сети без использования сложных протоколов управления, коммутатор SW3 теряет свое значение в топологии, поскольку к нему
не подключены экспериментальные устройства и он не используется для распространения экспериментальных VLAN. Также необходимо учитывать возможный поток кадров в сети для отдельных сетей VLAN. Рассмотрим два
сценария, показанные в соответствии с рисунком 2.2.

Рисунок 2.2 — Распространение кадров по принадлежности к VLAN
31

Первый сценарий представляет собой распространение кадров по сети в
случае, когда станция PC1 посылает кадры на всенаправленный адрес. Из-за
особенностей реализации сети Ethernet часто может происходить ненужное
или нежелательное распространение этих кадров по сети. По мере увеличения
количества устройств в сети увеличивается процент нагрузки на сеть, который приходится на поток кадров, отправленных на всенаправленный адрес.
Кроме того, можно ожидать неоптимального использования вычислительных
ресурсов сетевых устройств, которые в соответствии с определенными правилами должны выполнять перемаркировку Поля 802.1Q для каждого кадра
обучающей VLAN, распространяемого за пределы коммутатора SW1.
Второй сценарий показывает связь виртуальной станции с одноранговым
узлом в экспериментальной сети VLAN. Этот сценарий показывает физическое соединение элементов, составляющих часть топологии, описанной в
лабораторном задании. На рисунке показано неоптимальное использование
соединений и самих коммутаторов, т.к. для связи между VM1 и VM2, что
демонстрируется с использованием маршрутизаторов LAB1 и LAB2 в составе задачи, возникает нагрузка на остальные три промежуточных элемента
физической топологии.
2.1.2

Свойства экспериментальных топологий

Виртуализированные рабочие станции и серверы широко используются в
лабораторных задачах и часто подключаются к физическим элементам, которые являются предметом лабораторных задач. Подключение лабораторного
экспериментального оборудования обеспечивается главным коммутатором в
стойке R3, который далее подключен к коммутатору, обеспечивающему подключение к физическим рабочим станциям и серверам.
В топологии, представленной в задаче, используются рабочие станции,
устройства IP-телефонии и серверы, которые подключены к физическим элементам сети. Описанная логическая топология проиллюстрирована с помощью упрощенной диаграммы с символической маркировкой, в соответствии
с рисунком 2.3.
32

Рисунок 2.3 — Логическая топология для лаборатории
Изображенная топология экспериментальной площадки соответствует
физической топологии с использованием виртуализированных станций в соответствии с рисунком 2.4 иллюстрирующем символическую схему.

Рисунок 2.4 — Фактическая схема подключения устройств
Для наглядности схемы сохранены символические обозначения элементов лаборатории и полные наименования используемых устройств, которые
формируют физическую топологию сети. Таким образом, очевидно, что когда виртуальные машины взаимодействуют с использованием физического
33

лабораторного оборудования, между элементами лаборатории и виртуальными машинами возникает избыточный трафик. Это явление возникает изза неправильно выбранной точки подключения сервера виртуализации, даже
когда VM2 и S1 или другие элементы общаются друг с другом, то есть элементы, которые, казалось бы, подключены к одному физическому коммутатору
в топологии лабораторной сети.
В связи с характером лабораторных заданий этот недостаток можно
устранить, подключив сервер виртуализации непосредственно к интерфейсу лабораторного коммутатора SW3 (HP ProCurve 2650). Это позволяет избежать необходимости дважды передавать данные по каналу связи между
коммутаторами SW1, SW2 и SW3 для обеспечения односторонней связи.
Кроме того, необходимо рассмотреть ситуацию, когда в рамках лабораторного задания физическая рабочая станция общается с контрагентом в
обучающей VLAN. В этом случае и программный клиент, и аппаратный телефон подключаются к программной IP-АТС на виртуальном сервере. Однако
все устройства назначаются одной и той же VLAN, и маршрутизация между IP-подсетями отсутствует. Основной проблемой здесь является подключение сервера виртуализации, которое реализовано с использованием того
же транкового соединения, которое обеспечивает доступность других экспериментальных VLAN для сервера виртуализации. Так как все экспериментальные и обучающие VLAN подключены к этому серверу по единому линку, то весьма вероятно, что из-за чрезмерного использования этого линка и
неактивной поддержки параметров QoS на коммутаторе доступа результаты
лабораторного задания окажутся негативными. Решением этого недостатка
может быть использование отдельных соединений между «серверным» коммутатором и хостом виртуализации для обслуживания экспериментальной и
обучающей VLAN или перемещение виртуализированных серверов, которые
должны быть подключены к обучающей VLAN, на другой сервер виртуализации, который используется исключительно для подключения устройств в
виртуальной сети.

34

3

Новая архитектура сети передачи данных

Сеть передачи данных, описываемая в данной дипломной работе, должна
служить основой для выполнения большого количества лабораторных заданий в тестирования, но в то же время должна обеспечивать доступ к остальной рабочей сети и сети Интернет, должна обеспечивать доступ к некоторым
более продвинутым сервисам, обычно используемым в корпоративной среде,
и в то же время гарантировать определенную степень надежности. Поскольку доступно несколько активных сетевых элементов и передовых серверных
технологий, в работе также учитывается возможность включения этих элементов в окончательный проект.
Новая модель сети передачи данных создается в течение летнего семестра
параллельно с лабораторией. По этой причине здесь используется совершенно отдельный коммутатор Cisco WS3750X-48P, настроенный на роль главного
коммутатора, образующего ядро сети. В нем, помимо прочего, имеется 48 интерфейсов 1000BASE-T, которые соединяют не только пограничный маршрутизатор, но и другие коммутаторы доступа. Установленная версия операционной системы Cisco IOS включает, среди прочего, пакет ipservices, который
делает коммутатор пригодным для предоставления основных услуг на базе
IP (коммутация L3, создание и применение ACL, агент DHCP Relay и т.д.).
Благодаря использованию коммутатора L3 в ядре сети, топология становится очень гибкой и формирует основу для новой сети передачи данных со
следующими требованиями:
- Подключение рабочих станций через сеть Ethernet.
- Подключение лабораторного оборудования через сеть Ethernet.
- Защищенный доступ к рабочей сети и Интернету для ПК.
- Изолированное подключение L2/L3 для лабораторных рабочих станций.
- Резервное подключение с использованием агрегированных каналов.
- Устранение недостатков, описанных в предыдущей главе.
В сети передачи данных, которая будет функционировать в лаборатории
для реализации обучения, необходимо обеспечить сетевой доступ для 24 рабочих станций, которые составляют основу каждого рабочего места в лаборатории. Каждая рабочая станция оснащена сетевым интерфейсом, который
35

используется для доступа к локальной сети и реализации экспериментальной сетевой среды, обеспечивающей подключение к экспериментальным элементам лаборатории. Большинство рабочих станций используют тегирование
кадров для доступа к экспериментальным сетям, а другие (нетегированные)
назначаются операционной системой хоста в VLAN по умолчанию, которая
определяется как VLAN с VID 10 на коммутаторе доступа. Связность обеспечивается так же в серверной части, но в отдельном VLAN с VID 20. Особый случай — распространение VLAN с VID 90, который используется исключительно для управления и выводится на коммутаторы доступа только
для реализации виртуального L3-интерфейса для управления данным элементом. Конечная станция или сервер никогда не будут подключены к этой
сети VLAN, но между устройствами будет доступна маршрутизация и L3
коммутация (виртуальный L3 интерфейс сетевых элементов). VLAN управления распространяется на все активные элементы сетевой инфраструктуры.
Для новой разработанной топологии я также ввожу новую номенклатуру в
соответствии с рисунком 3.1. Их имена соответствуют связям согласно рисунку, которые могут быть могут быть разрешены с помощью DNS, как для
записей A, так и для PTR.

Рисунок 3.1 — Новые имена для активных сетевых элементов
Имена активных элементов выбираются в соответствии с заранее согласованным соглашением, цель которого - облегчить управление устройствами
(например, для удаленного доступа с помощью эмулированного терминала).
Первая пара букв выбирается в соответствии с назначением устройства, т.е.
- RB: RouterBoard - устройство является маршрутизатором.
36

- SW: Switch - устройство является коммутатором.
- FW: Firewall - устройство является фильтрующим элементом.
- R2 или R3 указывает на расположение устройства в техническом помещении (номер стойки).
- CORE: это устройство, образующее ядро сети.
- SRV: это устройство серверного сегмента.
- KLI: это устройство пользовательского сегмента.
- LAB: это устройство, соединяющее экспериментальные элементы.
3.1

Базовое подключение сетевых пользователей

Как уже упоминалось, используемый коммутатор Cisco WS-3750X обладает функцией коммутации L3 и будет использоваться в качестве основного
коммутатора в новой конструкции. В сетях меньшего масштаба, таких как
эта, это очень распространено для уровня распределения и ядра сети. Новая
топология представлена в соответствии с рисунком 3.2.

Рисунок 3.2 — Инфраструктура сети передачи данных без экспериментальных топологий
37

На диаграмме сети передачи данных показана реализация фрагмента
пользователя и сервиса с использованием только двух коммутаторов. Затем
они подключаются к «центральному» коммутатору L3, на интерфейсе которого IP-пакеты маршрутизируются между отдельными VLAN. Такая схема подразумевает требование доступности суб-каналов к коммутатору в ядре сети, поэтому они образуют агрегированный канал, который обеспечит
связь для фрагмента в случае отказа одной из пар, образующих логический
канал. Уровень доступа как для пользовательского, так и для сервисного
фрагмента состоит из двух соединенных между собой коммутаторов. Если
один коммутатор используется для рабочих станций, а другой - только для
серверных устройств, конфигурация обоих коммутаторов доступа значительно упрощается. Кроме того, можно применять другой уровень безопасности
«глобально», то есть с областью действия, ко всем интерфейсам серверного
коммутатора, чем в случае коммутатора, используемого для подключения рабочих станций, и серверов. Однако эта реализация предъявляет повышенные
требования к доступности серверной инфраструктуры в сети передачи данных. Если сегмент сервера недоступен для рабочих станций, рабочие станции
теряют доступ к службам домена DHCP, DNS и Active Directory. Недоступность этих служб не позволит всем пользователям рабочих станций работать,
поскольку учетные записи пользователей в базе данных AD не могут быть
аутентифицированы, если контроллер домена недоступен.
По этой причине серверная VLAN с VID 20 также передается на коммутатор клиентского доступа с помощью магистрального интерфейса. Интерфейс
41 выделен на этом коммутаторе для подключения ADC, вторичного DNSсервера и вторичного DHCP-сервера. Это обеспечивает доступность основных
сетевых услуг и возможность использования рабочих станций, даже если все
устройства, включая сам коммутатор серверного сегмента будут отключены.
Для каждой подсети на коммутаторе в ядре сети создается виртуальный
L3-интерфейс, которому назначается первый пригодный для использования
адрес данного сегмента, т.е. 10.10.10.1 из диапазона адресов 10.10.10.0/24.
Аналогичная схема адресации применяется к подсети, предназначенной для
серверных устройств, и подсети, предназначенной для управления сетевыми
элементами, т.е. IP-подсети в VLAN с VID 20 и 90. Кроме того, на коммута38

торе, который является ядром сети, создается дополнительный VLAN с VID
100, который передается только между коммутатором и пограничным маршрутизатором. В этом VLAN развернута IP-подсеть из диапазона 10.10.0.0/24
для обеспечения двухточечного соединения для передачи единиц данных к
маршрутизатору по умолчанию (пограничному). Это обеспечивает подключение к рабочей сети и Интернету для всех устройств в подсетях лаборатории,
кроме экспериментальных устройств или подсетей, определенных в экспериментальных VLAN.
3.1.1

Конфигурация коммутатора Cisco WS-3750X-48P

Коммутатор Cisco WS-3750X-48P является элементом агрегации в сети
передачи данных для связи между VLAN с VID 10, 20 и 90. Устройство образует так называемое ядро сети и предлагает функцию коммутации L3, то есть
маршрутизации между VLAN, которые обычно определяются на коммутаторах доступа. Для каждой такой VLAN на коммутаторе создается виртуальный интерфейс L3 с первым допустимым адресом IP-подсети. Соединения с
обоими коммутаторами доступа формируются агрегированным каналом с использованием двух физических каналов. Таким образом, максимальная теоретически доступная пропускная способность равна C = 2 Гбит/с. Резервный
канал выбран здесь для обеспечения связи в случае отказа одного из каналов,
а не для обеспечения более высокой пропускной способности между частью
доступа и основной частью сети.
Передача кадров между коммутаторами доступа и граничным маршрутизатором происходит исключительно с использованием тегированных кадров.
Особенностью этой конфигурации является установка VLAN по умолчанию
для всех интерфейсов на несуществующую VLAN с VID 3 и предотвращение распространения VLAN с VID 1. Это предотвращает передачу кадров,
не принадлежащих заранее определенной сети VLAN. На этом коммутаторе
зарезервированы интерфейсы доступа VLAN с VID 90, где только администратор (интерфейсы не выведены на панель коммутатора, а выведены на
LAN-розетки на рабочих местах лаборатории) может подключать устройства,
предназначение которых — управление сетевой инфраструктурой. Как пра39

вило, это устройства KVM-переключателей, Power over Net, ИБП и другие.
Для этих устройств выбирается подключение к элементу сети, для которого
предполагается максимальная доступность — например, из-за потери связи
на коммутаторе SW-R2-SRV-01 удаленное управление серверами с помощью
KVM будет невозможно.
Хотя на коммутаторе не настроены функции ARP Inspection, Port Security
и т.п., режим работы коммутатора можно охарактеризовать как работу с
повышенным уровнем безопасности для обеспечения согласованности топологии сети передачи данных. Это соответствует развертыванию механизмов
защиты PortFast и BPDU Guard. Кроме того, ограничение на передачу кадров, отправляемых на всенаправленный адрес с помощью функции Storm
Control, устанавливается на интерфейсе, формирующем логическое соединение с маршрутизаторами доступа. Эта функция для данного интерфейса
определяет уровень, связанный с доступной пропускной способностью интерфейса, который может достигать определенного типа трафик в заданном
интервале. Интервал выбран длительностью в одну секунду, а уровень в случае всенаправленных сообщений выбран L = 0, 125. Для конфигурации на
интерфейсе, теоретическая максимальная пропускная способность которого
составляет 2 Гбит/с, конфигурация ограничивает пропускную способность
интерфейса порт-канал 10 до 250 Мбит/с для распространения кадров, отправляемых на всенаправленный адрес. Настройка Storm control на коммутаторе показана в соответствии с рисунком 3.3.

Рисунок 3.3 — Использование Storm control
Для подсети клиентских устройств ограничивается связь рабочих станций с элементами сети VLAN с VID 90, т.е. IP-подсети 10.10.90.0/24, которая
предназначена только для управления и настройки этих устройств. В подсети 10.10.10.0/24 зарезервировано одно рабочее место (ПК администратора с
DHCP-резервированием), единственное, которому разрешен полный доступ
к указанной подсети. Используются расширенные списки контроля доступа
40

для фильтрации единиц данных и применяются их только во входящем направлении на виртуальном интерфейсе для VLAN 10. Эта настройка показана
в соответствии с рисунком 3.4

Рисунок 3.4 — Использование расширенных списков контроля доступа
Сказанное выше обеспечит требуемую безопасность и отключит L3маршрутизацию коммутатором для всех рабочих станций данной подсети, за
исключением ПК администратора, где, наоборот, желательно наличие всех
элементов данной подсети. В дополнение к описанной выше конфигурации
будут добавлены все экспериментальные VLAN в выделенный транк на интерфейсе между SW-R3-LAB-01 и SW-R2-LAB-01, чтобы обеспечить альтернативный путь в сети передачи данных для распространения экспериментальных VLAN. Также настраиваются общие параметры, IP-адреса SNTPсерверов, доступ по SNMP с правами на чтение и отправку сообщений SNMP
Trap на центральный элемент мониторинга.
3.1.2

Конфигурация коммутатора DLINK 3120-48PC

Коммутатор DLINK 3120-48PC, получивший соответствующее название
SW-R2-KLI-01, предлагает 48 интерфейсов, работающих на скорости до 1
Гбит/с, и 4 слота для модулей SFP+. Доступ к интерфейсу конфигурации
осуществляется через виртуальный интерфейс L3, адрес которому по умолчанию присваивается сервером DHCP. Конфигурирование коммутатора возможно с помощью веб-интерфейса, протоколов Telnet и SSH для терминального доступа, а также последовательного интерфейса RS-232. На коммутато41

ре имеется конфигурация, которая позволяет работать сети передачи данных,
описанной в разделе 2.1
Новая модель сети передачи данных учитывает наличие виртуальных
VLAN с VID 10, 20 и 90. Первым шагом является настройка VLAN, предназначенной для управления данным элементом, т. е. VLAN с VID 90, которая распространяется на транковый интерфейс, соединяющий вышестоящий
коммутатор в ядре сети. Это интерфейсы 1:47 и 1:48 (еще не назначенные на
канал LACP). Впоследствии эта VLAN назначается управляющей VLAN, поэтому будет создан виртуальный интерфейс L3, которому затем можно будет
назначить IP-адрес из диапазона 10.10.90.0/24. Конфигурация VlAN управления представлен в соответствии с рисунком 3.5

Рисунок 3.5 — Конфигурация VLAN 90 на коммутаторе
Все сети VLAN создаются на коммутаторе аналогичным образом, но им не
назначается IP-адрес. Вышесказанное подразумевает, что интерфейс настроен как магистральный, поскольку принимаются тегированные кадры. Пример
определения сети VLAN с VID 10 и интерфейсов доступа 1:01 - 1:42 показан
в соответствии с рисунком 3.6

Рисунок 3.6 — Конфигурация VLAN 10 на коммутаторе
42

Опять же, эта VLAN распространяется на магистральный интерфейс родительского коммутатора в ядре сети, в частности, используя порты 47 и
48.
Интерфейс соединения между SW-R2-KLI-01 и SW-R3-LAB-01 затем конфигурируется в соответствии с рисунком 3.7

Рисунок 3.7 — Конфигурация соединения SW-R2-KLI-01 и SW-R3-LAB-01
На этом этапе настраиваются отдельные интерфейсы коммутатора для
нужд расширения экспериментальных сетей VLAN и для доступа к сети
VLAN рабочих станций с использованием нетегированных кадров, т.е. VLAN
с VID 10. Разделение отдельных рабочих мест здесь реализуется путем настройки конкретных сетей VLAN для который коммутатор доступа на данном интерфейсе принимает кадры с соответствующими тегами. Ниже приведена конфигурация упомянутого логического канала, состоящего из двух
физических каналов с коммутатором в ядре сети. Для этого используются
интерфейсы 47 – 48 и следующая директива, в соответствии с рисунком 3.8

43

Рисунок 3.8 — Конфигурация логического канала, состоящего из двух физических каналов
Выше показано назначение портов 47 и 48 логическому каналу с идентификатором 10. Хотя основной целью является обеспечение избыточности
между двумя коммутаторами, протокол LACP также определяет алгоритмы балансировки нагрузки между физическими каналами. Все интерфейсы
установлены в пассивный режим, агрегированный канал инициируется родительским коммутатором.
Важной частью конфигурации является реализация механизмов безопасности, описанных в главах 1.3.2 - 1.3.4, предотвращение ARP-спуфинга и
экранирование DHCP-сервера. Конфигурация представлена в соответствии с
рисунком 3.9

Рисунок 3.9 — Конфигурация защиты от APR-спуфинга и экранирования
DHCP-сервера
44

Из приведенной выше конфигурации в случае функции проверки достоверности ARP устанавливается один MAC-адрес, который может содержаться в блоках данных ARP-ответа при поиске MAC-адреса, соответствующего
IP-адресу шлюза по умолчанию в сети, в данном случае 10.10.10.1. Также
ввожу ограничения активных MAC-адресов на интерфейсах доступа, предназначенных для рабочих станций, до максимально возможного количества
3 MAC-адресов, зарегистрированных на один порт, всего 40 MAC-адресов
для интерфейсов доступа для VLAN с VID 10 (по 1 MAC-адресу на каждый
интерфейс).
Последней, но очень важной частью является настройка, которая представлена в соответствии с рисунком 3.10, SNTP-клиента и набора информации, которая будет доступна с помощью SNMP OID и отправлена в центральную систему мониторинга (сервер Zabbix, IP 10.10.20.20). Клиент SNTP использует информацию о времени, полученную от обоих контроллеров домена.
Эта конфигурация очень полезна для отслеживания событий и их сравнения
с событиями на других элементах сети. Информация о синхронном времени
также очень важна для записи событий с отметками времени.

Рисунок 3.10 — Конфигурация SNTP и SNMP
45

Переходы, которые могут поставить под угрозу безопасность того или иного элемента (определения учетных записей пользователей, методы аутентификации, методы доступа и т.д.), намеренно опущены. Кроме того, я намеренно оставил настройки SNMP-сообщества по умолчанию и оставил сообщество
по умолчанию под названием public в качестве сообщества с разрешением на
чтение значений. На практике это сообщество обычно не используется по соображениям безопасности, и любой будущий администратор сети передачи
данных должен убедиться, что эта параметр изменен соответствующим образом.
3.1.3

Конфигурация коммутатора Zyxel XGS1910

Как и в случае с коммутатором доступа SW-R2-KLI-01, в этом разделе
будет произведен анализ настройки коммутатора SW-R2-SRV-01, обеспечивающего подключение серверного сегмента.
Как упоминалось ранее, коммутатор серверного сегмента предназначен
только для подключения серверных устройств. По этой причине некоторые
конфигурации безопасности удалены. Основное предположение заключается
в том, что ни один пользователь не имеет физического доступа к интерфейсу этого коммутатора. Здесь подключены серверы виртуализации, которые
обеспечивают связь со многими виртуальными станциями. Настройка ограничения MAC-адресов на таком интерфейсе весьма контрпродуктивна (значения могут динамически меняться во время миграции трафика), эффективная работа механизмов ARP Inspection здесь ограничена в основном из-за
статически назначенных адресов.
Коммутатор Zyxel XGS1910 имеет в общей сложности 48 портов стандарта
1000BASE-T и восемь отсеков для подключения модулей SFP+. Управление
устройством возможно только через веб-интерфейс или путем подключения
к физическому интерфейсу консоли. Так как большинство подключаемых
здесь устройств содержат несколько интерфейсов или сетевых карт, здесь во
многом настраивается агрегация физических линий, даже в случае подключения конечных устройств (серверов). Это обеспечивает как большую надежность соединения, так и лучшее распределение нагрузки между несколькими
46

соединениями. Для серверного сегмента характерна очень частая взаимная
связь серверов внутри локальной сети (VLAN 20). Примером такого взаимодействия является миграция виртуальных машин между хостами Hyper-V. В
основном это передача виртуальных жестких дисков, которые подключены
к отдельным серверам из общего сетевого хранилища или передача команд
SCSI по протоколу IP с использованием iSCSI.
Базовая конфигурация снова включает создание всех VLAN и назначение
их в соответствии с портами. Далее создается виртуальный интерфейс L3 для
управления устройством, которому снова присваивается VLAN с VID 90 и
IP-адресом из соответствующего диапазона, оглашенного ранее. Далее, при
настройке общих параметров, всегда надо включать достоверную информацию в поля Contact, Name и Location - эта информация передается в объектах
OID информационной базы по протоколу SNMP и облегчает идентификацию
и инвентаризацию. с помощью центрального элемента мониторинга.
Существенным отличием в конфигурации по сравнению с SW-R2-KLI-01
является многократное подключение серверных устройств к нескольким интерфейсам на одном коммутаторе. Серверы виртуализации имеют от 4 до 6
интерфейсов и, как правило, две сетевые карты. По этой причине целесообразно использовать агрегацию и выделять определенные VLAN, которые
могут распространяться по данному каналу. Для сервера, на котором работают критически важные сетевые компоненты, настройка этих интерфейсов
позволит передавать кадры с VIDs 10 и 20.
Поскольку этот коммутатор подключен, к устройству хранения Lenovo
px6-300, которое служит централизованным хранилищем для лабораторной
сети и общим хранилищем для кластера виртуализации, также были настроены оба его интерфейса на агрегированный канал.
Преимуществом такой конфигурации является, помимо прочего, удаление
всех экспериментальных сетей VLAN из конфигурации этого коммутатора.
Экспериментальные сети больше не будут передаваться между SW-R2-SRV01 и SW-R2-KLI-01, или магистральный интерфейс к серверу виртуализации
больше не будет подключен к этому коммутатору. Поэтому для них не подходит продолжение передачи между этими элементами и использование про-

47

пускной способности соединения через многоадресную рассылку. Сети VLAN
всегда статически назначаются отдельным интерфейсам.
3.2

Подключение экспериментальных сетей

Описанная до сих пор топология не учитывает возможность подключения
других устройств, в основном экспериментальных сетевых элементов, конфигурация которых обычно является предметом тестирования. Оригинальная
конструкция обеспечивает доступность экспериментальных устройств с помощью коммутатора HP ProCurve 2650, на интерфейсе которого передаются
тегированные кадры экспериментальных сетей VLAN между коммутаторами
SW-R2-KLI-01, SWR2-SRV-01 и SW-R3-LAB-01. Из-за характера тестирования такая реализация очень неуместна. Используемый сервер виртуализации
предлагает достаточное количество интерфейсов, которые можно подключать по мере необходимости к коммутаторам доступа, чтобы обеспечить кратчайший сетевой путь между двумя напрямую взаимодействующими станциями.
К сожалению, на коммутаторе SW-R3-LAB-01 (модель HP ProCurve 2650)
доступны только два интерфейса 1000BASET. По этой причине один интерфейс будет предназначен для передачи тегированных кадров между коммутатором SW-R2-KLI-01, соединяющим рабочие станции, а другой интерфейс для прямого подключения сервера виртуализации. С помощью тегированных
кадров кадры передаются между двумя коммутаторами, сопровождаемые соответствующим тегом в соответствии с принадлежностью станции к заданию
тестирования. Соединение активных элементов и участвующих станций для
связи в соответствии с потребностями лабораторных заданий показано, в соответствии с рисунком 3.11

48

Рисунок 3.11 — Связь между компонентами лабораторного задания тестирования
На модифицированной диаграмме топологии показано подключение узла
виртуализации к коммутатору SW-R3-LAB-01. Основным преимуществом является значительное сокращение количества элементов, участвующих в распространении экспериментальных сетей VLAN. Вторым преимуществом является снижение потребности в связи по магистральному интерфейсу между коммутатором, соединяющим рабочие станции и лабораторные элементы.
Однако недостатком этого относительно простого соединения снова является
существенное ограничение работы при выходе из строя одного из соединений
между элементами экспериментальной части и элементами рабочих мест обучающихся. Риск полного отказа можно частично снизить, подключив дополнительный канал, который обеспечит доступность экспериментальных сетей
VLAN даже в случае отказа канала между SW-R3-LAB-01 и SW-R2-KLI01. Здесь распространение экспериментальных сетей VLAN настраивается от
клиентского коммутатора через базовый элемент (SW-R2-CORE-01) и затем
к коммутатору SW-R3-LAB-01. Это соединение обеспечит приемлемый уровень резервирования и защиту от выхода из строя соединения между упомянутыми коммутаторами, но резервная линия будет реализована только с соединением 100BASE-TX. Кроме того, необходимо будет обеспечить удаление
петель в сети с помощью протокола управления с использованием алгоритма
поиска каркаса графа.

49

3.2.1

Конфигурация коммутатора HP ProCurve 2650

Основным коммутатором в стойке для подключения экспериментальных
элементов является коммутатор HP ProCurve 2650 под названием SW-R3LAB-01. Это устройство обеспечивает связь между экспериментальными элементами лабораторных заданий и виртуализированными рабочими станциями или виртуальными серверами. Хотя устройство предлагает до 50 портов, только два из них способны работать в режиме 1000BASE-T. Это существенное ограничение, особенно для реализации альтернативных маршрутов
экспериментальных топологий. Второй интерфейс зпредназначен для обеспечения вышеупомянутой связности хоста виртуализации, т.е. для доступа
к экспериментальным сетям с использованием тегированных кадров для 10
виртуализированных серверов.
Поэтому очевидно, что для связи виртуализированной станции на рабочих
станциях студентов с виртуальным сервером, работающим на хосте виртуализации, необходимо обеспечить доступность соответствующих сетей VLAN
на обоих портах коммутатора. Конфигурация конкретных сетей VLAN реализуется на основе анализа сетей VLAN, настроенных на сервере виртуализации, или их присвоение виртуальным станциям. Коммутатор SWR3-LAB-01
не предлагает функций сетевого уровня ни для одной из экспериментальных сетей, поэтому на его интерфейсе нет маршрутизации, фильтрации или
обеспечения качества обслуживания.
VLAN с VID 90 также распространяется на коммутаторе на транк интерфейсе, связанном коммутатором SW-R2-KLI-01, назначение которого зарезервировано для управления сетевыми элементами. Кроме того, для этой
VLAN создается виртуальный IP-интерфейс с IP-адресом 10.10.90.5 из соответствующего диапазона. Подключение к этому коммутатору возможно,
в частности, через консольный кабель или протокол Telnet для реализации
виртуального терминала.
Конфигурация этого коммутатора была оставлена в очень неудовлетворительном состоянии до внедрения нового лабораторного сетевого решения.
Самым большим недостатком является распространение самой VLAN, которая используется для управления (здесь использовалась тестовая VLAN 310
50

и выводилась на интерфейс доступа от коммутатора SW3 с помощью нетегированных кадров. По этой причине настраивается переопределение VLAN
с VID 90 и сопостовляется на интерфейс, соединяющий с коммутатором SWR2-KLI-01.
В процессе настройки заполняется полностью отсутствующая общая информация об устройстве — то есть местоположение, информацию для связи
с администратором, и настраивается синхронизация данных о времени по
протоколу SNTP с двумя контроллерами домена. Так же настраивается возможность сбора данных по протоколу SNMP и отправки SNMP "оповещения"(SNMPTraps) на сервер мониторинга с IP 10.10.20.20..
3.2.2

Конфигурация коммутатора HP ProCurve 2626

После перехода к новой концепции сети передачи данных коммутатор HP
2626 остался незадействованным. Его назначение заключалось в распространении обучающей сети VLAN на интерфейс коммутатора HP 2650 и - как видно из прилагаемой конфигурации - некоторых экспериментальных. Поскольку эти требования больше не присутствуют в новой структуре сети данных,
он конфигурируется для пробуждения расширения сети лаборатории, т.е. для
распространения VLAN с VIDs 10, 20 и 90. Его конфигурация аналогична
конфигурации клиентского коммутатора доступа, но функции безопасности,
характерные для коммутатора доступа SWR2-KLI-01, здесь не активированы. Физически этот коммутатор расположен в стойке R3, где по техническим причинам уже невозможно реализовать другое подключение к стойке
R2. Устройства, которые могут быть подключены к коммутаторам SW-R2KLI-01 и SW-R2-SRV-01 и которые не требуют использования интерфейса
1000BASE-T, могут быть подключены к 24 интерфейсам этого коммутатора.
Как правило, это беспроводные точки доступа или устройства Serial over Net.
Конфигурация осуществляется с помощью виртуального терминала, реализованного по протоколу Telnet. Задается базовая конфигурация - имя
устройства SW-R3-LAB-01, IP-адреса SNTP-серверов, конфигурацая для мониторинга с помощью SNMP и многое другое.
51

3.3

Устранение петель с помощью MSTP

Из конфигурации, описанной выше, очевидно внедрение топологии петли для обеспечения избыточности между блоками сети передачи данных. В
целом, надо разделять эту сеть на две отдельные части, каждая из которых
имеет различные требования к доступности топологии и производительности.
- Производственная инфраструктура - часть, выделенная красным цветом, т.е. сегмент сети передачи данных, обеспечивающий работу рабочих станций (DNS, DHCP, AD DC) с использованием базовых сетевых
сервисов.
- Экспериментальная инфраструктура - часть, выделенная зеленым цветом, т.е. сегмент сети передачи данных, обеспечивающий реализацию
экспериментальных топологий и обработку лабораторных заданий.
Основываясь на этом факте, реализуется первое петлевое соединение между коммутаторами SW-R2-CORE-01, SW-R2-KLI-01 и SWR2-SRV-01. Таким
образом, это две VLAN, которые удобно инстанцировать отдельно в рамках
протокола MSTP - в случае изменения топологии из-за сбоя эти VLAN будут
затронуты одинаково, поскольку они распространяются из основной сети на
одни и те же коммутаторы одновременно. Я назначаю эти VLAN первому экземпляру протокола MSTP, т.е. MSTI 1. Экспериментальная инфраструктура
образует отдельную структуру, которая сосуществует с производственной инфраструктурой и в некоторой степени зависит от нее (распространение VLAN
с VID 90). Распространение между элементами SW-R2-KLI-01, SWR3-LAB-01
и SW-R2-CORE-01 является специфическим для экспериментальных сетей.
Коммутатор в ядре сети намеренно выбран в качестве альтернативного элемента из-за достаточной коммутационной способности и количества незанятых портов. Для всех экспериментальных сетей, которые распространяются
между двумя основными коммутаторами (SW-R2-KLI-01 и SW-R2-LAB-01) и
резервным коммутатором в ядре сети, я выбираю другой экземпляр протокола MSTP - MSTI 2. И здесь, в случае, если из-за недоступности основного
канала необходимо будет найти альтернативный каркас графа, все экспериментальные сети VLAN должны будут распространяться через резервный
коммутатор.
52

Петлевая топология двух частей инфраструктуры показана на диаграмме,
в соответствии с рисунком 3.12.

Рисунок 3.12 — Петлевая топология двух частей инфраструктуры
На диаграмме также показаны предпочтительные варианты корней деревьев для обоих экземпляров. Для производственной инфраструктуры наиболее подходящим выбором является коммутатор в ядре сети, особенно из-за
избыточных связей, скорости и характера распространения VLAN с VID 10
и 20. С другой стороны, для экспериментальных топологий рекомендуется
выбрать коммутатор SW-R3-LAB-01 в качестве корня дерева и обеспечить
предпочтительную связь по первичному каналу путем настройки приоритетов интерфейса по следующим причинам:
- Связь между SW-R2-KLI-01 и SW-R3-LAB-01 представляет собой кратчайший путь для распространения кадров в экспериментальных VLAN.
- в будущем к SW-R3-LAB-01 могут быть подключены дополнительные
коммутаторы для распространения экспериментальной инфраструктуры.
- между SW-R3-LAB-01 и SW-R2-CORE-01 имеется канал связи
100BASE-TX.
Выбор корня дерева зависит, помимо прочего, от установленных приоритетов, и действительно, более низкое значение приоритета (обычно задается
кратным 4096) указывает на более подходящий коммутатор для корня дерева. В случае предоставления роли корня для коммутатора SW-R2-CORE-01

53

в режиме конфигурирования MSTI используется значение приоритета 8192.
Настройка выбора корня показана в соответствии с рисунком 3.13.

Рисунок 3.13 — Выбор корня MSTI
Кроме того, намеренно снижается приоритет выбора для интерфейса, реализующего резервный канал между SW-R2-SRV-01 и SW-R2-KLI-01, чтобы
для подключения к родительскому коммутатору был выбран агрегированный
канал. При тестировании сценария обрыва основного канала между SW-R2CORE-01 и коммутатором доступа серверного или пользовательского сегмента время восстановления канала, т.е. скорость сходимости протокола MSTP
для экземпляра 1 MSTI, было измерено в диапазоне 1 - 3 секунд. Пользователь не заметит обрыва такого соединения при обычной работе.
Таким же образом обеспечивается подходящий выбор корня для второго
экземпляра протокола MSTP, что обеспечивает устранение петли в случае
экспериментальных сетей VLAN. Опять же, было выбрано значение 8192,
чтобы установить приоритет на коммутаторе SW-R3-LAB-01 и адекватный
приоритет предпочтительного интерфейса. Коммутаторы SWR2-CORE-01 и
SW-R2-KLI-01 для MSTI 2 должны иметь более низкий приоритет, чтобы
предотвратить их нежелательный выбор в качестве корня дерева. Намеренно оставлена виртуальная сеть с VID 90 как часть экземпляра MSTI 0 по
умолчанию.
Выбор корня для данного экземпляра не очень важен, большая часть трафика данных, передаваемого в этой VLAN, состоит только из блоков данных
протокола SNMP, либо данных протоколов Telnet и SSH при подключении
к интерфейсу конфигурации сетевых элементов. Исключением может быть
работа с KVM, однако здесь предполагается, что административные операции выполняются удаленно подключенным администратором только в случае
необходимости, как правило, с использованием VPN. Эти пакеты никогда не
распространяются за пределы основного коммутатора сети и пограничного
54

маршрутизатора. Устройства управления подключаются к портам коммутатора в ядре сети. Выбор соответствующего корня дерева существенно не повлияет на необходимость обеспечения доступности устройств в IP-подсети
10.10.90.0/24.

55

4

Серверная инфраструктура

Основным элементом новой инфраструктуры серверного сегмента является коммутатор Zyxel XGS1910, который обеспечивает сетевой доступ ко всем
физическим и виртуальным серверам. Это коммутатор, назначение которого
намеренно зарезервировано только для подключения серверных устройств,
взаимодействующих в недавно созданной виртуальной локальной сети с VID
20. Такая реализация выбрана с учетом повышенных требований к передаче
данных между серверами (например, резервное копирование на общее хранилище, использование общего хранилища кластером виртуализации). В определенной таким образом серверной подсети работают, в частности, следующие серверы:
- Два узла кластера виртуализации.
- Физический контроллер домена, DHCP и первичный DNS-сервер.
- Общее хранилище.
- Неиспользуемый сервер.
Поскольку службы и серверные системы Microsoft Windows Server в значительной степени были развернуты в старой версии 2008 R2, обновление (переход) на более свежую версию Windows Server происходит с переходом к новой концепции. Основная цель - более эффективное распределение серверных
служб между доступными серверами и обеспечение устойчивости к отказам
серверов, предоставляющих основные услуги, характерные для корпоративных сетей. По этой причине я использую два сервера для формирования
кластера виртуализации, который включает в себя резервный контроллер
домена и выделенную станцию для управления сетевой инфраструктурой.
Два узла кластера виртуализации обеспечивают High Availability для виртуального сервера, который способен запускать службы AD, DNS и DHCP.
Все виртуальные станции для выполнения тестовыъ заданий обеспечиваются
только одним узлом, и эти виртуальные машины не резервируются HA.
4.1

Хранилище данных

В лаборатории имеется запоминающее устройство с подключением к сети передачи данных. Это LenovoEMC™PX6-300d. Данное устройство имеет
56

шесть внутренних отсеков для жестких дисков с интерфейсом SATA 6 Гбит/с
и разъемы USB3.0 для подключения внешних устройств. Жесткие диски могут быть настроены для использования в дисковых массивах RAID 0, 1 и
5. Устройство также оснащено двумя сетевыми интерфейсами, которые поддерживают максимальную скорость до 1 Гбит/с и могут быть объединены в
логический канал. Для лучшего доступа к устройству и его легкой идентификации в доменной структуре устройству присваивается имя SC5-32-NAS01
с IP-адресом 10.10.20.3 из диапазона 10.10.20.0/24. Кроме того, устройство
хранения включено в доменную структуру Active Directory.
В настоящее время в накопителе установлено четыре жестких диска
Western Digital WD20EFRX емкостью 2 ТБ. Это жесткие диски, предназначенные производителем для использования в устройствах хранения для
«домашнего» использования, а не в устройствах, где в приоритете высокая
производительность и быстродействие. На этом устройстве все диски назначены на массив RAID 5. По своему предложению я реструктуризирую дисковый массив, где всего 4 диска разбиты на пары по 2 жестких диска. Каждая
пара образует массив RAID 1. Такое расположение основано на требованиях отдельных приложений к дисковой подсистеме. Каждый дисковый массив
образует пространство для хранения, общая емкость которого определяется
по уравнению CRAID1 = n/2, где n — сумма емкостей всех жестких дисков в
дисковом массиве RAID 1. Конфигурация этих массивов тогда соответствует
рисунку 4.1.

Рисунок 4.1 — Расположение жестких дисков в устройстве хранения данных
Включение дисков в нечетные и четные положения двух массивов дисков приводит к снижению вибраций и излучаемого тепла за счет активности
дисков. Дисковое пространство с пометкой drive_pool_1-3 в дальнейшем используется для создания томов, которые подключаются по протоколу iSCSI
в качестве хранилища для виртуальных машин. Таким образом, можно пред57

положить, что эти диски будут использоваться постоянно, а диски с ID 2 и 4,
составляющие дисковое пространство с меткой dirve_pool_2-4, составляют
пространство для создания общих папок. Здесь можно предположить более
частую остановку жестких дисков, потому что диски в этом поле крутятся только в случае доступа к общему диску, который предлагает дисковое
пространство.
Каждое дисковое пространство предлагает в общей сложности 1 802
Тб дискового пространства. Его распределение будет подчинено будущим потребностям. Для создания кластера виртуализации в пространстве
drive_pool_1-3 я создаю новый том iscsi-5-cluster емкостью 300 ГБ, который
может быть смонтирован по протоколу iSCSI и будет использоваться в качестве общего хранилища всеми узлами кластера. Этому тому автоматически
присваивается идентификатор IQN iqn.2012.07.com.lenovoemc:storage.SC5-32NAS01.iscsi-5-cluster.
4.1.1

Подключение к тому с помощью iSCSI

Идентификатор IQN может использоваться для уникальной идентификации тома устройства хранения, который должен быть подключен с помощью
протокола iSCSI на конечной станции или сервере. Для этого используется
инструмент iSCSIInitiator, доступный в ОС Windows, который применяется
на обоих узлах кластера. Этим инструментом также можно управлять из
интерфейса интерпретатора Windows Powershell. Первым шагом на целевом
сервере является запуск службы iSCSI, которая, помимо прочего, обеспечивает автоматическое подключение к тому на сетевом хранилище даже после
перезагрузки ОС.
Следующим шагом будет нахождение iSCSI Target Portal - сервера, который является посредником при подключении к дисковым накопителям,
называемым iSCSI Targets. Конкретные дисковые накопители идентифицируются строкой IQN, также называемой NodeAddress. Подключение к тому,
созданному в предыдущей главе, показано в соответствии с рисунком 4.2.

58

Рисунок 4.2 — Подключение ISCSI тома
Доступ к дисковым томам может контролироваться RADIUS-сервером,
инициатор и целевой сервер могут быть аутентифицированы, а сама передача команд может быть защищена с помощью протокола IPSec. Однако в
работе это не используется. Запись MBR, разделы диска и их файловые системы теперь можно создавать на подключенном таким образом виртуальном
диске. Для реализации кластерного общего хранилища (т.н. Cluster Shared
Storage) с помощью базовых средств я создаю новый раздел диска с буквой
R и файловой системой NTFS. Созданный часами раздел теперь доступен для
хранения данных внутри ОС. Чтобы иметь возможность воспроизвести эту
процедуру и на втором узле кластера, необходимо отключить подключенный
диск на первом узле (перевести его в автономный режим). Том iSCSI может
оставаться подключенным, но раздел не должен быть активен на нескольких
узлах.
4.2

Инфраструктура виртуализации

Для сохранения привычек и легкой интеграции в существующую среду
инфраструктура лаборатории будет расширена за счет совершенно нового
узла кластера виртуализации, реализованного с помощью Hyper-V. В качестве операционной системы хоста выбрана ОС Microsoft Windows Server 2016
Datacenter. Одним из критериев выбора здесь является требование простого управления платформой виртуализации и бесшовной интеграции в существующую среду, которая использует доменные службы Active Directory от
Microsoft.
Обновление операционной системы серверов виртуализации приносит значительные преимущества, наиболее важными из которых являются новые
режимы динамической памяти ВМ, новые сетевые службы ВМ (QoS, раз59

мещение общих дисков) и, наконец, возможность управления виртуальной
машиной из Windows Powershell.
С переходом на новую версию гипервизора появилась возможность более
эффективно распределять ресурсы физического хоста между виртуальными
станциями. Это достигается, в частности, за счет более продвинутой интеграции между родительскими и дочерними разделами и возможности динамического выделения ресурсов для данной виртуальной станции "на лету".
Полная виртуализация серверной инфраструктуры неизбежно влечет за собой критический момент - надежную работу физического узла. Требования
к его постоянной доступности возрастают с увеличением количества работающих на нем виртуальных машин, роль которых в сети незаменима. В то
время как функции контроллера домена и DNS-сервера могут быть обеспечены ADC в случае отказа одного из хостов, серверы, не являющиеся частью
распределенной среды, могут быть защищены только функцией резервного
копирования кластера. Этот механизм также может обеспечить безопасность
других служб или серверов, таких как файловый сервер, SQL-сервер и многие
другие.
Преимуществом кластера виртуализации является не только возможность
миграции виртуальных машин между отдельными хостами кластера, но и
запуск их на другом хосте в случае сбоя сервера виртуализации, на котором была запущена виртуальная машина. В зависимости от сложности механизма резервного копирования можно говорить о резервном копировании
без необходимости перезапуска машины или о резервном копировании путем
запуска на другом хосте. В случае резервного копирования без перезапуска виртуальная машина запускается одновременно на двух или более хостах
кластера, содержимое их оперативной памяти синхронизируется и в случае
сбоя сервера, на котором в данный момент активна ВМ, подключение к "резервной"виртуальной машине восстанавливается путем автоматической реконфигурации сетевой подсистемы.
Более эффективным использованием ресурсов лаборатории является запуск кластера с резервным копированием виртуальных машин с возможным
перезапуском на другом хосте. Такое решение является подходящим компромиссом для обеспечения высокой доступности виртуальных машин и эффек60

тивного использования вычислительных мощностей отдельных хостов. Данный метод также выбран с учетом особенностей виртуализированной инфраструктуры - некоторые виртуальные серверы являются частью распределенной архитектуры (контроллеры Active Directory, DNS-серверы), что обеспечивает функциональность в случае отказа одного из серверов на уровне приложений или ролей ОС.
Важным компонентом кластера виртуализации является общее хранилище, не только для обеспечения доступности виртуальных машин и их конфигураций, но и для операций управления записью и чтением, которые используются для поддержания координации между членами кластера. Функциональная схема кластера виртуализации с внешним разделяемым хранилищем
показана, в соответствии с рисунком 4.3.

Рисунок 4.3 — Запуск виртуальных машин HA в инфраструктуре виртуализации
Если данная виртуальная машина настроена для работы на альтернативном хосте, эта машина обозначается как Highly Available VM.
Схема показывает, что не все виртуальные машины должны быть запущены в кластере. Более того, необходимо учитывать резервирование вычислительных мощностей для машин, которые придется перезапускать на аль61

тернативном хосте в случае отказа одного из членов кластера.Для решения
этой проблемы на практике вводится резервирование и приоритеты для отдельных ВМ, чтобы в случае отказа инфраструктура могла продолжать работать, даже если хост не имеет ресурсов для запуска ВМ.Этот механизм должен обеспечивать как минимум один контроллер домена, один DNS-сервер
и DHCP-сервер. Однако в лабораторной сети имеется выделенный физический сервер, предоставляющий идентичные услуги, поэтому резервирование
ресурсов не используется.
4.3

Работа AD, DNS и DHCP с высокой доступностью

С переходом на новую концепцию сети передачи данных и разделением
ролей, установленных на доступных серверах, исчезла и роль альтернативного контроллера домена, который неоптимально функционировал на сервере
виртуализации (не в ВМ). Поскольку в рамках защиты доменной структуры
рекомендуется запускать как минимум два синхронизированных контроллера
домена с функцией глобального каталога, устанавливается новая виртуальная машина SC5-32-DC03v с работающим датацентром MS Windows Server
2016. система. Далее виртуальная машина помещается в расположение смонтированного тома CSV и добавляется в качестве роли кластера после установки.
Первичным узлом является сервер SC5-32-HPV01, но в процессе миграции и в случае отказа возможно перемещение ВМ на второй узел виртуализации. Предполагается, что в случае отказа физического контроллера домена можно будет продолжать использовать службы Active Directory, DNS и
DHCP-сервера - эти службы при необходимости будут предоставляться вновь
установленным виртуальным сервером.
При добавлении роли контроллера домена автоматически устанавливается DNS-сервер. Зоны этого DNS-сервера интегрируются в базу данных Active
Directory и ее данные в том числе. Записи DNS автоматически реплицируются
и синхронизируются с другими контроллерами домена с заданным интервалом в 15 минут.
62

Во время перехода на новую концепцию сети передачи данных этот контроллер домена также является единственным DHCP-сервером в лабораторной сети. Он обслуживает определенные диапазоны адресов для VLAN 10,
20 и 90. Для VLAN 20 и 90 существует диапазон с заведомо ограниченным
количеством - адреса из этих диапазонов обычно назначаются статически,
а динамическая конфигурация существует только для облегчения перехода
от исходной сети передачи данных к новой концепции. Это обеспечивает адресацию и доступ к сетевому оборудованию, которое еще не было должным
образом переконфигурировано. Кроме того, существует определенный диапазон IP-адресов для выделения клиентам из VLAN 12, который зарезервирован для пользователей беспроводных точек доступа в лаборатории. Запросы
DHCP направляются на сервер DHCP агентом DHCP Relay, который настроен на коммутаторе в ядре сети, за исключением VLAN 12 и 20.
Настройка обоих серверов DHCP требует, чтобы одинаковые адресные
пространства были добавлены и настроены идентично - например, резервирование адресов, исключения диапазонов и многое другое. Процесс настройки «резервирования трафика» сервера DHCP гарантирует, что оба сервера
DHCP установят партнерство и определят процент каждого диапазона, обслуживаемого сервером DHCP. Это партнерство может работать в режимах
HotStandby и Load Balancing. Создание нового партнерства для серверов с
именами SC5-32-DC03v и MERCURY можно выполнить с помощью командлетов, представленных в соответствии с рисунком 4.4

Рисунок 4.4 — Создание партнерства DHCP серверов
Работа пары заключается в контролируемом обслуживании запроса клиента на основе значения его MAC-адреса. Он вычисляется специальной функцией хэширования, выход которой принимает значения от 1 до 256. Если
коэффициент разделения установлен на 50%, то первый сервер отвечает на
запросы клиентов со значениями хэша от 1 до 128, второй - со значениями
хэша от 129 до 256. Доступные для аренды адреса в адресном пространстве
63

также делятся поровну между двумя DHCP-серверами. Если из-за выходных
значений хэш-функции одна половина диапазона используется с большей скоростью, чем другая, каждые 5 минут доступные адреса выделяются в новое
подпространство, которое перераспределяется между партнерскими DHCPсерверами. Если один из серверов выходит из строя, сервер-аналог берет на
себя распределение заимствований, независимо от хэш-функции для MACадреса клиента.
После правильной конфигурации обоих серверов DHCP необходимо соответствующим образом настроить параметры устройства, реализующего
функцию DHCP Relay. Эти устройства могут пересылать запросы соответствующим образом на омниканальный адрес в IP-подсети, где расположены DHCP-серверы. расположены. В качестве альтернативы можно указать
только адреса этих DHCP-серверов. В новой сети передачи данных используем целевую переадресацию на IP-адреса серверов DHCP. Эта настройка
выполняется на виртуальном интерфейсе L3 коммутатора в ядре сети, для
виртуальных локальных сетей с VID 10, 20 и 90.

64

5

Система мониторинга и резервное коипрование

Последняя часть работы связана с проектированием и реализацией системы мониторинга в сети передачи данных лаборатории. Кроме того, имеются
варианты резервного копирования конфигураций сетевых элементов, немедленная доступность которых позволит администратору отслеживать изменения и даст более четкую ориентацию в их настройках. Вместе с возможностью
наблюдения за текущим состоянием оборудования лаборатории это является очень полезным источником информации, и не только в случае решения
ошибочных ситуаций.
5.1

Мониторинг с помощью Zabbix

Система Zabbix доступна для загрузки для наиболее часто используемых
дистрибутивов ОС ядра Linux. Развертывание системы возможно путем загрузки и импорта так называемого Appliance, т.е. виртуального диска с заранее подготовленной установкой ОС Zabbix и ПО. Затем создание ВМ происходит таким же образом (это не ВМ с высокой доступностью), но вместо
создания нового виртуального диска подключается уже загруженный и извлеченный жесткий диск с установленной ОС Linux и полностью установленным Zabbix система версии 6.4.
Zabbix выбран в данной работе в основном из-за простоты администрирования и использования системы. Целью развертывания системы мониторинга
является возможность мониторинга основной оперативной информации (доступность, использование, применение физических ресурсов), инвентаризации и, возможно, предоставление основных методик для локализации возможных проблем.
виртуальную машину, обеспечивающую работу системы мониторинга, запускается на сервере виртуализации SC5-32-HPV01. Для этой ВМ намеренно
не используется функция кластерного резервного копирования (однако можно выборочно инициировать перемещение между хостами). Рассматриваемая
ВМ использует агрегированный физический канал и подключена к серверной
VLAN 20.
65

5.1.1

Мониторинг с помощью SNMP и агента Zabbix

Система Zabbix предлагает несколько способов мониторинга и сбора данных с целевого устройства. Первым широко распространенным является сбор
и передача данных с помощью протокола SNMP. Этот метод особенно подходит для активных сетевых элементов (коммутаторов и маршрутизаторов).
Информация о сетевом элементе передается через так называемый SNMPагент, который генерирует SNMP-сообщения и отправляет их на заранее настроенный адрес элемента мониторинга.
Чтобы добавить целевой элемент, предоставляется его описательное имя
и указывается коммуникационный интерфейс. Интерфейс всегда указывает,
по крайней мере, IP-адрес или DNS-запись для элемента. Если сбор данных
осуществляется с помощью протокола SNMP, то добавляется так называемый
интерфейс SNMP, если с помощью агента Zabbix, то добавляется соответствующая информацая в поле Agent Interface. Для наглядности рекомендуется
классифицировать добавленные элементы в зависимости от типа устройства
в соответствующие группы.
Далее назначается шаблон конфигурации для каждого устройства, который содержит определения служб и параметров, которые отслеживаются на
устройстве. В случае устройств, использующих SNMP, это обычно таблица,
определяющая OID, значения и их интерпретацию. В этом шаблоне также
указываются так называемые триггеры событий, которыми могут быть, например, предельный уровень загрузки линии или использования оперативной
памяти и т.д.
Предварительно подготовленные шаблоны могут быть далее объединены
в цепочку. Шаблон также может определять использование системного приложения для выполнения действия и последующую интерпретацию этих результатов. Примером такого шаблона является проверка доступности с помощью системного инструмента ping. Шаблоны могут быть созданы произвольно, им может быть назначено действие и метод интерпретации результатов.
Кроме того, может быть определено место обработки, например, проверка
обновлений на контролируемой машине.
66

Обычно всегда назначаются шаблоны SNMP Device и ICMP Ping для
устройств, настроенных в данной работе. Это обеспечивает проверку доступности устройства, а также мониторинг состояния устройства (общая информация - имя, контакт администратора, местоположение) и текущего использования. Однако экспериментальным путем было проверено, что значение,
опосредованное SNMPagent, показывает разброс значений в диапазоне от 10
до 15 процентов. Таким образом, информация на линии нагрузки может рассматриваться только как ориентировочная.
льтернативой мониторингу с помощью агента SNMP является использование программного клиента Zabbix Agent, который устанавливается на операционную систему контролируемой станции. Хотя компьютеры под управлением ОС Linux или Windows также можно контролировать с помощью
SNMP, использование программного клиента является более гибким. Для мониторинга базовой информации о состоянии конечных станций я намеренно
оставляю настройки в состоянии по умолчанию. Программный клиент должен быть установлен в качестве службы на компьютере под управлением
Windows, автоматически запущен и включен на TCP-порту 10050. Файл конфигурации агента для всех настроенных устройств доступен в приложении.
Программный клиент установлен на всех серверах с ОС Windows Server. Развертывание агента на рабочих станциях не реализовано, но может быть эффективно выполнено путем установки объектов групповой политики.
5.2

Резервное копирование конфигураций сетевых элементов

Большинство операционных систем, развернутых сегодня на сетевых элементах, также реализуют методы резервного копирования и передачи файлов
конфигурации с помощью TFTP, FTP и т.д. Резервное копирование и передача конфигураций с помощью установленного клиента TFTP по-прежнему
является предпочтительным выбором, даже с учетом уступающих функций
безопасности TFTP, в основном из-за его простоты. Сетевые элементы, которые предлагают графический интерфейс, обычно предлагают возможность
загрузки или восстановления конфигурации с помощью HTTP-передачи. Однако недостатком сохранения конфигураций из среды веб-браузера являет67

ся меньшая возможность автоматизации этой задачи. В следующих разделах описан принцип автоматического резервного копирования конфигураций
коммутатора с использованием как терминального доступа, так и отправки
специальных запросов с использованием протокола HTTP.
Для работы с резервными копиями я использую виртуализированную рабочую станцию SC5-32-MNG01v и виртуальный сервер SC5-32-SRV01vx. Вышеупомянутый сервер с ОС Linux в дистрибутиве Ubuntu 22.04 выполняет
функцию TFTP-сервера, где хранятся резервные копии конфигурационных
файлов, а также служит интерпретатором языка сценариев Expect. В целях
безопасности, используя программу iptables, я добавляю в ОС конфигурацию
пакетного фильтра, который предотвращает получение датаграмм TFTP из
всех IP-подсетей, кроме IP-подсети, используемой для администрирования,
подсети сервера и станции с IP 10.10.10.50 (ПК администратора). Использование iptables показано в соответствии с рисунком 5.1.

Рисунок 5.1 — Использование iptables

5.2.1 Автоматическое резервное копирование с помощью виртуального терминала
Хотя некоторые новые операционные системы сетевых устройств предлагают возможность планирования и автоматического запуска заданий резервного копирования, более старые операционные системы предлагают только
загрузку конфигурации по инициативе администратора. Метод, описанный
в этой главе, использует преимущества автоматизации взаимодействия с сетевым элементом. Для этого используется интерпретатор языка сценариев
Expect, который предназначен для взаимодействия с компьютерной системой. Запуск сценариев резервного копирования на сервере SC5-32-SRV01vx

68

настроен на повторное выполнение в 14:30 каждый день с помощью программы Cron.
Рассмотрим последовательность задач, которая приводит к успешной загрузке файла конфигурации на сервер TFTP из резервной копии элемента. Терминальный доступ почти всегда требует аутентификации. Эта аутентификация может быть выполнена, например, путем ввода пароля для используемой учетной записи или аутентификации с помощью пары закрытый/открытый ключ. Для простоты и ясности я использую метод аутентификации с помощью пароля. После входа в устройство требуется переход в
привилегированный режим. Затем пользователь получает право читать текущие конфигурации (часто называемые running-config или startup-config). Затем они могут быть загружены с помощью упомянутого выше TFTP-клиента.
Когда процесс резервного копирования завершен, администратор выходит
из системы и разрывает соединение. Для автоматизации этого процесса на
устройствах Cisco IOS используется следующая последовательность команд,
показанная в соответсвии с рисунком 5.2

Рисунок 5.2 — Загрузка файла конфигурации на сервер TFTP

69

Администратор запрашивает пароль в общей сложности два раза с момента установления соединения. После входа в привилегированный режим
делается запрос на отправку конфигурации. Далее подтверждается место назначения резервного копирования (IP-адрес или имя TFTP-сервера) и указывается имя файла, в который будет записана конфигурация. Затем следует подтверждение передачи и выход из устройства. Эти действия могут
быть полностью автоматизированы с помощью скриптов, интерпретируемых
библиотекой Expect. Сам скрипт запроса представлен соответствии с рисунком 5.3

70

Рисунок 5.3 — Скрипт отправки конфигурации
Используемая методология очевидна из содержания сценария. На первом
этапе определяются значения переменных, в которых хранится информация
об учетной записи пользователя. Затем устанавливается сеанс связи по протоколу Telnet. Интерпретатор языка Expect считывает строку символов, отправленную контрагентом, и посылает команды элементу для выполнения в
71

соответствии с введенными данными. Эти команды форматируются как одиночные символы, где конец строки, т.е. выполнение команды, соответствует
«отправке» клавиши Enter (символ ). Намеренно включается в скрипт задержки (в данном случае 1 секунда), чтобы обеспечить достаточное время
для ответа контрагента. Целесообразно вставлять искусственные задержки
после команды отправки пароля, так как аутентификация может осуществляться с помощью проверки подлинности сервером в сети, время ответа которого может достигать единиц или десятков миллисекунд. Затем выполняется
отправка на сервер с именем SC5-32-SRV01vx, подтверждается место назначения и имя файла, и сеанс завершается отправкой команды выхода из системы
по окончании отправки. Принцип резервного копирования других элементов
сети аналогичен. Для каждого элемента последовательность отправляемых
команд должна быть адаптирована в соответствии со строками, отправляемыми контрагентом.

72

ЗАКЛЮЧЕНИЕ
Дипломная работа посвящена разработке и описанию реализации совершенно новой сети передачи данных, которая реализуется в одной из лабораторий организации. В этой сети упор сделан на надежность и эффективное использование сети передачи данных для нужд преподавания предметов
с упором на изучение передовых сетевых технологий. Работа начинается с
теоретического анализа практик, которые обычно используются сегодня при
создании сетей передачи данных, и оцениваются возможности их внедрения
и реализации в сети передачи данных лаборатории.
При проектировании новой сети передачи данных идет опора в первую
очередь на знания пользователя, а затем на знания администратора существующей инфраструктуры. Этот анализ кратко обсуждается в главе 2. При
проектировании идет концентрация в основном на недостатки исходной инфраструктуры, к которым относится снижение безопасности, структуру сети
передачи данных и ее недостаточную связность. Эти выводы заставляют заново оценить возможности управления такой сетью, надзора за самими элементами и оценки эффективности использования оборудования лаборатории.
По этой причине в значительной степени внедряется виртуализация серверов и переход к многоуровневой модели сети передачи данных в сетевой
инфраструктуре. Целью этой реструктуризации является более эффективное
использование как той части, которая составляет серверную инфраструктуру, так и той, которая обеспечивает доступ к сети для конечных станций и
их пользователей. Поскольку лабораторная сеть используется для проведения большого объема разнообразных тестов, то следует попытка защитить
инфраструктуру этой сети соответствующим образом, внедряя более современные методы безопасности, особенно в пользовательском фрагменте.
К сожалению, в первоначальной сети данных не были учтены требования
к ее надежности, то есть к комплексу технических мер, ведущих к устранению
любых возникающих условий ошибки. По этой причине идет пыпытка разделить сеть данных на экспериментальную и производственную части, используя различные методы для обеспечения надежности обеих частей сети. Они
включают в себя развертывание резервных связей между ключевыми устройствами и создание альтернативных топологий для обеспечения, хотя и ценой
73

снижения пропускной способности части сети, доступность всех устройств в
сети передачи данных.
В последней части представляется система мониторинга состояния элементов сети и самих конечных устройств. Выбор этой системы идет в связи с ее простотой с точки зрения как пользователя, так и администратора.
Это обеспечивает мониторинг инфраструктуры в пределах лаборатории. На
последнем этапе идет работа с обеспечением резервного копирования конфигураций всех элементов, составляющих функциональную единицу как производственной инфраструктуры, так и экспериментальных элементов. На основании тестирования (особенно надежности и безопасности) можно считать
новую сетевую структуру функциональной и надежной.
л. с экрана. – Яз. англ.

75


