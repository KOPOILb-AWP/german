
Введение

    Сети передачи данных сегодня служат основой для развертывания совре-
менных форм связи. В зависимости от своего назначения и сложности, более
простой или более сложной реализации, сети становятся более сложными и
могут гарантировать различный уровень качества обслуживания, предлагать
большую степень избыточности или устойчивости к ошибкам. В этом случае
надежность самой сети является решающим фактором для предоставления
сервисов конечным пользователям. В этой работе описывается, проектирует-
ся и внедряется оптимизация для лабораторной сети с акцентом на изучение
сетевых технологий.
    Первая часть работы посвящена анализу и оценке возможностей реали-
зации сети передачи данных в лабораторной среде организации. Последую-
щий анализ сети начинается с описания текущего состояния с точки зрения
пользователя и администратора такой сети. Затем описываются возможно-
сти реализации этой сети с использованием приемов разбиения виртуальной
сети, сегментации подсетей и их безопасности, а также реализации поддер-
живающих элементов, обеспечивающих не только функционирование самой
инфраструктуры, но и работу оборудования, необходимого для выполнения
лабораторных заданий.
    Реализация новой инфраструктуры идет параллельно с существующей се-
тью, описанной в первой части. Происходит настройка этой «новой» сети в
соответствии с требованиями и возможностями, описанными в первой части.
В лаборатории работает большое количество устройств различных типов от
Cisco, HP, Mikrotik и других. Поэтому конфигурация каждого устройства ис-
пользует стандартизированные протоколы, что обеспечивает переносимость
конфигурации и работу инфраструктуры на других устройствах того же ти-
па.
    Одновременно с реструктуризацией лабораторной сети развертываются
новые услуги серверной инфраструктуры. В то же время, развернутые в на-
стоящее время сервисы переносятся на вновь установленное оборудование. Ре-
зультатом работы является пересмотренная концепция сетевой инфраструк-
туры, включая ее часть, предназначенную для работы с устройствам. Эта

сетевая единица впоследствии будет введена в эксплуатацию и станет вдаль-
нейшем основовной. Работа будет служить, помимо прочего, описанием прак-
тики, которая привела к вводу сети в эксплуатацию, и послужит ориентиром
для будущих сетевых администраторов в управлении и обслуживании этой
инфраструктуры.




  1   Корпоративные сети передачи данных

   Корпоративная сеть - это среда для реализации базовых сетевых служб
передачи данных и других расширенных сервисов, характерных для корпо-
ративной среды. Такая сеть, независимо от ее размера и сложности, должна
гарантировать определенный уровень надежности, безопасности, доступно-
сти услуг и, наконец, возможности для ее эффективного управления. С ро-
стом числа сервисов растут и требования к ее проектированию и управлению.
Требование взаимной интеграции сервисов и их объединения через единый
элемент управления доступом также характерно для среды предприятия.
   В большинстве случаев корпоративная сеть управляется одной организа-
цией. Если необходимо реализовать сеть передачи данных между географиче-
ски разделенными местами (например, главный офис и удаленный филиал),
то для обеспечения взаимосвязи и безопасной передачи данных между этими
сетями принято использовать, например, IP-туннели. Они могут соединять
эти удаленные сети в одну большую, кажущуюся «локальной» сеть. Одна-
ко для целей данной работы ограничимся одной географически разделенной
сетью, которая реализована в одном месте.
   Структура любой локальной сети может быть разделена на уровни в со-
ответствии со свойствами, которые реализует соответствующий уровень и его
сетевые элементы. В такой структурированной модели представлены уровень
основной сети, уровень распределения и уровень доступа. Хотя это общепри-
нятая практика, реализация каждого свойства для каждого уровня не явля-
ется строгой. В небольших сетях, таких как наша, роль уровня распределения
может быть разделена между уровнем доступа и уровнем основной сети, а
сама сеть может не содержать специального оборудования для реализации
этого уровня. Такая топология называется свернутой иерархией. Многоуров-
невый подход также выгоден с точки зрения модульности всей архитектуры и
возможности разделения сетевого оборудования в зависимости от требуемых
функций (например, PoE на коммутаторе, являющемся ядром сети, не дает
никаких преимуществ и неоправданно увеличивает цену элемента).
   Уровень доступа обеспечивает пограничные функции между сетью и ко-
нечными устройствами, такими как компьютеры, телефоны, камеры и т.д.
Устройства, предназначенные для этого уровня, обычно предлагают боль-

шее количество сетевых интерфейсов для подключения конечных устройств
и включают, например, функции безопасности для взаимодействующих узлов
(проверка ARP, DHCP snooping, функции IEEE 802.1X), функции безопасно-
сти для сетевой инфраструктуры (STP, фильтрация кадров BPDU) или PoE
для облегчения развертывания конечных узлов (телефонов, камер и т.д.).
   Уровень распределения является точкой агрегации сетевой связи между
маршрутизаторами доступа и ядром сети, где обычно располагаются клю-
чевые службы, обеспечивающие работу сетевой инфраструктуры. Резерви-
рование и агрегирование каналов связи и соответствующая защита от сбоев
отдельных каналов также является общей функцией. Также может присут-
ствовать маршрутизация между виртуальными сетями, которая может обес-
печить разделение трафика между логическими топологиями, реализован-
ными на втором уровне RM ISO/OSI. Преимуществом реализации уровня
распределения с использованием дополнительного оборудования в сетевой
топологии является, прежде всего, высокая доступность сетевых служб и
модульность конструкции.
   Уровень ядра сети состоит из мощных коммутаторов и маршрутизаторов,
которые обеспечивают связь с внешними сетями и доступ в Интернет. Ядро
сети является точкой агрегации для большей части сетевых коммуникаций,
поэтому существует требование не только к максимальной доступности, из-
быточности, но и к высокоскоростным сетевым элементам. Таким образом,
большинство каналов резервируется и подкрепляется другими сетевыми эле-
ментами, физические каналы распределяются между большим количеством
активных элементов, а каналы группируются в логические каналы со скоро-
стью порядка десятков гигабит в секунду.


   1.1   Разделение сетей передачи данных


   В сетях передачи данных любого масштаба обычно сталкиваются с актив-
ными элементами, которые обеспечивают взаимосвязь взаимодействующих
узлов как на физическом, так и на логическом уровне. К элементам, обеспечи-
вающим физическое соединение, относятся в основном коммутаторы и точки
доступа для беспроводных сетей. Эти элементы работают в большинстве сво-

ем с адресами канального уровня и поэтому коммутируют только единицы
данных. Взаимосвязь логических сетей обеспечивается маршрутизаторами,
интерфейсы которых в основном принадлежат этим взаимосвязанным сетям,
между которыми пакеты направляются на сетевом уровне, в настоящее время
в большей степени исключительно на уровне IP пакета протоколов TCP/IP.
   Очень часто используемым методом разделения сетей передачи данных
по их назначению является их взаимная изоляция на канальном уровне. Это
приводит к значительному сокращению всенаправленной широковещатель-
ной области, а также к желаемой необходимости внедрения маршрутизации
на уровне сетевого уровня. Возможности взаимной маршрутизации между се-
тями избирательно ограничиваются методами фильтрации сетевого трафика.
В следующих двух главах описываются принципы разделения физической то-
пологии с помощью маркировки кадров и реализации отдельных подсетей в
возникающих виртуальных сетях. Эти методы необходимы для разделения
различных типов устройств (серверов, рабочих станций, VoIP-устройства) и
для последующей реализации механизмов QoS.


   1.1.1   Разделение физической топологии с помощью VLAN


   Коммутаторы устраняют недостатки хабов путем развертывания процес-
сов или схем, которые обеспечивают коммутацию на основе информации, со-
держащейся в заголовке коммутируемых кадров. Заголовок каждого кадра
содержит, помимо прочего, адрес отправителя и адрес получателя, обеспе-
чивая тем самым возможность адресации коммутируемых устройств между
двумя связывающимися узлами. Коммутация кадров от одного отправителя
к нескольким получателям также очень распространена в локальных сетях.
   Сегодня в локальных сетях, реализующих многоточечные каналы связи,
часто сталкиваемся с блоками (кадрами) типа Ethernet II. В соответствии с
рисунком 1.1 , представлена структура этого кадра.




              Рисунок 1.1 — Структура кадра Ethernet II

    Структура этого кадра, показывает, среди прочего, поле, определяющее
длину или тип передаваемого протокола ( поле «управление»). Поле, опреде-
ляющее тип передаваемого протокола, может содержать заголовок протокола
802.1Q, который в основном используется для указания принадлежности кад-
ра к VLAN. Из заголовка 802.1Q коммутатор может определить, в том чис-
ле, определения параметров QoS канального уровня. Если кадр не содержит
этого значения, коммутатор может добавить его на основе заранее определен-
ных правил, перемаркировать кадр или вообще удалить метку. В простейшем
случае установка принадлежности устройств к VLAN задается на определен-
ном порту коммутатора. Если интерфейс используется для доступа только к
одной VLAN, его называют портом доступа (Access port), и наоборот, если
через этот интерфейс можно передавать кадры, принадлежащие нескольким
VLAN, то такой интерфейс называется магистральным портом (Trunk port).
    В случае использования идентификатора VLAN в кадрах говорят о теги-
рованных кадрах (Tagged Frame). Тегированные кадры обычно не встречают-
ся на интерфейсе конечной станции, так как идентификаторы чаще использу-
ются на интерфейсах, соединяющих элементы сети. Большинство драйверов
сетевых карт поддерживают добавление идентификатора VLAN непосред-
ственно в процессор сетевой карты, однако коммутаторы, на входе которых
настроен порт доступа, ожидают нетегированные кадры и аналогичным обра-
зом удаляют идентификатор VLAN из тегированного кадра перед отправкой
его на конечную станцию. На некоторых типах коммутаторов можно влиять
на реакцию коммутатора на «неожиданный» тегированный кадр на его вхо-
де - коммутатор может принять тегированный кадр, повторно тегировать его
или отбросить.


   Поле заголовка протокола 802.1Q далее делится на две записи - пер-
вые 16 бит относятся к идентификатору протокола тега TPID (Tag protocol
identifier), а младшие 16 бит - к информационным полям управляющей ин-
формации тега TCI (Tag control information). Значение TPID предваритель-
но установлено на 0x8100. Поскольку в этом месте указывается тип кадра
(биты поля TPID соответствуют положению битов поля EtherType в нетеги-
рованных кадрах), это значение сигнализирует об использовании протокола
тегирования.
    Оставшиеся 16 битов коммутатора указывают на три части информации о
том, как работать с кадром. Эти три бита служат так называемым идентифи-
катором кодовой точки приоритета PCP (Priority code point) и используются
в основном для обеспечения качества обслуживания на канальном уровне.
Значение поля может принимать до 8 значений, определяющих приоритет
единицы данных, причем 0 означает самый низкий приоритет (best effort), а
7 - самый высокий приоритет, обычно управляющий сетевым трафиком. Чет-
вертый бит устанавливает значение индикатора возможности сброса (Drop
Eligible Indicator - DEI), на основании которого коммутатор может принять
решение о сбросе кадра в случае нехватки коммутационной мощности в каче-
стве меры предосторожности против перегрузки сети. Оставшиеся 12 битов
в TCI представляют собой идентификатор VLAN (VLAN identifier), который
определяет принадлежность кадра к данной виртуальной сети канального
уровня.


   1.1.2   Сегментация на сетевом уровне


   Логические адреса IP используются для адресации коммуникаций на
интернет-уровне TCP/IP. Поскольку устройства не являются членами од-
ного и того же домена L2 после сегментации канального уровня, необходима
маршрутизация. Хотя коммутаторы L3, которые способны маршрутизиро-
вать кадры на основе данных, содержащихся в IP-пакете, сейчас устанавли-
ваются в качестве стандарта для больших сетей, в небольших сетях необходи-
мо использовать маршрутизаторы. Работа с блоками данных сетевого уровня
предоставляет несколько возможностей для выборочной фильтрации трафи-

ка, трансляции логических адресов или реализации механизмов обеспечения
качества обслуживания.
    Для логически сегментированных сетей L2 рекомендуется реализовать
схему адресации с эффективным использованием адресного пространства.
Если трафик данных из внешних сетей будет направляться в эти подсети без
преобразования адресов, целесообразно сегментировать адресное простран-
ство с учетом возможности обратного объединения (supernetting) подсетей в
одну большую сеть. Это позволит уменьшить количество записей в таблицах
маршрутизации внешних маршрутизаторов для обеспечения маршрутизации
во внутренние подсети и потенциально сэкономить вычислительные мощно-
сти маршрутизаторов.


   1.2     Отдельные службы в локальной сети


   В следующей главе описываются основные службы, которые развертыва-
ются в локальных сетях передачи данных. В частности, это службы DHCP и
DNS, которые предоставляют функции для связи с использованием интернет-
протокола IP версии 4 и версии 6. Корпоративные сети также обычно развер-
тывают функции и механизмы NAT для защиты абонентов как на граничных
элементах, так и на конечных точках.


   1.2.1    Функции DHCP


   DHCP основан на RFC 1531 и считается преемником BOOTP. Связь
DHCP основана на модели сервер-клиент, т.е. сервер отвечает на запросы
клиентов о передаче параметров конфигурации сети. Наиболее распростра-
ненными параметрами являются параметры IP-адреса запрашивающего узла,
маска сети, адрес шлюза по умолчанию этой сети и IP-адреса серверов разре-
шения имен DNS. Однако протокол DHCP предлагает и более продвинутые
возможности, в частности, передачу сетевой информации узлу и наоборот.
Эта информация передается через сообщения DHCP Options, которые пред-
ставляют собой отдельные параметры, устанавливаемые с помощью прото-


кола DHCP. В соответствии с рисунком 1.2, представлены параметры DHCP
Options.




           Рисунок 1.2 — Основные параметры DHCP Options

    Помимо основных параметров для реализации сетевого взаимодействия,
существует также возможность отправки параметров загрузчика операцион-
ной системы клиентам из сетевого расположения. Эта функция необходима
для реализованной позже службы Windows Deployment Service, которая мо-
жет использоваться для выполнения неуправляемой установки и настройки
образа операционной системы на рабочих станциях [1]. Помимо описанных
выше, многие другие функции сетевых устройств могут быть настроены с
помощью протокола DHCP, например, WINS-адреса, IRC, SMTP и т.д. Неко-
торые производители конкретных HW (VoIP/SIP-устройств) предоставляют
список используемых ими параметров DHCP для массовой передачи управ-
ляющей информации (адреса TFTP для загрузки прошивки, адреса реги-
страторов SIP).
    Поскольку IP-адреса и другие параметры «одалживаются» только на за-
ранее определенный период времени, во время связи необходимо обрабаты-
вать состояние, когда срок действия одалживания подходит к концу. Поэтому
клиентская станция обычно работает с таймерами T1 и T2. Когда истекает
половина срока действия займа (время T1), клиент DHCP пытается возобно-
вить заем, отправляя сообщение DHCP Request на исходный сервер DHCP,
который предоставил заем. Если клиент не добился успеха, после истечения
87,5% времени аренды (время T2) он снова отправляет запрос на продление
аренды. Это сообщение уже адресовано всенаправленно, и если какой-либо
сервер DHCP отклоняет запрос (клиент получает сообщение DHCP Nack),



клиент должен немедленно прекратить использование адреса и начать про-
цесс конфигурирования сети заново.
    При опросе некоторые сообщения адресуются всем получателям (широко-
вещательные пакеты). Широковещательные сообщения необходимы, в част-
ности, для определения местонахождения сервера DHCP в сети, что показы-
вает, что если сервер DHCP и клиент находятся в разных доменах широкове-
щательной рассылки, необходимо использовать другой элемент, который пе-
рехватывает сообщение на интерфейсе домена широковещательной рассылки
и перенаправляет его на адрес сервера DHCP [2].
    На первом этапе клиент обнаруживает серверы DHCP, отправляя сообще-
ние DHCP Discover на всенаправленный адрес. Все доступные DHCP-серверы
в данном домене L2 отвечают на запрос, но только если в их базе данных
есть свободный адрес, который можно предоставить клиенту. Хотя у кли-
ента в данный момент нет назначенного логического адреса, это сообщение
адресуется всенаправленно. Клиент DHCP может получить несколько пред-
ложений, поэтому он выбирает наиболее подходящий сервер на основе пред-
почтений и отправляет сообщение DHCP Request на всенаправленный адрес.
Это сообщение снова перехватывается всеми серверами DHCP - единствен-
ный выбранный сервер, который идентифицируется с запросом, затем под-
тверждает заем сообщением DHCP Ack, для других серверов запрос DHCP
Request является признаком того, что клиент выбрал другой сервер. После
успешной настройки конфигурации на клиенте запускаются таймеры T1 и
T2.
    Если сетевая подсистема клиента перезапускается (перезагрузка ОС, от-
ключение и повторное подключение к сети), а договор аренды все еще дей-
ствителен согласно таймеру клиента, клиент может использовать IP-адрес без
необходимости повторять процесс автоконфигурации. Такая ситуация обыч-
но не возникает во время запланированного выхода из сети (остановка про-
граммного обеспечения ОС) - в этом случае клиент DHCP обычно отправля-
ет сообщение DHCP Release, информируя клиентский серверу о том, что он
больше не желает использовать заем.




  1.2.2   Функции DNS


   DNS занимает важное место в современных локальных и публичных се-
тях. Ведение полной базы данных сетевых узлов в их естественном, т.е. чис-
ловом, виде сегодня практически невозможно. Однако связь в компьютер-
ных сетях осуществляется исключительно посредством IP-адресов, то есть
32- или 128-битных числовых идентификаторов, и поэтому система DNS с
точки зрения пользователя служит скорее инструментом, помогающим уз-
лам сети присвоить легко запоминающееся имя.
   DNS - это прикладной протокол, который использует транспортные про-
токолы UDP 53 и TCP 53 на стороне сервера. Он использует модели связи
клиент-сервер и сервер-сервер. Транспортный протокол UDP используется
для «нормальной передачи» клиентских запросов, в основном из-за его быст-
рого времени отклика. Надежность передачи здесь обычно не требуется, воз-
можная ошибка передачи DNS обычно компенсируется клиентом путем от-
правки нескольких запросов к нескольким DNS-серверам за очень короткое
время. Напротив, связь, ориентированная на соединение, с использованием
протокола TCP требуется при так называемой передаче зон, то есть передаче
и синхронизации информационной базы между самими DNS-серверами, где,
наоборот, надежность передачи желательнее скорости передачи.
   Поскольку подробный анализ взаимодействия DNS-сервера с клиентами
выходит за рамки данной работы, ниже перечислены только наиболее распро-
страненные типы используемых записей DNS. Эти записи бывают следующих
типов:
    - A, или AAAA - запись сопоставляющая доменное имя с IPv4, или IPv6
      адресом.
    - CNAME - каноническое имя (псевдоним), ссылающееся на другую за-
      пись.
    - MX - запись, указывающая на IP почтового сервера для домена.
    - PTR - запись, сопоставляющая IP-адрес с доменным именем (обратный
      поиск)
   Точность и своевременность информации, предоставляемой DNS-
сервером, является одним из необходимых условий для функционирования

корпоративной сети, основанной на службах Active Directory [3]. DNS-серверы
также могут быть настроены для обеспечения балансировки нагрузки на
нужную станцию или сервер. По запросу клиента для «перевода» имени в
IP-адрес оно может быть выбрано из нескольких узлов, доступных под одним
и тем же именем. В этой работе используются только номинальные названия
для идентификации станций.


   1.3     Безопасность и надежность в локальной сети


   В современных установках сетей передачи данных довольно часто мож-
но увидеть множественные соединения двух сетевых объектов, то есть ме-
тод, при котором несколько физических соединений создают одно логическое.
Аналогичным образом, сегодня довольно распространено внедрение механиз-
мов безопасности для защиты сети передачи данных и ее участников. Сле-
дующий раздел служит кратким описанием метода объединения физических
линий и описанием выбранных методов обеспечения безопасности логической
топологии сети. Поскольку описание других доступных механизмов выходит
за рамки данного текста, я привожу здесь лишь краткий список тех, конфи-
гурация которых предпочтительна в диссертации. В основном это функции,
настроенные на коммутаторах доступа. Это функции защиты от атаки пере-
полнения, защиты от фальсификации записей ARP-таблиц участников сети
и фильтрации сообщений неавторизованного DHCP-сервера в сети. Примеры
настройки и маркировки отдельных функций могут варьироваться в зави-
симости от производителя устройства, в данной работе приведены примеры
настройки для устройств Cisco, работающих под управлением операционной
системы Cisco IOS [5].


   1.3.1    Агрегация соединений согласно IEEE 802.1AX


   Агрегирование интерфейсов стало распространенной практикой для эф-
фективного использования нескольких доступных каналов между двумя точ-
ками сети. Хотя эта техника чаще всего используется между сетевыми эле-


ментами, образующими сетевую инфраструктуру, сегодня принцип агрегации
нескольких сетевых интерфейсов также применяется на конечных устрой-
ствах сети передачи данных, обычно серверах, требующих более высокой
пропускной способности для доступа к сети передачи данных.
    Для агрегации нескольких доступных интерфейсов в современные опера-
ционные системы интегрирована так называемая функция «NIC Teaming»,
которая часто может агрегировать соединения без прямой поддержки со сто-
роны коммутатора. Однако в своей работе я использую исключительно «аг-
регацию с помощью коммутатора». агрегацию с помощью протокола LACP
(Link Aggregation Control Protocol).
    Первоначально этот протокол был определен в рекомендации IEEE 802.3
ad, но сегодня он является частью пересмотренной рекомендации IEEE 802.1
AX. В отличие от фирменных протоколов отдельных производителей, таких
как Cisco PAgP или Juniper Aggregated Ethernet, этот стандарт IEEE реали-
зуется независимо от производителя устройства, даже на активных элемен-
тах от производителей, предлагающих собственные решения по агрегации.
По этой причине его использование целесообразно в средах, где развернуто
несколько устройств от разных производителей.
    Рассмотрим коммутаторы SW1 и SW2, пусть каждый из них сможет на-
значить два физических соединения со скоростью 1 Гбит/с для объединен-
ного канала. Таким образом, максимальная теоретически достижимая про-
пускная способность в результирующем соединении составляет V = 2 Гбит/с,
поскольку

где n - количество физических портов в канале, а υ - скорость каждого от-
дельного порта. Число n связанных портов обычно составляет от 1 до 8, а
скорость каждого интерфейса должна быть одинаковой для всех участни-
ков логического канала. Этот метод также обеспечивает определенную сте-
пень устойчивости к сбоям канала, поскольку в случае отказа любого из ин-
терфейсов, участвующих в логическом канале, агрегированный канал может
продолжать работать, даже если он состоит из одного физического канала.



  LACP обычно настраивается в активном или пассивном режиме на сете-
вом устройстве. Когда вспомогательный интерфейс настроен как активный,
устройство повторно транслирует кадры LACPDU и активно запрашивает
контрагента для согласования логического канала. Противоположностью ак-
тивного режима является пассивный режим – в этом режиме устройство при-
нимает только управляющие кадры LACP, и согласование логического кана-
ла происходит только тогда, когда принимается вызов от устройства, пере-
дающего в активном режиме. В течение периода обнаружения, т.е. времени,
когда ни один логический канал не согласован на данном интерфейсе, кадры
LACP транслируются с периодом в 1 секунду, а затем так называемые кадры
«обслуживания» транслируются с периодом в 30 секунд для поддержания
логического канала.


   1.3.2   Предотвращение атаки переполнения


    Коммутаторы создают таблицы привязки MAC-адресов и членства в
VLAN для устройств, подключенных к портам коммутатора, в зависимости
от полученных кадров. Это позволяет адресовать кадры только назначен-
ным станциям. Атака переполнения использует ограниченный объем памяти
коммутатора путем отправки большого количества кадров с поддельными
MAC-адресами источников, которые коммутатор последовательно записыва-
ет в свою таблицу коммутации [6]. Эти записи хранятся в течение ограни-
ченного периода времени - обычно 300 секунд. По истечении этого периода
времени или при перезагрузке коммутатора эта информация удаляется. В тот
момент, когда память коммутатора исчерпана и, следовательно, больше нет
возможности хранить записи в таблице MAC-адресов, коммутатор переходит
в состояние полной пересылки, где его функция близка к функции хаба. Что-
бы не прерывать связь, коммутатор посылает кадры даже на интерфейсы, где
нет целевого устройства. Таким образом, кадры, адресованные другому уз-
лу сети, пересылаются на станцию злоумышленника. Защита от этого типа
атак заключается в установке ограничения на количество активных MAC-
адресов, которые могут быть зарегистрированы на одном интерфейсе комму-
татора, или в прямом указании значений MAC-адресов, которые могут быть

зарегистрированы на данном интерфейсе в таблице коммутатора [6]. В соот-
ветствии с рисунком 1.3, показан пример конфигурации доступа для интер-
фейса F a0/1 коммутатора SW1, которая не допускает более 2 MAC-адресов,
связанных с этим интерфейсом, и отключает интерфейс при нарушении этой
политики:




           Рисунок 1.3 — Политика ограничения MAC-адресов

   Опционально можно указать исходные MAC-адреса, которые будут вне-
сены в базу данных коммутации коммутатора, если они встречаются на дан-
ном интерфейсе. Оставшиеся или неуказанные адреса будут добавлены в базу
данных коммутации при условии, что не будет нарушен установленный вы-
ше предел активных MAC-адресов на интерфейсе. Эта функция подходит,
например, для соединения телефонного устройства и компьютера на одном
интерфейсе коммутатора, или может быть использована для предотвраще-
ния возможности соединения, например, небезопасной виртуальной станции
с мостовым сетевым интерфейсом.


   1.3.3   Проверка достоверности блоков данных протокола ARP


   Для того чтобы обеспечить связь между двумя клиентами в локальных
сетях Ethernet на основе их IP-адресов, необходимо развернуть механизмы
сопоставления физических адресов (MAC-адрес интерфейса) с логическими
адресами сетевого уровня (IP-адресами). Чтобы эту таблицу привязки не
приходилось настраивать вручную на каждой станции и сетевом элементе,
особенно в больших сетях передачи данных, она опирается на поддержива-
ющие протоколы ARP ((Address Resolution Protocol)) или ICMPv6 (Neighbor
Discovery). ARP - это протокол без статических данных, определенный в RFC
826 и обеспечивающий «преобразование» IP-адреса станции в ее MAC-адрес.


   Станция обычно регистрирует и обрабатывает ARP-ответы, даже если
она сама не посылала ARP-запрос. Это позволяет контролируемым обра-
зом внести нелегитимную (ложную) информацию в таблицу привязки ад-
ресов каналов и сетей на станции-жертве. Затем связь жертвы в данной сети
Ethernet переключается на интерфейс коммутатора, имеющего соответству-
ющий MAC-адрес целевой станции.
    Способом защиты от этого типа атак является функция сетевого элемента,
создающая таблицу привязки только реальных, т. е. легитимных IP-адресов и
легитимных MAC-адресов. Эта функция обеспечивается механизмом под на-
званием Dynamic ARP Inspection, сокращенно DAI. Все кадры, содержащие
запрос или ответ ARP, перехватываются и анализируются блоком управле-
ния коммутатора. В частности, это проверка информации, содержащейся в
блоке данных протокола ARP. Эта проверка производится коммутатором по
собственной доверенной базе данных, которую он динамически наполняет
информацией (на основе работы механизма DHCP Snooping) или в которую
администратор данного сетевого элемента вводит статические данные. Метод
ввода статических данных особенно удобен, если в данной сети есть элементы
со статической конфигурацией протокола IP. Как правило, настройка DHCP
для этих станций не производится, и коммутатор не сможет захватить эту
связь между линией и сетевым адресом с помощью функций DHCP Snooping.
    Если коммутатор оценивает информацию в блоках данных протокола
ARP как достоверную, он использует ее для обновления своей собственной
таблицы коммутации, а затем пересылает кадр на соответствующий выход-
ной интерфейс. В противном случае кадр, содержащий блок протокола ARP,
уничтожается. В соответствии с рисунком 1.4, приведен пример конфигура-
ции DAI на коммутаторе SW1 для проверки пакетов ARP, распространяемых
в VLAN с VID 10.




          Рисунок 1.4 — Конфигурация DAI на коммутаторе SW1

   Приведенная выше конфигурация устанавливает проверку достоверности
распространяемой информации ARP глобально для VLAN 10. Впоследствии
доверие устанавливается для интерфейса GigabitEthernet 0/1, поэтому про-
верка единиц данных протокола ARP на этом интерфейсе не производится.


   1.3.4   Проверка валидности сервера DHCP


   В корпоративных сетях централизованно управляется не только частное
адресное пространство. В то же время необходимо предотвратить подключе-
ние неавторизованного DHCP-сервера к компьютерной сети, чтобы избежать
раздачи недействительных или конфликтующих IP-адресов клиентам сети. С
этой целью вводятся функции, особенно на коммутаторах доступа, для огра-
ничения распространения определенных типов сообщений DHCP. Функция,
контролирующая или ограничивающая распространение сообщений DHCP в
соответствии с интерфейсом источника, на современных сетевых элементах
называется DHCP snooping.
   Администратор сетевого элемента указывает порты коммутатора, через
которые пакет DHCP Offer может распространяться в сети Ethernet (для кон-
кретной сети VLAN это может быть указано по-другому). Опять же, в упро-
щенном виде, сообщение DHCP Offer от неавторизованного DHCP-сервера
отбрасывается на входном порту коммутатора и никогда не переключается
на выходной интерфейс к станции, которая сгенерировала сообщение DHCP
Discover. Настройка уровня доверия порта коммутатора показаны в соответ-
ствии с рисунком 1.5.



Рисунок 1.5 — Обозначения интерфейсов коммутатора для DHCP Snooping

   Пусть интерфейсы F a0/1 коммутаторов SW1 и SW2 являются интерфей-
сами доступа для рабочих станций в сети. Эти интерфейсы настроены адми-
нистратором коммутатора как недоверенные. И наоборот, интерфейсы, к ко-
торым подключен авторизованный DHCP-сервер, или интерфейсы, которые
подключаются к DHCP-серверу через промежуточный элемент, помечаются
как доверенные. Если поддельный DHCP-сервер на станции злоумышленника
перехватывает всенаправленное сообщение DHCP Discover и генерирует ответ
DHCP Offer, коммутатор SW2 выполняет настроенное действие на интерфей-
се F a0/1, например, отсоединяет (выключает) интерфейс коммутатора.
   Пример конфигурации коммутатора SW2, который активирует DHCP
snooping глобально, то есть на всех интерфейсах и виртуальной сети пред-
ставлен в соответствии с рисунком 1.6 .




          Рисунок 1.6 — Глобальная активация DHCP snooping

   Затем, в соответствии с рисунком 1.7, необходимо указать доверенные
интерфейсы, например Gi0/2:




            Рисунок 1.7 — Указание доверенного интерфейса


  Правильная настройка механизма DHCP snooping на коммутаторах до-
ступа является необходимым условием для эффективной защиты с помощью
механизмов Dynamic ARP Inspection. Эти функции обычно настраиваются
на интерфейсах доступа коммутатора, к портам которого подключаются ко-
нечные устройства клиентов.


   1.3.5   Фильтрация единиц данных с помощью ACL


    Очень часто в сетях передачи данных требуется контролировать трафик
между определенными IP-подсетями. В случае с лабораторной сетью, напри-
мер, доступ к сети, в которой расположен административный интерфейс, со
станций на рабочих местах сотрудников крайне нежелателен. По этой при-
чине современные сетевые элементы, например, коммутаторы и маршрути-
заторы, позволяют создавать так называемые «списки контроля доступа»,
которые в простейшем случае определяют исходную сеть, целевую сеть (воз-
можно, также протоколы транспортного уровня) и правила, в соответствии
с которым устройство обрабатывает данные. В случае нашей сети переда-
чи данных это простейшие правила для разрешения или отказа в доступе, то
есть для определения того, будет ли пакет принят и направлен по интерфейсу
или будет уничтожен [7].
    Обычно на устройствах Cisco IOS можно создавать ACL двух типов: стан-
дартные и расширенные. Стандартный ACL учитывает только адрес станции-
источника и выполняет определенное действие. С другой стороны, так назы-
ваемый расширенный ACL может использоваться для более «конкретной»
спецификации единиц данных, т.е., например, для предотвращения трафика
по определенным транспортным адресам и т.д. Списки контроля доступа при-
меняются к определенному интерфейсу и в определенном направлении (вход
или выход), их правила проходят последовательно от первого к последнему,
а последнее правило каждого ACL - это правило уничтожения трафика, ко-
торый не был разрешен или уничтожен на основании любого предыдущего
правила.




  1.4     Серверные и сетевые службы Microsoft


   Следующие главы посвящены описанию избранных технологий и сервер-
ных служб Microsoft, которые в настоящее время реализованы в лаборатор-
ной среде. Продукты этой компании выбирают в основном из-за их надежно-
сти, производительности и возможностей администрирования. Существуют
также альтернативы для отдельных продуктов, например, для виртуализа-
ции серверов предлагаются продукты из серии vSphere конкурирующей ком-
пании VMware. Службы каталогов также могут быть реализованы с исполь-
зованием свободно доступных альтернатив, таких как сервер OpenLDAP.


   1.4.1    Виртуализация серверов Hyper-V


   Hyper-V — это роль операционной системы Windows Server в версии 2008
R2 и более поздних. Эта роль дает возможность управлять несколькими вир-
туальными системами на одном физическом сервере, который называется
хостом виртуализации. Аппаратное обеспечение хост-сервера обычно полно-
стью предназначено для работы только роли виртуализации, и никакая дру-
гая роль не развертывается. Целью виртуализации серверов часто является
создание уровня, который предлагает определенную абстракцию оборудова-
ния, на котором работает виртуальная машина (сокращенно VM от англ.
Virtual Machine), и ее операционной системы, которая является посредником
в требуемой службе — например, контроллере домена, веб-сервере и т. д. Та-
ким образом, физический сервер де-факто становится многоцелевым устрой-
ством, на котором могут работать серверные сетевые службы, веб-сайты или
службы файлового сервера. Хотя можно было бы запускать эти роли в одном
экземпляре операционной системы, разделение этих ролей является рекомен-
дуемой практикой как с точки зрения производительности, так и с точки
зрения безопасности серверной инфраструктуры [8].
   После установки роли Hyper-V на физическом сервере реализуется архи-
тектура, которая показана в соответствии с рисунком 1.8.



       Рисунок 1.8 — Многоуровневая архитектура хоста Hyper-V

   На схеме архитектуры виртуализации показано развертывание уровня ги-
первизора непосредственно на физическом оборудовании и его соединение че-
рез шину виртуализации VMBus, которая опосредует доступ операционных
систем к аппаратному обеспечению хоста. Этот принцип аналогичен общей
многоуровневой архитектуре операционных систем. Операционная система,
выполняющая роль сервера Hyper-V, становится поставщиком всех необхо-
димых операционных процессов и служб для запуска виртуальных машин
(поставщик объектов WMI, запуск процессов и служб) и становится так на-
зываемым родительским разделом. Затем отдельные виртуальные машины
устанавливаются в так называемые дочерние разделы. В зависимости от спо-
собности операционной системы работать в виртуализированном режиме, до-
ступ и взаимодействие отдельных виртуальных машин через шину виртуали-
зации VMBus различаются. Доступ к этой шине обычно обеспечивается ин-
теграционными компонентами Hyper-V, который доступен для большинства
современных операционных систем.



  Перед установкой сервера Hyper-V необходимо учитывать не только тре-
бования самой операционной системы, но и требования работающих в ней
виртуальных систем. Из модели уровня видно, что работающие в ней вир-
туальные машины также конкурируют за ресурсы физического сервера, и
для оптимальной работы необходимо обеспечить зарезервированный доступ
к физическим ресурсам. Этого можно добиться в Hyper-V за счет резерви-
рования ядер ЦП, предоставления минимального и максимального объема
памяти, доступной для ВМ, и возможности распределять дисковые контей-
неры по нескольким физическим дискам или дисковому массиву.
   Помимо общих требований операционной системы (в нашем случае
Windows Server 2016), поддержки 64-битных процессорных инструкций, под-
держки технологий виртуализации Intel VT или AMD-V и поддержки защиты
сегментов данных в машинном коде, т.е. Предотвращение выполнения, реали-
зованное с использованием битовой технологии Intel XD, требуется бит AMD
NX или.


   1.4.2   Доменные службы Active Directory


   Доменные службы и службы каталогов, как правило, являются основой
инфраструктуры предприятий любого размера. В нашем случае речь идет о
реализации службы каталогов Microsoft, которая основана на стандарте X.500
и протоколе LDAP. Эта служба (Active Directory Domain Services, сокращенно
AD DS) выступает в качестве централизованного хранилища объектов, содер-
жащихся в базе данных AD DS. Эта база данных содержит информацию о
пользователях, группах, компьютерах, топологии сети, а также записи DNS
и аренды DHCP. Однако основной целью является аутентификация личности
(пользователей и компьютеров), авторизация (контроль доступа к) ресурсам
и их извлечение.
   Роль AD DS предоставляет основные службы домена и каталогов, но вы
можете установить множество других ролей в структуре Active Directory, ко-
торые используют структуры, реализованные ролью AD DS. К ним относятся
службы AD CA, службы федерации, службы разрешений и другие. В нашем
случае, однако, будут использоваться только «базовые» роли AD DS, осо-

бенно для хранения идентификационных данных, управления объектами и
совместного использования ресурсов.
    Active Directory представляет несколько логических компонентов в се-
тевой инфраструктуре. Это домены, деревья, леса, OUs и местоположения.
Упрощенно эти компоненты можно охарактеризовать как области действия
определенных правил. Разработка доменной структуры требует значительно-
го объема планирования, особенно когда речь идет об определении групповых
политик (массовая и централизованная настройка ОС Windows), назначении
членства в группах безопасности (авторизация), а также о более сложных
задачах, таких как установление так называемых доверительных отношений
с другими доменами [9].
    Доменные службы Active Directory развертываются в существующей сети
передачи данных, включая интеграцию рабочих станций в доменную струк-
туру. Любое вмешательство в конфигурацию рабочих станций выходит за
рамки данного текста и не рассматривается при проектировании сети пере-
дачи данных. Более подробное описание выходит за рамки данной работы, и
в следующих главах будут только описаны и обоснованы конкретные конфи-
гурации.


   1.4.3   Удаленное администрирование ОС Windows


   И серверные, и компьютерные версии ОС Windows поставляются в стан-
дартной комплектации с множеством инструментов и опций для эффектив-
ного и удаленного управления. Поскольку, начиная с версии 2012, рекоменду-
ется использовать серверные версии без графических интерфейсов, необходи-
мо развернуть методы удаленного администрирования операционной систе-
мы и ее ролей в ОС. Для этого можно использовать несколько инструментов
для подключения через «службу терминалов», или Remote Desktop. Одна-
ко на серверах, где не установлены графические инструменты, администра-
тору обычно предлагается только командный интерпретатор или Windows
Powershell, что делает Remote Desktop относительно ненужным для этих
нужд.


  По описанной выше причине ОС Windows снабжена набором инструмен-
тов, которые в совокупности образуют службу удаленного управления ОС
Windows (WinRM). В основе этих инструментов лежит так называемый про-
токол WS-Management. Этот текстовый протокол основан на реализации мо-
дели SOAP для передачи информации в формате данных XML. В отличие от
типа объекта, например, при использовании WMI. WS Management Protocol
также может использоваться в сторонних приложениях, т.е. не только в сред-
ствах администрирования, входящих в состав ОС Windows. Источником его
данных может быть уже упомянутый провайдер WMI, с помощью которого
можно получить доступ к ряду сведений о самом аппаратном обеспечении,
таких как версия BIOS, производственные и серийные номера и другая ин-
формация. Эти данные в основном собираются потенциальными клиентами
систем наблюдения.
   Однако с точки зрения администратора операционной системы Windows
наиболее удобным методом удаленного администрирования является воз-
можность удаленного подключения к сеансу командного интерпретатора
Windows Powershell. Это достигается путем включения функции «Powershell
Remoting», которая автоматически включается при включении компонен-
та Windows Remote Management. Это позволяет администратору не только
обращаться к удаленным операционным системам в командах и сценариях
Windows Powershell, но и получать доступ к экземпляру самого командного
интерпретатора, запущенного на удаленной операционной системе.




  2     Лабораторная сетевая среда

   Следующая глава посвящена описанию текущей топологии и представ-
ленных в ней устройств. Также оцениваются преимущества и недостатки ло-
гической структуры сети и функционирующих в ней сервисов. Лаборатор-
ная сеть обеспечивает передачу блоков данных в отдельных сетях VLAN,
специфичных для каждого рабочего места. Затем эти VLAN передаются на
коммутатор, соединяющий физические экспериментальные устройства. Экс-
периментальные VLAN с VID в диапазоне 330–360 передаются только с ис-
пользованием тегированных кадров. Таким образом, экспериментальные се-
ти представляют собой совершенно отдельную часть лабораторной сети, и их
взаимосвязь обычно нежелательна. Эти сети могут содержать большое коли-
чество неправильно защищенных рабочих станций, неправильно настроенных
сетевых устройств, а их взаимосвязь может нарушить работу лабораторной
сети (например, неправильно настроенный STP) [10].
   Поскольку коммутатор в стойке экспериментального оборудования обес-
печивает только коммутацию кадров между элементами лабораторных зада-
ний, его конфигурация должна обеспечивать полностью прозрачную пере-
дачу без каких-либо помех для передаваемых данных. Поэтому не должно
быть никаких механизмов фильтрации, QoS и т.д. Выполнение эксперимен-
тальных заданий и возможность их выполнения - главное требование к вновь
проектируемой сети передачи данных.


   2.1    Инфраструктура лабораторной сети


   В настоящее время в сети передачи данных используется один маршрути-
затор и четыре коммутатора. Для простоты будем использовать символиче-
скую маркировку элементов сети и подключенных физических и виртуаль-
ных станций.
   Пусть R1 формирует граничный маршрутизатор лабораторной подсети,
выполняет трансляцию адресов сетевого уровня и выборочную трансляцию
адресов транспортного уровня. На маршрутизаторе определена только од-
на локальная сеть, которая распространяется на первый коммутатор SW1 с
использованием нетегированных кадров. На этом коммутаторе уже опреде-

лены определенные виртуальные сети (VLAN), которые выборочно назнача-
ются отдельным интерфейсам. Однако отделение так называемых обучаю-
щих VLAN от экспериментальных, т.е. виртуальных сетей, между которыми
маршрутизация не происходит и зарезервированы для нужд лабораторных
задач, здесь реализовано не оптимально. На SW1 VLAN по умолчанию с
VID 1 практически не используется, а все устройства, которые подключа-
ются к лабораторной сети (не конкретной экспериментальной), подключа-
ются к интерфейсу, который служит точкой доступа для VLAN с VID 310.
Затем эти устройства члены одной IP-подсети, чей адресуемый интерфейс
шлюза по умолчанию находится на граничном маршрутизаторе R1 член сети
Ethernet по умолчанию с VLAN VID 1. По этой причине необходимо удалить
тег VLAN из заголовков кадров переключается на исходящий интерфейс на
R1, а в обратном направлении, то есть при передаче от R1 на SW1, все кадры
маркируются согласно 802.1Q и указывают поле VID со значением 310.
   Другой коммутатор, SW2, напрямую подключен к SW1. Интерфейс, со-
единяющий второй коммутатор с SW1, настроен так же, как и связь между
R1 и SW1. Кадры, назначенные VLAN с VID 310 на SW1, снова лишаются
этой метки и отправляются на интерфейс, соединяющий SW2, где они больше
не включаются в какой-либо конкретный VLAN и остаются в родном VLAN.
   Учитывая этот факт, можно сделать вывод, что одна IP-подсеть неэф-
фективно распределена между отдельными виртуальными локальными сетя-
ми и определена на R1, SW1 и SW2 с несогласованными идентификаторами
VLAN. Когда станция, подключенная к коммутатору SW2, передает кадр,
который коммутируется на интерфейсе между SW2 и SW1, а затем на R1
(обычно, когда инкапсулированный пакет направляется за пределы подсе-
ти лаборатории), происходит тройная маркировка кадра IEEE 802.1Q. От-
носительно ненужная повторная маркировка кадра вызывает необходимость
вычисления новой контрольной суммы в поле FCS кадра, расходуя вычис-
лительную мощность всех участвующих коммутаторов. IP-подсеть, управля-
емая таким образом, является единственной обучающей подсетью, а также
служит для доступа к интерфейсам конфигурации всех сетевых элементов,
KVM-устройств, встроенных интерфейсов управления серверами и других



устройств, использующих протокол IP. В соответствии с рисунком 2.1, пока-
зана полная символическая схема элементов лаборатории.




    Рисунок 2.1 — Полная символическая схема элементов лаборатории

   Здесь показано подключение нескольких виртуальных рабочих станций,
которые виртуализируются как на конечных рабочих станциях, так и на вы-
деленном сервере виртуализации. Эти виртуальные машины включены почти
исключительно в экспериментальные виртуальные локальные сети. Для до-
ступа к экспериментальным виртуальным сетям рабочие станции использу-
ют комбинацию тегированного и нетегированного трафика, принимаемого на
соответствующем интерфейсе коммутатора. Нетегированные кадры интегри-
руются в обучающую VLAN с VID 310 и VID 1, соответственно, а тегирован-
ные кадры интегрируются непосредственно в VLAN, для которой коммутатор
ожидает кадры на этом интерфейсе.
   В случае виртуализации на выделенном сервере используется выделенная
сетевая карта, подключенная к интерфейсу, на котором коммутатор ожидает
тегированные кадры для виртуальных локальных сетей.




  2.1.1   Доступность виртуальных сетей


   Как упоминалось в предыдущем разделе, рабочие станции обеспечивают,
помимо прочего, доступ виртуальных машин к экспериментальным VLAN,
которые направляются на коммутатор SW4 через тегированные кадры на
магистральных интерфейсах. Рисунок 2.1 показывает циклическое соедине-
ние коммутаторов SW1 - SW4, что создает риск переполнения кадров. Однако
такая ситуация не возникает по следующим причинам:
    - VLAN с VID 1 не распространяется между SW2 и SW4.
    - на канале между SW1 и SW3 VLAN с VID 310 и другие эксперимен-
      тальные VLAN распространяются с помощью тегированных кадров.
    - VLAN 310 распространяется с помощью нетегированных кадров на ин-
      терфейсе доступа между SW3 и SW4, где ей назначается действитель-
      ный IP-адрес.
    - Только экспериментальные VLAN передаются между SW2 и SW4 с ис-
      пользованием тегированных кадров.
   В то время как вышеизложенное может быть простым решением для
устранения петли в сети без использования сложных протоколов управле-
ния, коммутатор SW3 теряет свое значение в топологии, поскольку к нему
не подключены экспериментальные устройства и он не используется для рас-
пространения экспериментальных VLAN. Также необходимо учитывать воз-
можный поток кадров в сети для отдельных сетей VLAN. Рассмотрим два
сценария, показанные в соответствии с рисунком 2.2.




   Рисунок 2.2 — Распространение кадров по принадлежности к VLAN

  Первый сценарий представляет собой распространение кадров по сети в
случае, когда станция PC1 посылает кадры на всенаправленный адрес. Из-за
особенностей реализации сети Ethernet часто может происходить ненужное
или нежелательное распространение этих кадров по сети. По мере увеличения
количества устройств в сети увеличивается процент нагрузки на сеть, кото-
рый приходится на поток кадров, отправленных на всенаправленный адрес.
Кроме того, можно ожидать неоптимального использования вычислительных
ресурсов сетевых устройств, которые в соответствии с определенными пра-
вилами должны выполнять перемаркировку Поля 802.1Q для каждого кадра
обучающей VLAN, распространяемого за пределы коммутатора SW1 [11].
   Второй сценарий показывает связь виртуальной станции с одноранговым
узлом в экспериментальной сети VLAN. Этот сценарий показывает физи-
ческое соединение элементов, составляющих часть топологии, описанной в
лабораторном задании. На рисунке показано неоптимальное использование
соединений и самих коммутаторов, т.к. для связи между VM1 и VM2, что
демонстрируется с использованием маршрутизаторов LAB1 и LAB2 в соста-
ве задачи, возникает нагрузка на остальные три промежуточных элемента
физической топологии.


   2.1.2   Свойства экспериментальных топологий


   Виртуализированные рабочие станции и серверы широко используются в
лабораторных задачах и часто подключаются к физическим элементам, кото-
рые являются предметом лабораторных задач. Подключение лабораторного
экспериментального оборудования обеспечивается главным коммутатором в
стойке R3, который далее подключен к коммутатору, обеспечивающему под-
ключение к физическим рабочим станциям и серверам.
   В топологии, представленной в задаче, используются рабочие станции,
устройства IP-телефонии и серверы, которые подключены к физическим эле-
ментам сети. Описанная логическая топология проиллюстрирована с помо-
щью упрощенной диаграммы с символической маркировкой, в соответствии
с рисунком 2.3.


        Рисунок 2.3 — Логическая топология для лаборатории

   Изображенная топология экспериментальной площадки соответствует
физической топологии с использованием виртуализированных станций в со-
ответствии с рисунком 2.4 иллюстрирующем символическую схему.




        Рисунок 2.4 — Фактическая схема подключения устройств

   Для наглядности схемы сохранены символические обозначения элемен-
тов лаборатории и полные наименования используемых устройств, которые
формируют физическую топологию сети. Таким образом, очевидно, что ко-
гда виртуальные машины взаимодействуют с использованием физического

лабораторного оборудования, между элементами лаборатории и виртуаль-
ными машинами возникает избыточный трафик. Это явление возникает из-
за неправильно выбранной точки подключения сервера виртуализации, даже
когда VM2 и S1 или другие элементы общаются друг с другом, то есть элемен-
ты, которые, казалось бы, подключены к одному физическому коммутатору
в топологии лабораторной сети.
    В связи с характером лабораторных заданий этот недостаток можно
устранить, подключив сервер виртуализации непосредственно к интерфей-
су лабораторного коммутатора SW3 (HP ProCurve 2650). Это позволяет из-
бежать необходимости дважды передавать данные по каналу связи между
коммутаторами SW1, SW2 и SW3 для обеспечения односторонней связи [12].
    Кроме того, необходимо рассмотреть ситуацию, когда в рамках лабора-
торного задания физическая рабочая станция общается с контрагентом в
обучающей VLAN. В этом случае и программный клиент, и аппаратный теле-
фон подключаются к программной IP-АТС на виртуальном сервере. Однако
все устройства назначаются одной и той же VLAN, и маршрутизация меж-
ду IP-подсетями отсутствует. Основной проблемой здесь является подклю-
чение сервера виртуализации, которое реализовано с использованием того
же транкового соединения, которое обеспечивает доступность других экспе-
риментальных VLAN для сервера виртуализации. Так как все эксперимен-
тальные и обучающие VLAN подключены к этому серверу по единому лин-
ку, то весьма вероятно, что из-за чрезмерного использования этого линка и
неактивной поддержки параметров QoS на коммутаторе доступа результаты
лабораторного задания окажутся негативными. Решением этого недостатка
может быть использование отдельных соединений между «серверным» ком-
мутатором и хостом виртуализации для обслуживания экспериментальной и
обучающей VLAN или перемещение виртуализированных серверов, которые
должны быть подключены к обучающей VLAN, на другой сервер виртуали-
зации, который используется исключительно для подключения устройств в
виртуальной сети.




  3   Новая архитектура сети передачи данных

    Сеть передачи данных, описываемая в данной дипломной работе, должна
служить основой для выполнения большого количества лабораторных зада-
ний в тестирования, но в то же время должна обеспечивать доступ к осталь-
ной рабочей сети и сети Интернет, должна обеспечивать доступ к некоторым
более продвинутым сервисам, обычно используемым в корпоративной среде,
и в то же время гарантировать определенную степень надежности. Посколь-
ку доступно несколько активных сетевых элементов и передовых серверных
технологий, в работе также учитывается возможность включения этих эле-
ментов в окончательный проект.
    Новая модель сети передачи данных создается в течение летнего семестра
параллельно с лабораторией. По этой причине здесь используется совершен-
но отдельный коммутатор Cisco WS3750X-48P, настроенный на роль главного
коммутатора, образующего ядро сети. В нем, помимо прочего, имеется 48 ин-
терфейсов 1000BASE-T, которые соединяют не только пограничный маршру-
тизатор, но и другие коммутаторы доступа. Установленная версия операци-
онной системы Cisco IOS включает, среди прочего, пакет ipservices, который
делает коммутатор пригодным для предоставления основных услуг на базе
IP (коммутация L3, создание и применение ACL, агент DHCP Relay и т.д.).
    Благодаря использованию коммутатора L3 в ядре сети, топология стано-
вится очень гибкой и формирует основу для новой сети передачи данных со
следующими требованиями:
    - Подключение рабочих станций через сеть Ethernet.
    - Подключение лабораторного оборудования через сеть Ethernet.
    - Защищенный доступ к рабочей сети и Интернету для ПК.
    - Изолированное подключение L2/L3 для лабораторных рабочих стан-
      ций.
    - Резервное подключение с использованием агрегированных каналов.
    - Устранение недостатков, описанных в предыдущей главе.
    В сети передачи данных, которая будет функционировать в лаборатории
для реализации обучения, необходимо обеспечить сетевой доступ для 24 ра-
бочих станций, которые составляют основу каждого рабочего места в лабо-
ратории. Каждая рабочая станция оснащена сетевым интерфейсом, который

используется для доступа к локальной сети и реализации эксперименталь-
ной сетевой среды, обеспечивающей подключение к экспериментальным эле-
ментам лаборатории. Большинство рабочих станций используют тегирование
кадров для доступа к экспериментальным сетям, а другие (нетегированные)
назначаются операционной системой хоста в VLAN по умолчанию, которая
определяется как VLAN с VID 10 на коммутаторе доступа. Связность обес-
печивается так же в серверной части, но в отдельном VLAN с VID 20. Осо-
бый случай — распространение VLAN с VID 90, который используется ис-
ключительно для управления и выводится на коммутаторы доступа только
для реализации виртуального L3-интерфейса для управления данным эле-
ментом. Конечная станция или сервер никогда не будут подключены к этой
сети VLAN, но между устройствами будет доступна маршрутизация и L3
коммутация (виртуальный L3 интерфейс сетевых элементов). VLAN управ-
ления распространяется на все активные элементы сетевой инфраструктуры.
Для новой разработанной топологии я также ввожу новую номенклатуру в
соответствии с рисунком 3.1. Их имена соответствуют связям согласно ри-
сунку, которые могут быть могут быть разрешены с помощью DNS, как для
записей A, так и для PTR.




       Рисунок 3.1 — Новые имена для активных сетевых элементов

   Имена активных элементов выбираются в соответствии с заранее согла-
сованным соглашением, цель которого - облегчить управление устройствами
(например, для удаленного доступа с помощью эмулированного терминала).
Первая пара букв выбирается в соответствии с назначением устройства, т.е.
    - RB: RouterBoard - устройство является маршрутизатором.

  - SW: Switch - устройство является коммутатором.
   - FW: Firewall - устройство является фильтрующим элементом.
   - R2 или R3 указывает на расположение устройства в техническом поме-
     щении (номер стойки).
   - CORE: это устройство, образующее ядро сети.
   - SRV: это устройство серверного сегмента.
   - KLI: это устройство пользовательского сегмента.
   - LAB: это устройство, соединяющее экспериментальные элементы.


   3.1   Базовое подключение сетевых пользователей


   Как уже упоминалось, используемый коммутатор Cisco WS-3750X обла-
дает функцией коммутации L3 и будет использоваться в качестве основного
коммутатора в новой конструкции. В сетях меньшего масштаба, таких как
эта, это очень распространено для уровня распределения и ядра сети. Новая
топология представлена в соответствии с рисунком 3.2.




Рисунок 3.2 — Инфраструктура сети передачи данных без эксперименталь-
ных топологий

  На диаграмме сети передачи данных показана реализация фрагмента
пользователя и сервиса с использованием только двух коммутаторов. Затем
они подключаются к «центральному» коммутатору L3, на интерфейсе ко-
торого IP-пакеты маршрутизируются между отдельными VLAN. Такая схе-
ма подразумевает требование доступности суб-каналов к коммутатору в яд-
ре сети, поэтому они образуют агрегированный канал, который обеспечит
связь для фрагмента в случае отказа одной из пар, образующих логический
канал. Уровень доступа как для пользовательского, так и для сервисного
фрагмента состоит из двух соединенных между собой коммутаторов. Если
один коммутатор используется для рабочих станций, а другой - только для
серверных устройств, конфигурация обоих коммутаторов доступа значитель-
но упрощается. Кроме того, можно применять другой уровень безопасности
«глобально», то есть с областью действия, ко всем интерфейсам серверного
коммутатора, чем в случае коммутатора, используемого для подключения ра-
бочих станций, и серверов. Однако эта реализация предъявляет повышенные
требования к доступности серверной инфраструктуры в сети передачи дан-
ных. Если сегмент сервера недоступен для рабочих станций, рабочие станции
теряют доступ к службам домена DHCP, DNS и Active Directory. Недоступ-
ность этих служб не позволит всем пользователям рабочих станций работать,
поскольку учетные записи пользователей в базе данных AD не могут быть
аутентифицированы, если контроллер домена недоступен.
   По этой причине серверная VLAN с VID 20 также передается на коммута-
тор клиентского доступа с помощью магистрального интерфейса. Интерфейс
41 выделен на этом коммутаторе для подключения ADC, вторичного DNS-
сервера и вторичного DHCP-сервера. Это обеспечивает доступность основных
сетевых услуг и возможность использования рабочих станций, даже если все
устройства, включая сам коммутатор серверного сегмента будут отключены.
   Для каждой подсети на коммутаторе в ядре сети создается виртуальный
L3-интерфейс, которому назначается первый пригодный для использования
адрес данного сегмента, т.е. 10.10.10.1 из диапазона адресов 10.10.10.0/24.
Аналогичная схема адресации применяется к подсети, предназначенной для
серверных устройств, и подсети, предназначенной для управления сетевыми
элементами, т.е. IP-подсети в VLAN с VID 20 и 90. Кроме того, на коммута-

торе, который является ядром сети, создается дополнительный VLAN с VID
100, который передается только между коммутатором и пограничным марш-
рутизатором. В этом VLAN развернута IP-подсеть из диапазона 10.10.0.0/24
для обеспечения двухточечного соединения для передачи единиц данных к
маршрутизатору по умолчанию (пограничному). Это обеспечивает подклю-
чение к рабочей сети и Интернету для всех устройств в подсетях лаборатории,
кроме экспериментальных устройств или подсетей, определенных в экспери-
ментальных VLAN.


   3.1.1   Конфигурация коммутатора Cisco WS-3750X-48P


   Коммутатор Cisco WS-3750X-48P является элементом агрегации в сети
передачи данных для связи между VLAN с VID 10, 20 и 90. Устройство обра-
зует так называемое ядро сети и предлагает функцию коммутации L3, то есть
маршрутизации между VLAN, которые обычно определяются на коммутато-
рах доступа. Для каждой такой VLAN на коммутаторе создается виртуаль-
ный интерфейс L3 с первым допустимым адресом IP-подсети. Соединения с
обоими коммутаторами доступа формируются агрегированным каналом с ис-
пользованием двух физических каналов. Таким образом, максимальная тео-
ретически доступная пропускная способность равна C = 2 Гбит/с. Резервный
канал выбран здесь для обеспечения связи в случае отказа одного из каналов,
а не для обеспечения более высокой пропускной способности между частью
доступа и основной частью сети [13].
   Передача кадров между коммутаторами доступа и граничным маршрути-
затором происходит исключительно с использованием тегированных кадров.
Особенностью этой конфигурации является установка VLAN по умолчанию
для всех интерфейсов на несуществующую VLAN с VID 3 и предотвраще-
ние распространения VLAN с VID 1. Это предотвращает передачу кадров,
не принадлежащих заранее определенной сети VLAN. На этом коммутаторе
зарезервированы интерфейсы доступа VLAN с VID 90, где только админи-
стратор (интерфейсы не выведены на панель коммутатора, а выведены на
LAN-розетки на рабочих местах лаборатории) может подключать устройства,
предназначение которых — управление сетевой инфраструктурой. Как пра-

вило, это устройства KVM-переключателей, Power over Net, ИБП и другие.
Для этих устройств выбирается подключение к элементу сети, для которого
предполагается максимальная доступность — например, из-за потери связи
на коммутаторе SW-R2-SRV-01 удаленное управление серверами с помощью
KVM будет невозможно.
   Хотя на коммутаторе не настроены функции ARP Inspection, Port Security
и т.п., режим работы коммутатора можно охарактеризовать как работу с
повышенным уровнем безопасности для обеспечения согласованности топо-
логии сети передачи данных. Это соответствует развертыванию механизмов
защиты PortFast и BPDU Guard. Кроме того, ограничение на передачу кад-
ров, отправляемых на всенаправленный адрес с помощью функции Storm
Control, устанавливается на интерфейсе, формирующем логическое соеди-
нение с маршрутизаторами доступа. Эта функция для данного интерфейса
определяет уровень, связанный с доступной пропускной способностью ин-
терфейса, который может достигать определенного типа трафик в заданном
интервале. Интервал выбран длительностью в одну секунду, а уровень в слу-
чае всенаправленных сообщений выбран L = 0, 125. Для конфигурации на
интерфейсе, теоретическая максимальная пропускная способность которого
составляет 2 Гбит/с, конфигурация ограничивает пропускную способность
интерфейса порт-канал 10 до 250 Мбит/с для распространения кадров, от-
правляемых на всенаправленный адрес. Настройка Storm control на комму-
таторе показана в соответствии с рисунком 3.3.




                Рисунок 3.3 — Использование Storm control

   Для подсети клиентских устройств ограничивается связь рабочих стан-
ций с элементами сети VLAN с VID 90, т.е. IP-подсети 10.10.90.0/24, которая
предназначена только для управления и настройки этих устройств. В подсе-
ти 10.10.10.0/24 зарезервировано одно рабочее место (ПК администратора с
DHCP-резервированием), единственное, которому разрешен полный доступ
к указанной подсети. Используются расширенные списки контроля доступа

для фильтрации единиц данных и применяются их только во входящем на-
правлении на виртуальном интерфейсе для VLAN 10. Эта настройка показана
в соответствии с рисунком 3.4




  Рисунок 3.4 — Использование расширенных списков контроля доступа

   Сказанное выше обеспечит требуемую безопасность и отключит L3-
маршрутизацию коммутатором для всех рабочих станций данной подсети, за
исключением ПК администратора, где, наоборот, желательно наличие всех
элементов данной подсети. В дополнение к описанной выше конфигурации
будут добавлены все экспериментальные VLAN в выделенный транк на ин-
терфейсе между SW-R3-LAB-01 и SW-R2-LAB-01, чтобы обеспечить альтер-
нативный путь в сети передачи данных для распространения эксперимен-
тальных VLAN. Также настраиваются общие параметры, IP-адреса SNTP-
серверов, доступ по SNMP с правами на чтение и отправку сообщений SNMP
Trap на центральный элемент мониторинга.


   3.1.2   Конфигурация коммутатора DLINK 3120-48PC


   Коммутатор DLINK 3120-48PC, получивший соответствующее название
SW-R2-KLI-01, предлагает 48 интерфейсов, работающих на скорости до 1
Гбит/с, и 4 слота для модулей SFP+. Доступ к интерфейсу конфигурации
осуществляется через виртуальный интерфейс L3, адрес которому по умол-
чанию присваивается сервером DHCP. Конфигурирование коммутатора воз-
можно с помощью веб-интерфейса, протоколов Telnet и SSH для терминаль-
ного доступа, а также последовательного интерфейса RS-232. На коммутато-

ре имеется конфигурация, которая позволяет работать сети передачи данных,
описанной в разделе 2.1
    Новая модель сети передачи данных учитывает наличие виртуальных
VLAN с VID 10, 20 и 90. Первым шагом является настройка VLAN, пред-
назначенной для управления данным элементом, т. е. VLAN с VID 90, кото-
рая распространяется на транковый интерфейс, соединяющий вышестоящий
коммутатор в ядре сети. Это интерфейсы 1:47 и 1:48 (еще не назначенные на
канал LACP). Впоследствии эта VLAN назначается управляющей VLAN, по-
этому будет создан виртуальный интерфейс L3, которому затем можно будет
назначить IP-адрес из диапазона 10.10.90.0/24. Конфигурация VlAN управ-
ления представлен в соответствии с рисунком 3.5




         Рисунок 3.5 — Конфигурация VLAN 90 на коммутаторе

    Все сети VLAN создаются на коммутаторе аналогичным образом, но им не
назначается IP-адрес. Вышесказанное подразумевает, что интерфейс настро-
ен как магистральный, поскольку принимаются тегированные кадры. Пример
определения сети VLAN с VID 10 и интерфейсов доступа 1:01 - 1:42 показан
в соответствии с рисунком 3.6




         Рисунок 3.6 — Конфигурация VLAN 10 на коммутаторе

   Опять же, эта VLAN распространяется на магистральный интерфейс ро-
дительского коммутатора в ядре сети, в частности, используя порты 47 и
48.
    Интерфейс соединения между SW-R2-KLI-01 и SW-R3-LAB-01 затем кон-
фигурируется в соответствии с рисунком 3.7




 Рисунок 3.7 — Конфигурация соединения SW-R2-KLI-01 и SW-R3-LAB-01

   На этом этапе настраиваются отдельные интерфейсы коммутатора для
нужд расширения экспериментальных сетей VLAN и для доступа к сети
VLAN рабочих станций с использованием нетегированных кадров, т.е. VLAN
с VID 10. Разделение отдельных рабочих мест здесь реализуется путем на-
стройки конкретных сетей VLAN для который коммутатор доступа на дан-
ном интерфейсе принимает кадры с соответствующими тегами. Ниже при-
ведена конфигурация упомянутого логического канала, состоящего из двух
физических каналов с коммутатором в ядре сети. Для этого используются
интерфейсы 47 – 48 и следующая директива, в соответствии с рисунком 3.8




Рисунок 3.8 — Конфигурация логического канала, состоящего из двух физи-
ческих каналов

   Выше показано назначение портов 47 и 48 логическому каналу с иден-
тификатором 10. Хотя основной целью является обеспечение избыточности
между двумя коммутаторами, протокол LACP также определяет алгорит-
мы балансировки нагрузки между физическими каналами. Все интерфейсы
установлены в пассивный режим, агрегированный канал инициируется роди-
тельским коммутатором.
   Важной частью конфигурации является реализация механизмов безопас-
ности, описанных в главах 1.3.2 - 1.3.4, предотвращение ARP-спуфинга и
экранирование DHCP-сервера. Конфигурация представлена в соответствии с
рисунком 3.9




Рисунок 3.9 — Конфигурация защиты от APR-спуфинга и экранирования
DHCP-сервера

   Из приведенной выше конфигурации в случае функции проверки досто-
верности ARP устанавливается один MAC-адрес, который может содержать-
ся в блоках данных ARP-ответа при поиске MAC-адреса, соответствующего
IP-адресу шлюза по умолчанию в сети, в данном случае 10.10.10.1. Также
ввожу ограничения активных MAC-адресов на интерфейсах доступа, пред-
назначенных для рабочих станций, до максимально возможного количества
3 MAC-адресов, зарегистрированных на один порт, всего 40 MAC-адресов
для интерфейсов доступа для VLAN с VID 10 (по 1 MAC-адресу на каждый
интерфейс).
    Последней, но очень важной частью является настройка, которая пред-
ставлена в соответствии с рисунком 3.10, SNTP-клиента и набора информа-
ции, которая будет доступна с помощью SNMP OID и отправлена в централь-
ную систему мониторинга (сервер Zabbix, IP 10.10.20.20). Клиент SNTP ис-
пользует информацию о времени, полученную от обоих контроллеров домена.
Эта конфигурация очень полезна для отслеживания событий и их сравнения
с событиями на других элементах сети. Информация о синхронном времени
также очень важна для записи событий с отметками времени.




              Рисунок 3.10 — Конфигурация SNTP и SNMP


  Переходы, которые могут поставить под угрозу безопасность того или ино-
го элемента (определения учетных записей пользователей, методы аутенти-
фикации, методы доступа и т.д.), намеренно опущены. Кроме того, я намерен-
но оставил настройки SNMP-сообщества по умолчанию и оставил сообщество
по умолчанию под названием public в качестве сообщества с разрешением на
чтение значений. На практике это сообщество обычно не используется по со-
ображениям безопасности, и любой будущий администратор сети передачи
данных должен убедиться, что эта параметр изменен соответствующим об-
разом.


   3.1.3   Конфигурация коммутатора Zyxel XGS1910


   Как и в случае с коммутатором доступа SW-R2-KLI-01, в этом разделе
будет произведен анализ настройки коммутатора SW-R2-SRV-01, обеспечи-
вающего подключение серверного сегмента.
   Как упоминалось ранее, коммутатор серверного сегмента предназначен
только для подключения серверных устройств. По этой причине некоторые
конфигурации безопасности удалены. Основное предположение заключается
в том, что ни один пользователь не имеет физического доступа к интерфей-
су этого коммутатора. Здесь подключены серверы виртуализации, которые
обеспечивают связь со многими виртуальными станциями. Настройка огра-
ничения MAC-адресов на таком интерфейсе весьма контрпродуктивна (зна-
чения могут динамически меняться во время миграции трафика), эффектив-
ная работа механизмов ARP Inspection здесь ограничена в основном из-за
статически назначенных адресов [14].
   Коммутатор Zyxel XGS1910 имеет в общей сложности 48 портов стандарта
1000BASE-T и восемь отсеков для подключения модулей SFP+. Управление
устройством возможно только через веб-интерфейс или путем подключения
к физическому интерфейсу консоли. Так как большинство подключаемых
здесь устройств содержат несколько интерфейсов или сетевых карт, здесь во
многом настраивается агрегация физических линий, даже в случае подклю-
чения конечных устройств (серверов). Это обеспечивает как большую надеж-
ность соединения, так и лучшее распределение нагрузки между несколькими

соединениями. Для серверного сегмента характерна очень частая взаимная
связь серверов внутри локальной сети (VLAN 20). Примером такого взаимо-
действия является миграция виртуальных машин между хостами Hyper-V. В
основном это передача виртуальных жестких дисков, которые подключены
к отдельным серверам из общего сетевого хранилища или передача команд
SCSI по протоколу IP с использованием iSCSI.
   Базовая конфигурация снова включает создание всех VLAN и назначение
их в соответствии с портами. Далее создается виртуальный интерфейс L3 для
управления устройством, которому снова присваивается VLAN с VID 90 и
IP-адресом из соответствующего диапазона, оглашенного ранее. Далее, при
настройке общих параметров, всегда надо включать достоверную информа-
цию в поля Contact, Name и Location - эта информация передается в объектах
OID информационной базы по протоколу SNMP и облегчает идентификацию
и инвентаризацию. с помощью центрального элемента мониторинга.
   Существенным отличием в конфигурации по сравнению с SW-R2-KLI-01
является многократное подключение серверных устройств к нескольким ин-
терфейсам на одном коммутаторе. Серверы виртуализации имеют от 4 до 6
интерфейсов и, как правило, две сетевые карты. По этой причине целесо-
образно использовать агрегацию и выделять определенные VLAN, которые
могут распространяться по данному каналу. Для сервера, на котором рабо-
тают критически важные сетевые компоненты, настройка этих интерфейсов
позволит передавать кадры с VIDs 10 и 20.
   Поскольку этот коммутатор подключен, к устройству хранения Lenovo
px6-300, которое служит централизованным хранилищем для лабораторной
сети и общим хранилищем для кластера виртуализации, также были настро-
ены оба его интерфейса на агрегированный канал.
   Преимуществом такой конфигурации является, помимо прочего, удаление
всех экспериментальных сетей VLAN из конфигурации этого коммутатора.
Экспериментальные сети больше не будут передаваться между SW-R2-SRV-
01 и SW-R2-KLI-01, или магистральный интерфейс к серверу виртуализации
больше не будет подключен к этому коммутатору. Поэтому для них не под-
ходит продолжение передачи между этими элементами и использование про-



пускной способности соединения через многоадресную рассылку. Сети VLAN
всегда статически назначаются отдельным интерфейсам.


   3.2   Подключение экспериментальных сетей


   Описанная до сих пор топология не учитывает возможность подключения
других устройств, в основном экспериментальных сетевых элементов, конфи-
гурация которых обычно является предметом тестирования. Оригинальная
конструкция обеспечивает доступность экспериментальных устройств с по-
мощью коммутатора HP ProCurve 2650, на интерфейсе которого передаются
тегированные кадры экспериментальных сетей VLAN между коммутаторами
SW-R2-KLI-01, SWR2-SRV-01 и SW-R3-LAB-01. Из-за характера тестирова-
ния такая реализация очень неуместна. Используемый сервер виртуализации
предлагает достаточное количество интерфейсов, которые можно подклю-
чать по мере необходимости к коммутаторам доступа, чтобы обеспечить крат-
чайший сетевой путь между двумя напрямую взаимодействующими станци-
ями.
   К сожалению, на коммутаторе SW-R3-LAB-01 (модель HP ProCurve 2650)
доступны только два интерфейса 1000BASET. По этой причине один интер-
фейс будет предназначен для передачи тегированных кадров между комму-
татором SW-R2-KLI-01, соединяющим рабочие станции, а другой интерфейс -
для прямого подключения сервера виртуализации. С помощью тегированных
кадров кадры передаются между двумя коммутаторами, сопровождаемые со-
ответствующим тегом в соответствии с принадлежностью станции к заданию
тестирования. Соединение активных элементов и участвующих станций для
связи в соответствии с потребностями лабораторных заданий показано, в со-
ответствии с рисунком 3.11




Рисунок 3.11 — Связь между компонентами лабораторного задания тестиро-
вания

    На модифицированной диаграмме топологии показано подключение узла
виртуализации к коммутатору SW-R3-LAB-01. Основным преимуществом яв-
ляется значительное сокращение количества элементов, участвующих в рас-
пространении экспериментальных сетей VLAN. Вторым преимуществом яв-
ляется снижение потребности в связи по магистральному интерфейсу меж-
ду коммутатором, соединяющим рабочие станции и лабораторные элементы.
Однако недостатком этого относительно простого соединения снова является
существенное ограничение работы при выходе из строя одного из соединений
между элементами экспериментальной части и элементами рабочих мест обу-
чающихся. Риск полного отказа можно частично снизить, подключив допол-
нительный канал, который обеспечит доступность экспериментальных сетей
VLAN даже в случае отказа канала между SW-R3-LAB-01 и SW-R2-KLI-
01. Здесь распространение экспериментальных сетей VLAN настраивается от
клиентского коммутатора через базовый элемент (SW-R2-CORE-01) и затем
к коммутатору SW-R3-LAB-01. Это соединение обеспечит приемлемый уро-
вень резервирования и защиту от выхода из строя соединения между упомя-
нутыми коммутаторами, но резервная линия будет реализована только с со-
единением 100BASE-TX. Кроме того, необходимо будет обеспечить удаление
петель в сети с помощью протокола управления с использованием алгоритма
поиска каркаса графа.



  3.2.1   Конфигурация коммутатора HP ProCurve 2650


   Основным коммутатором в стойке для подключения экспериментальных
элементов является коммутатор HP ProCurve 2650 под названием SW-R3-
LAB-01. Это устройство обеспечивает связь между экспериментальными эле-
ментами лабораторных заданий и виртуализированными рабочими станци-
ями или виртуальными серверами. Хотя устройство предлагает до 50 пор-
тов, только два из них способны работать в режиме 1000BASE-T. Это суще-
ственное ограничение, особенно для реализации альтернативных маршрутов
экспериментальных топологий. Второй интерфейс зпредназначен для обес-
печения вышеупомянутой связности хоста виртуализации, т.е. для доступа
к экспериментальным сетям с использованием тегированных кадров для 10
виртуализированных серверов.
   Поэтому очевидно, что для связи виртуализированной станции на рабочих
станциях студентов с виртуальным сервером, работающим на хосте виртуа-
лизации, необходимо обеспечить доступность соответствующих сетей VLAN
на обоих портах коммутатора. Конфигурация конкретных сетей VLAN реа-
лизуется на основе анализа сетей VLAN, настроенных на сервере виртуализа-
ции, или их присвоение виртуальным станциям. Коммутатор SWR3-LAB-01
не предлагает функций сетевого уровня ни для одной из эксперименталь-
ных сетей, поэтому на его интерфейсе нет маршрутизации, фильтрации или
обеспечения качества обслуживания.
   VLAN с VID 90 также распространяется на коммутаторе на транк ин-
терфейсе, связанном коммутатором SW-R2-KLI-01, назначение которого за-
резервировано для управления сетевыми элементами. Кроме того, для этой
VLAN создается виртуальный IP-интерфейс с IP-адресом 10.10.90.5 из со-
ответствующего диапазона. Подключение к этому коммутатору возможно,
в частности, через консольный кабель или протокол Telnet для реализации
виртуального терминала.
   Конфигурация этого коммутатора была оставлена в очень неудовлетво-
рительном состоянии до внедрения нового лабораторного сетевого решения.
Самым большим недостатком является распространение самой VLAN, кото-
рая используется для управления (здесь использовалась тестовая VLAN 310

и выводилась на интерфейс доступа от коммутатора SW3 с помощью нете-
гированных кадров. По этой причине настраивается переопределение VLAN
с VID 90 и сопостовляется на интерфейс, соединяющий с коммутатором SW-
R2-KLI-01.
   В процессе настройки заполняется полностью отсутствующая общая ин-
формация об устройстве — то есть местоположение, информацию для связи
с администратором, и настраивается синхронизация данных о времени по
протоколу SNTP с двумя контроллерами домена. Так же настраивается воз-
можность сбора данных по протоколу SNMP и отправки SNMP "оповеще-
ния"(SNMPTraps) на сервер мониторинга с IP 10.10.20.20..


   3.2.2   Конфигурация коммутатора HP ProCurve 2626


   После перехода к новой концепции сети передачи данных коммутатор HP
2626 остался незадействованным. Его назначение заключалось в распростра-
нении обучающей сети VLAN на интерфейс коммутатора HP 2650 и - как
видно из прилагаемой конфигурации - некоторых экспериментальных. По-
скольку эти требования больше не присутствуют в новой структуре сети
данных, он конфигурируется для пробуждения расширения сети лаборато-
рии, т.е. для распространения VLAN с VIDs 10, 20 и 90. Его конфигурация
аналогична конфигурации клиентского коммутатора доступа, но функции
безопасности, характерные для коммутатора доступа SWR2-KLI-01, здесь не
активированы. Физически этот коммутатор расположен в стойке R3, где по
техническим причинам уже невозможно реализовать другое подключение к
стойке R2. Устройства, которые могут быть подключены к коммутаторам
SW-R2-KLI-01 и SW-R2-SRV-01 и которые не требуют использования интер-
фейса 1000BASE-T, могут быть подключены к 24 интерфейсам этого комму-
татора. Как правило, это беспроводные точки доступа или устройства Serial
over Net [15].
   Конфигурация осуществляется с помощью виртуального терминала, ре-
ализованного по протоколу Telnet. Задается базовая конфигурация - имя
устройства SW-R3-LAB-01, IP-адреса SNTP-серверов, конфигурацая для мо-
ниторинга с помощью SNMP и многое другое.

  3.3   Устранение петель с помощью MSTP


   Из конфигурации, описанной выше, очевидно внедрение топологии пет-
ли для обеспечения избыточности между блоками сети передачи данных. В
целом, надо разделять эту сеть на две отдельные части, каждая из которых
имеет различные требования к доступности топологии и производительности.
    - Производственная инфраструктура - часть, выделенная красным цве-
      том, т.е. сегмент сети передачи данных, обеспечивающий работу рабо-
      чих станций (DNS, DHCP, AD DC) с использованием базовых сетевых
      сервисов.
    - Экспериментальная инфраструктура - часть, выделенная зеленым цве-
      том, т.е. сегмент сети передачи данных, обеспечивающий реализацию
      экспериментальных топологий и обработку лабораторных заданий.
   Основываясь на этом факте, реализуется первое петлевое соединение меж-
ду коммутаторами SW-R2-CORE-01, SW-R2-KLI-01 и SWR2-SRV-01. Таким
образом, это две VLAN, которые удобно инстанцировать отдельно в рамках
протокола MSTP - в случае изменения топологии из-за сбоя эти VLAN будут
затронуты одинаково, поскольку они распространяются из основной сети на
одни и те же коммутаторы одновременно. Я назначаю эти VLAN первому эк-
земпляру протокола MSTP, т.е. MSTI 1. Экспериментальная инфраструктура
образует отдельную структуру, которая сосуществует с производственной ин-
фраструктурой и в некоторой степени зависит от нее (распространение VLAN
с VID 90). Распространение между элементами SW-R2-KLI-01, SWR3-LAB-01
и SW-R2-CORE-01 является специфическим для экспериментальных сетей.
Коммутатор в ядре сети намеренно выбран в качестве альтернативного эле-
мента из-за достаточной коммутационной способности и количества незаня-
тых портов. Для всех экспериментальных сетей, которые распространяются
между двумя основными коммутаторами (SW-R2-KLI-01 и SW-R2-LAB-01) и
резервным коммутатором в ядре сети, я выбираю другой экземпляр прото-
кола MSTP - MSTI 2. И здесь, в случае, если из-за недоступности основного
канала необходимо будет найти альтернативный каркас графа, все экспери-
ментальные сети VLAN должны будут распространяться через резервный
коммутатор.

   Петлевая топология двух частей инфраструктуры показана на диаграмме,
в соответствии с рисунком 3.12.




    Рисунок 3.12 — Петлевая топология двух частей инфраструктуры

    На диаграмме также показаны предпочтительные варианты корней дере-
вьев для обоих экземпляров. Для производственной инфраструктуры наибо-
лее подходящим выбором является коммутатор в ядре сети, особенно из-за
избыточных связей, скорости и характера распространения VLAN с VID 10
и 20. С другой стороны, для экспериментальных топологий рекомендуется
выбрать коммутатор SW-R3-LAB-01 в качестве корня дерева и обеспечить
предпочтительную связь по первичному каналу путем настройки приорите-
тов интерфейса по следующим причинам:
    - Связь между SW-R2-KLI-01 и SW-R3-LAB-01 представляет собой крат-
      чайший путь для распространения кадров в экспериментальных VLAN.
    - в будущем к SW-R3-LAB-01 могут быть подключены дополнительные
      коммутаторы для распространения экспериментальной инфраструкту-
      ры.
    - между SW-R3-LAB-01 и SW-R2-CORE-01 имеется канал связи
      100BASE-TX.
    Выбор корня дерева зависит, помимо прочего, от установленных приори-
тетов, и действительно, более низкое значение приоритета (обычно задается
кратным 4096) указывает на более подходящий коммутатор для корня дере-
ва. В случае предоставления роли корня для коммутатора SW-R2-CORE-01


в режиме конфигурирования MSTI используется значение приоритета 8192.
Настройка выбора корня показана в соответствии с рисунком 3.13.




                   Рисунок 3.13 — Выбор корня MSTI

   Кроме того, намеренно снижается приоритет выбора для интерфейса, ре-
ализующего резервный канал между SW-R2-SRV-01 и SW-R2-KLI-01, чтобы
для подключения к родительскому коммутатору был выбран агрегированный
канал. При тестировании сценария обрыва основного канала между SW-R2-
CORE-01 и коммутатором доступа серверного или пользовательского сегмен-
та время восстановления канала, т.е. скорость сходимости протокола MSTP
для экземпляра 1 MSTI, было измерено в диапазоне 1 - 3 секунд. Пользова-
тель не заметит обрыва такого соединения при обычной работе.
   Таким же образом обеспечивается подходящий выбор корня для второго
экземпляра протокола MSTP, что обеспечивает устранение петли в случае
экспериментальных сетей VLAN. Опять же, было выбрано значение 8192,
чтобы установить приоритет на коммутаторе SW-R3-LAB-01 и адекватный
приоритет предпочтительного интерфейса. Коммутаторы SWR2-CORE-01 и
SW-R2-KLI-01 для MSTI 2 должны иметь более низкий приоритет, чтобы
предотвратить их нежелательный выбор в качестве корня дерева. Намерен-
но оставлена виртуальная сеть с VID 90 как часть экземпляра MSTI 0 по
умолчанию.
   Выбор корня для данного экземпляра не очень важен, большая часть тра-
фика данных, передаваемого в этой VLAN, состоит только из блоков данных
протокола SNMP, либо данных протоколов Telnet и SSH при подключении
к интерфейсу конфигурации сетевых элементов. Исключением может быть
работа с KVM, однако здесь предполагается, что административные опера-
ции выполняются удаленно подключенным администратором только в случае
необходимости, как правило, с использованием VPN. Эти пакеты никогда не
распространяются за пределы основного коммутатора сети и пограничного

маршрутизатора. Устройства управления подключаются к портам коммута-
тора в ядре сети. Выбор соответствующего корня дерева существенно не по-
влияет на необходимость обеспечения доступности устройств в IP-подсети
10.10.90.0/24.




  4     Серверная инфраструктура

    Основным элементом новой инфраструктуры серверного сегмента являет-
ся коммутатор Zyxel XGS1910, который обеспечивает сетевой доступ ко всем
физическим и виртуальным серверам. Это коммутатор, назначение которого
намеренно зарезервировано только для подключения серверных устройств,
взаимодействующих в недавно созданной виртуальной локальной сети с VID
20. Такая реализация выбрана с учетом повышенных требований к передаче
данных между серверами (например, резервное копирование на общее храни-
лище, использование общего хранилища кластером виртуализации). В опре-
деленной таким образом серверной подсети работают, в частности, следую-
щие серверы:
    - Два узла кластера виртуализации.
    - Физический контроллер домена, DHCP и первичный DNS-сервер.
    - Общее хранилище.
    - Неиспользуемый сервер.
Поскольку службы и серверные системы Microsoft Windows Server в значи-
тельной степени были развернуты в старой версии 2008 R2, обновление (пе-
реход) на более свежую версию Windows Server происходит с переходом к но-
вой концепции. Основная цель - более эффективное распределение серверных
служб между доступными серверами и обеспечение устойчивости к отказам
серверов, предоставляющих основные услуги, характерные для корпоратив-
ных сетей. По этой причине я использую два сервера для формирования
кластера виртуализации, который включает в себя резервный контроллер
домена и выделенную станцию для управления сетевой инфраструктурой.
Два узла кластера виртуализации обеспечивают High Availability для вир-
туального сервера, который способен запускать службы AD, DNS и DHCP.
Все виртуальные станции для выполнения тестовыъ заданий обеспечиваются
только одним узлом, и эти виртуальные машины не резервируются HA.


   4.1    Хранилище данных


   В лаборатории имеется запоминающее устройство с подключением к се-
ти передачи данных. Это LenovoEMC™PX6-300d. Данное устройство имеет

шесть внутренних отсеков для жестких дисков с интерфейсом SATA 6 Гбит/с
и разъемы USB3.0 для подключения внешних устройств. Жесткие диски мо-
гут быть настроены для использования в дисковых массивах RAID 0, 1 и
5. Устройство также оснащено двумя сетевыми интерфейсами, которые под-
держивают максимальную скорость до 1 Гбит/с и могут быть объединены в
логический канал. Для лучшего доступа к устройству и его легкой иденти-
фикации в доменной структуре устройству присваивается имя SC5-32-NAS01
с IP-адресом 10.10.20.3 из диапазона 10.10.20.0/24. Кроме того, устройство
хранения включено в доменную структуру Active Directory.
    В настоящее время в накопителе установлено четыре жестких диска
Western Digital WD20EFRX емкостью 2 ТБ. Это жесткие диски, предна-
значенные производителем для использования в устройствах хранения для
«домашнего» использования, а не в устройствах, где в приоритете высокая
производительность и быстродействие. На этом устройстве все диски назна-
чены на массив RAID 5. По своему предложению я реструктуризирую диско-
вый массив, где всего 4 диска разбиты на пары по 2 жестких диска. Каждая
пара образует массив RAID 1. Такое расположение основано на требовани-
ях отдельных приложений к дисковой подсистеме. Каждый дисковый массив
образует пространство для хранения, общая емкость которого определяется
по уравнению CRAID1 = n/2, где n — сумма емкостей всех жестких дисков в
дисковом массиве RAID 1. Конфигурация этих массивов тогда соответствует
рисунку 4.1.




Рисунок 4.1 — Расположение жестких дисков в устройстве хранения данных

    Включение дисков в нечетные и четные положения двух массивов дис-
ков приводит к снижению вибраций и излучаемого тепла за счет активности
дисков. Дисковое пространство с пометкой drive_pool_1-3 в дальнейшем ис-
пользуется для создания томов, которые подключаются по протоколу iSCSI
в качестве хранилища для виртуальных машин. Таким образом, можно пред-
положить, что эти диски будут использоваться постоянно, а диски с ID 2 и 4,

составляющие дисковое пространство с меткой dirve_pool_2-4, составляют
пространство для создания общих папок. Здесь можно предположить более
частую остановку жестких дисков, потому что диски в этом поле крутят-
ся только в случае доступа к общему диску, который предлагает дисковое
пространство.
    Каждое дисковое пространство предлагает в общей сложности 1 802
Тб дискового пространства. Его распределение будет подчинено буду-
щим потребностям. Для создания кластера виртуализации в пространстве
drive_pool_1-3 я создаю новый том iscsi-5-cluster емкостью 300 ГБ, который
может быть смонтирован по протоколу iSCSI и будет использоваться в каче-
стве общего хранилища всеми узлами кластера. Этому тому автоматически
присваивается идентификатор IQN iqn.2012.07.com.lenovoemc:storage.SC5-32-
NAS01.iscsi-5-cluster.


   4.1.1   Подключение к тому с помощью iSCSI


   Идентификатор IQN может использоваться для уникальной идентифика-
ции тома устройства хранения, который должен быть подключен с помощью
протокола iSCSI на конечной станции или сервере. Для этого используется
инструмент iSCSIInitiator, доступный в ОС Windows, который применяется
на обоих узлах кластера. Этим инструментом также можно управлять из
интерфейса интерпретатора Windows Powershell. Первым шагом на целевом
сервере является запуск службы iSCSI, которая, помимо прочего, обеспечи-
вает автоматическое подключение к тому на сетевом хранилище даже после
перезагрузки ОС.
   Следующим шагом будет нахождение iSCSI Target Portal - сервера, кото-
рый является посредником при подключении к дисковым накопителям, назы-
ваемым iSCSI Targets. Конкретные дисковые накопители идентифицируются
строкой IQN, также называемой NodeAddress [16]. Подключение к тому, со-
зданному в предыдущей главе, показано в соответствии с рисунком 4.2.




                Рисунок 4.2 — Подключение ISCSI тома

   Доступ к дисковым томам может контролироваться RADIUS-сервером,
инициатор и целевой сервер могут быть аутентифицированы, а сама пере-
дача команд может быть защищена с помощью протокола IPSec. Однако в
работе это не используется. Запись MBR, разделы диска и их файловые си-
стемы теперь можно создавать на подключенном таким образом виртуальном
диске. Для реализации кластерного общего хранилища (т.н. Cluster Shared
Storage) с помощью базовых средств я создаю новый раздел диска с буквой
R и файловой системой NTFS. Созданный часами раздел теперь доступен для
хранения данных внутри ОС. Чтобы иметь возможность воспроизвести эту
процедуру и на втором узле кластера, необходимо отключить подключенный
диск на первом узле (перевести его в автономный режим). Том iSCSI может
оставаться подключенным, но раздел не должен быть активен на нескольких
узлах.


   4.2   Инфраструктура виртуализации


   Для сохранения привычек и легкой интеграции в существующую среду
инфраструктура лаборатории будет расширена за счет совершенно нового
узла кластера виртуализации, реализованного с помощью Hyper-V. В каче-
стве операционной системы хоста выбрана ОС Microsoft Windows Server 2016
Datacenter. Одним из критериев выбора здесь является требование просто-
го управления платформой виртуализации и бесшовной интеграции в суще-
ствующую среду, которая использует доменные службы Active Directory от
Microsoft.
   Обновление операционной системы серверов виртуализации приносит зна-
чительные преимущества, наиболее важными из которых являются новые
режимы динамической памяти ВМ, новые сетевые службы ВМ (QoS, раз-

мещение общих дисков) и, наконец, возможность управления виртуальной
машиной из Windows Powershell.
   С переходом на новую версию гипервизора появилась возможность более
эффективно распределять ресурсы физического хоста между виртуальными
станциями. Это достигается, в частности, за счет более продвинутой инте-
грации между родительскими и дочерними разделами и возможности дина-
мического выделения ресурсов для данной виртуальной станции "на лету".
Полная виртуализация серверной инфраструктуры неизбежно влечет за со-
бой критический момент - надежную работу физического узла. Требования
к его постоянной доступности возрастают с увеличением количества работа-
ющих на нем виртуальных машин, роль которых в сети незаменима. В то
время как функции контроллера домена и DNS-сервера могут быть обеспе-
чены ADC в случае отказа одного из хостов, серверы, не являющиеся частью
распределенной среды, могут быть защищены только функцией резервного
копирования кластера. Этот механизм также может обеспечить безопасность
других служб или серверов, таких как файловый сервер, SQL-сервер и многие
другие.
   Преимуществом кластера виртуализации является не только возможность
миграции виртуальных машин между отдельными хостами кластера, но и
запуск их на другом хосте в случае сбоя сервера виртуализации, на кото-
ром была запущена виртуальная машина. В зависимости от сложности ме-
ханизма резервного копирования можно говорить о резервном копировании
без необходимости перезапуска машины или о резервном копировании путем
запуска на другом хосте. В случае резервного копирования без перезапус-
ка виртуальная машина запускается одновременно на двух или более хостах
кластера, содержимое их оперативной памяти синхронизируется и в случае
сбоя сервера, на котором в данный момент активна ВМ, подключение к "ре-
зервной"виртуальной машине восстанавливается путем автоматической ре-
конфигурации сетевой подсистемы.
   Более эффективным использованием ресурсов лаборатории является за-
пуск кластера с резервным копированием виртуальных машин с возможным
перезапуском на другом хосте. Такое решение является подходящим компро-
миссом для обеспечения высокой доступности виртуальных машин и эффек-

тивного использования вычислительных мощностей отдельных хостов. Дан-
ный метод также выбран с учетом особенностей виртуализированной инфра-
структуры - некоторые виртуальные серверы являются частью распределен-
ной архитектуры (контроллеры Active Directory, DNS-серверы), что обеспе-
чивает функциональность в случае отказа одного из серверов на уровне при-
ложений или ролей ОС.
   Важным компонентом кластера виртуализации является общее хранили-
ще, не только для обеспечения доступности виртуальных машин и их конфи-
гураций, но и для операций управления записью и чтением, которые исполь-
зуются для поддержания координации между членами кластера. Функцио-
нальная схема кластера виртуализации с внешним разделяемым хранилищем
показана, в соответствии с рисунком 4.3.




Рисунок 4.3 — Запуск виртуальных машин HA в инфраструктуре виртуали-
зации

   Если данная виртуальная машина настроена для работы на альтернатив-
ном хосте, эта машина обозначается как Highly Available VM.
   Схема показывает, что не все виртуальные машины должны быть запу-
щены в кластере. Более того, необходимо учитывать резервирование вычис-
лительных мощностей для машин, которые придется перезапускать на аль-

тернативном хосте в случае отказа одного из членов кластера.Для решения
этой проблемы на практике вводится резервирование и приоритеты для от-
дельных ВМ, чтобы в случае отказа инфраструктура могла продолжать ра-
ботать, даже если хост не имеет ресурсов для запуска ВМ.Этот механизм дол-
жен обеспечивать как минимум один контроллер домена, один DNS-сервер
и DHCP-сервер. Однако в лабораторной сети имеется выделенный физиче-
ский сервер, предоставляющий идентичные услуги, поэтому резервирование
ресурсов не используется.


   4.3   Работа AD, DNS и DHCP с высокой доступностью


   С переходом на новую концепцию сети передачи данных и разделением
ролей, установленных на доступных серверах, исчезла и роль альтернативно-
го контроллера домена, который неоптимально функционировал на сервере
виртуализации (не в ВМ). Поскольку в рамках защиты доменной структуры
рекомендуется запускать как минимум два синхронизированных контроллера
домена с функцией глобального каталога, устанавливается новая виртуаль-
ная машина SC5-32-DC03v с работающим датацентром MS Windows Server
2016. система. Далее виртуальная машина помещается в расположение смон-
тированного тома CSV и добавляется в качестве роли кластера после уста-
новки [17].
   Первичным узлом является сервер SC5-32-HPV01, но в процессе мигра-
ции и в случае отказа возможно перемещение ВМ на второй узел виртуа-
лизации. Предполагается, что в случае отказа физического контроллера до-
мена можно будет продолжать использовать службы Active Directory, DNS и
DHCP-сервера - эти службы при необходимости будут предоставляться вновь
установленным виртуальным сервером.
   При добавлении роли контроллера домена автоматически устанавливает-
ся DNS-сервер. Зоны этого DNS-сервера интегрируются в базу данных Active
Directory и ее данные в том числе. Записи DNS автоматически реплицируются
и синхронизируются с другими контроллерами домена с заданным интерва-
лом в 15 минут.


  Во время перехода на новую концепцию сети передачи данных этот кон-
троллер домена также является единственным DHCP-сервером в лаборатор-
ной сети. Он обслуживает определенные диапазоны адресов для VLAN 10,
20 и 90. Для VLAN 20 и 90 существует диапазон с заведомо ограниченным
количеством - адреса из этих диапазонов обычно назначаются статически,
а динамическая конфигурация существует только для облегчения перехода
от исходной сети передачи данных к новой концепции. Это обеспечивает ад-
ресацию и доступ к сетевому оборудованию, которое еще не было должным
образом переконфигурировано. Кроме того, существует определенный диапа-
зон IP-адресов для выделения клиентам из VLAN 12, который зарезервиро-
ван для пользователей беспроводных точек доступа в лаборатории. Запросы
DHCP направляются на сервер DHCP агентом DHCP Relay, который настро-
ен на коммутаторе в ядре сети, за исключением VLAN 12 и 20.
   Настройка обоих серверов DHCP требует, чтобы одинаковые адресные
пространства были добавлены и настроены идентично - например, резерви-
рование адресов, исключения диапазонов и многое другое. Процесс настрой-
ки «резервирования трафика» сервера DHCP гарантирует, что оба сервера
DHCP установят партнерство и определят процент каждого диапазона, об-
служиваемого сервером DHCP. Это партнерство может работать в режимах
HotStandby и Load Balancing. Создание нового партнерства для серверов с
именами SC5-32-DC03v и MERCURY можно выполнить с помощью команд-
летов, представленных в соответствии с рисунком 4.4




          Рисунок 4.4 — Создание партнерства DHCP серверов

   Работа пары заключается в контролируемом обслуживании запроса кли-
ента на основе значения его MAC-адреса. Он вычисляется специальной функ-
цией хэширования, выход которой принимает значения от 1 до 256. Если
коэффициент разделения установлен на 50%, то первый сервер отвечает на
запросы клиентов со значениями хэша от 1 до 128, второй - со значениями
хэша от 129 до 256. Доступные для аренды адреса в адресном пространстве

также делятся поровну между двумя DHCP-серверами. Если из-за выходных
значений хэш-функции одна половина диапазона используется с большей ско-
ростью, чем другая, каждые 5 минут доступные адреса выделяются в новое
подпространство, которое перераспределяется между партнерскими DHCP-
серверами. Если один из серверов выходит из строя, сервер-аналог берет на
себя распределение заимствований, независимо от хэш-функции для MAC-
адреса клиента.
   После правильной конфигурации обоих серверов DHCP необходимо со-
ответствующим образом настроить параметры устройства, реализующего
функцию DHCP Relay. Эти устройства могут пересылать запросы соответ-
ствующим образом на омниканальный адрес в IP-подсети, где расположе-
ны DHCP-серверы. расположены. В качестве альтернативы можно указать
только адреса этих DHCP-серверов. В новой сети передачи данных исполь-
зуем целевую переадресацию на IP-адреса серверов DHCP. Эта настройка
выполняется на виртуальном интерфейсе L3 коммутатора в ядре сети, для
виртуальных локальных сетей с VID 10, 20 и 90.




  5     Система мониторинга и резервное коипрование

   Последняя часть работы связана с проектированием и реализацией систе-
мы мониторинга в сети передачи данных лаборатории. Кроме того, имеются
варианты резервного копирования конфигураций сетевых элементов, немед-
ленная доступность которых позволит администратору отслеживать измене-
ния и даст более четкую ориентацию в их настройках. Вместе с возможностью
наблюдения за текущим состоянием оборудования лаборатории это являет-
ся очень полезным источником информации, и не только в случае решения
ошибочных ситуаций.


   5.1    Мониторинг с помощью Zabbix


   Система Zabbix доступна для загрузки для наиболее часто используемых
дистрибутивов ОС ядра Linux. Развертывание системы возможно путем за-
грузки и импорта так называемого Appliance, т.е. виртуального диска с за-
ранее подготовленной установкой ОС Zabbix и ПО. Затем создание ВМ про-
исходит таким же образом (это не ВМ с высокой доступностью), но вместо
создания нового виртуального диска подключается уже загруженный и из-
влеченный жесткий диск с установленной ОС Linux и полностью установлен-
ным Zabbix система версии 6.4 [18].
   Zabbix выбран в данной работе в основном из-за простоты администриро-
вания и использования системы. Целью развертывания системы мониторинга
является возможность мониторинга основной оперативной информации (до-
ступность, использование, применение физических ресурсов), инвентариза-
ции и, возможно, предоставление основных методик для локализации воз-
можных проблем.
   Виртуальную машину, обеспечивающую работу системы мониторинга, за-
пускается на сервере виртуализации SC5-32-HPV01. Для этой ВМ намеренно
не используется функция кластерного резервного копирования (однако мож-
но выборочно инициировать перемещение между хостами). Рассматриваемая
ВМ использует агрегированный физический канал и подключена к серверной
VLAN 20.


  5.1.1   Мониторинг с помощью SNMP и агента Zabbix


    Система Zabbix предлагает несколько способов мониторинга и сбора дан-
ных с целевого устройства. Первым широко распространенным является сбор
и передача данных с помощью протокола SNMP. Этот метод особенно под-
ходит для активных сетевых элементов (коммутаторов и маршрутизаторов).
Информация о сетевом элементе передается через так называемый SNMP-
агент, который генерирует SNMP-сообщения и отправляет их на заранее на-
строенный адрес элемента мониторинга [19].
    Чтобы добавить целевой элемент, предоставляется его описательное имя
и указывается коммуникационный интерфейс. Интерфейс всегда указывает,
по крайней мере, IP-адрес или DNS-запись для элемента. Если сбор данных
осуществляется с помощью протокола SNMP, то добавляется так называемый
интерфейс SNMP, если с помощью агента Zabbix, то добавляется соответству-
ющая информацая в поле Agent Interface. Для наглядности рекомендуется
классифицировать добавленные элементы в зависимости от типа устройства
в соответствующие группы.
    Далее назначается шаблон конфигурации для каждого устройства, кото-
рый содержит определения служб и параметров, которые отслеживаются на
устройстве. В случае устройств, использующих SNMP, это обычно таблица,
определяющая OID, значения и их интерпретацию. В этом шаблоне также
указываются так называемые триггеры событий, которыми могут быть, на-
пример, предельный уровень загрузки линии или использования оперативной
памяти и т.д.
    Предварительно подготовленные шаблоны могут быть далее объединены
в цепочку. Шаблон также может определять использование системного при-
ложения для выполнения действия и последующую интерпретацию этих ре-
зультатов. Примером такого шаблона является проверка доступности с помо-
щью системного инструмента ping. Шаблоны могут быть созданы произволь-
но, им может быть назначено действие и метод интерпретации результатов.
Кроме того, может быть определено место обработки, например, проверка
обновлений на контролируемой машине.


  Обычно всегда назначаются шаблоны SNMP Device и ICMP Ping для
устройств, настроенных в данной работе. Это обеспечивает проверку доступ-
ности устройства, а также мониторинг состояния устройства (общая инфор-
мация - имя, контакт администратора, местоположение) и текущего исполь-
зования. Однако экспериментальным путем было проверено, что значение,
опосредованное SNMPagent, показывает разброс значений в диапазоне от 10
до 15 процентов. Таким образом, информация на линии нагрузки может рас-
сматриваться только как ориентировочная.
   Альтернативой мониторингу с помощью агента SNMP является использо-
вание программного клиента Zabbix Agent, который устанавливается на опе-
рационную систему контролируемой станции. Хотя компьютеры под управ-
лением ОС Linux или Windows также можно контролировать с помощью
SNMP, использование программного клиента является более гибким. Для мо-
ниторинга базовой информации о состоянии конечных станций я намеренно
оставляю настройки в состоянии по умолчанию. Программный клиент дол-
жен быть установлен в качестве службы на компьютере под управлением
Windows, автоматически запущен и включен на TCP-порту 10050. Файл кон-
фигурации агента для всех настроенных устройств доступен в приложении.
Программный клиент установлен на всех серверах с ОС Windows Server. Раз-
вертывание агента на рабочих станциях не реализовано, но может быть эф-
фективно выполнено путем установки объектов групповой политики.


   5.2   Резервное копирование конфигураций сетевых элементов


   Большинство операционных систем, развернутых сегодня на сетевых эле-
ментах, также реализуют методы резервного копирования и передачи файлов
конфигурации с помощью TFTP, FTP и т.д. Резервное копирование и пере-
дача конфигураций с помощью установленного клиента TFTP по-прежнему
является предпочтительным выбором, даже с учетом уступающих функций
безопасности TFTP, в основном из-за его простоты. Сетевые элементы, ко-
торые предлагают графический интерфейс, обычно предлагают возможность
загрузки или восстановления конфигурации с помощью HTTP-передачи. Од-
нако недостатком сохранения конфигураций из среды веб-браузера являет-

ся меньшая возможность автоматизации этой задачи. В следующих разде-
лах описан принцип автоматического резервного копирования конфигураций
коммутатора с использованием как терминального доступа, так и отправки
специальных запросов с использованием протокола HTTP [20].
   Для работы с резервными копиями я использую виртуализированную ра-
бочую станцию SC5-32-MNG01v и виртуальный сервер SC5-32-SRV01vx. Вы-
шеупомянутый сервер с ОС Linux в дистрибутиве Ubuntu 22.04 выполняет
функцию TFTP-сервера, где хранятся резервные копии конфигурационных
файлов, а также служит интерпретатором языка сценариев Expect. В целях
безопасности, используя программу iptables, я добавляю в ОС конфигурацию
пакетного фильтра, который предотвращает получение датаграмм TFTP из
всех IP-подсетей, кроме IP-подсети, используемой для администрирования,
подсети сервера и станции с IP 10.10.10.50 (ПК администратора). Использо-
вание iptables показано в соответствии с рисунком 5.1.




                  Рисунок 5.1 — Использование iptables


   5.2.1 Автоматическое резервное копирование с помощью вир-
   туального терминала


   Хотя некоторые новые операционные системы сетевых устройств предла-
гают возможность планирования и автоматического запуска заданий резерв-
ного копирования, более старые операционные системы предлагают только
загрузку конфигурации по инициативе администратора. Метод, описанный
в этой главе, использует преимущества автоматизации взаимодействия с се-
тевым элементом. Для этого используется интерпретатор языка сценариев
Expect, который предназначен для взаимодействия с компьютерной систе-
мой. Запуск сценариев резервного копирования на сервере SC5-32-SRV01vx



настроен на повторное выполнение в 14:30 каждый день с помощью програм-
мы Cron.
    Рассмотрим последовательность задач, которая приводит к успешной за-
грузке файла конфигурации на сервер TFTP из резервной копии элемен-
та. Терминальный доступ почти всегда требует аутентификации. Эта аутен-
тификация может быть выполнена, например, путем ввода пароля для ис-
пользуемой учетной записи или аутентификации с помощью пары закры-
тый/открытый ключ. Для простоты и ясности я использую метод аутенти-
фикации с помощью пароля. После входа в устройство требуется переход в
привилегированный режим. Затем пользователь получает право читать теку-
щие конфигурации (часто называемые running-config или startup-config). За-
тем они могут быть загружены с помощью упомянутого выше TFTP-клиента.
Когда процесс резервного копирования завершен, администратор выходит
из системы и разрывает соединение. Для автоматизации этого процесса на
устройствах Cisco IOS используется следующая последовательность команд,
показанная в соответствии с рисунком 5.2




      Рисунок 5.2 — Загрузка файла конфигурации на сервер TFTP



  Администратор запрашивает пароль в общей сложности два раза с мо-
мента установления соединения. После входа в привилегированный режим
делается запрос на отправку конфигурации. Далее подтверждается место на-
значения резервного копирования (IP-адрес или имя TFTP-сервера) и ука-
зывается имя файла, в который будет записана конфигурация. Затем сле-
дует подтверждение передачи и выход из устройства. Эти действия могут
быть полностью автоматизированы с помощью скриптов, интерпретируемых
библиотекой Expect. Сам скрипт запроса представлен соответствии с рисун-
ком 5.3




            Рисунок 5.3 — Скрипт отправки конфигурации

   Используемая методология очевидна из содержания сценария. На первом
этапе определяются значения переменных, в которых хранится информация
об учетной записи пользователя. Затем устанавливается сеанс связи по про-
токолу Telnet. Интерпретатор языка Expect считывает строку символов, от-
правленную контрагентом, и посылает команды элементу для выполнения

в соответствии с введенными данными. Эти команды форматируются как
одиночные символы, где конец строки, т.е. выполнение команды, соответ-
ствует «отправке» клавиши Enter. Намеренно включается в скрипт задерж-
ки (в данном случае 1 секунда), чтобы обеспечить достаточное время для
ответа контрагента. Целесообразно вставлять искусственные задержки после
команды отправки пароля, так как аутентификация может осуществляться
с помощью проверки подлинности сервером в сети, время ответа которого
может достигать единиц или десятков миллисекунд. Затем выполняется от-
правка на сервер с именем SC5-32-SRV01vx, подтверждается место назначе-
ния и имя файла, и сеанс завершается отправкой команды выхода из системы
по окончании отправки. Принцип резервного копирования других элементов
сети аналогичен. Для каждого элемента последовательность отправляемых
команд должна быть адаптирована в соответствии со строками, отправляе-
мыми контрагентом.




                          ЗАКЛЮЧЕНИЕ
    Дипломная работа посвящена разработке и описанию реализации совер-
шенно новой сети передачи данных, которая реализуется в одной из лабо-
раторий организации. В этой сети упор сделан на надежность и эффектив-
ное использование сети передачи данных для нужд преподавания предметов
с упором на изучение передовых сетевых технологий. Работа начинается с
теоретического анализа практик, которые обычно используются сегодня при
создании сетей передачи данных, и оцениваются возможности их внедрения
и реализации в сети передачи данных лаборатории.
    При проектировании новой сети передачи данных идет опора в первую
очередь на знания пользователя, а затем на знания администратора суще-
ствующей инфраструктуры. Этот анализ кратко обсуждается в главе 2. При
проектировании идет концентрация в основном на недостатки исходной ин-
фраструктуры, к которым относится снижение безопасности, структуру сети
передачи данных и ее недостаточную связность. Эти выводы заставляют за-
ново оценить возможности управления такой сетью, надзора за самими эле-
ментами и оценки эффективности использования оборудования лаборатории.
    По этой причине в значительной степени внедряется виртуализация сер-
веров и переход к многоуровневой модели сети передачи данных в сетевой
инфраструктуре. Целью этой реструктуризации является более эффективное
использование как той части, которая составляет серверную инфраструкту-
ру, так и той, которая обеспечивает доступ к сети для конечных станций и
их пользователей. Поскольку лабораторная сеть используется для проведе-
ния большого объема разнообразных тестов, то следует попытка защитить
инфраструктуру этой сети соответствующим образом, внедряя более совре-
менные методы безопасности, особенно в пользовательском фрагменте.
    К сожалению, в первоначальной сети данных не были учтены требования
к ее надежности, то есть к комплексу технических мер, ведущих к устранению
любых возникающих условий ошибки. По этой причине идет пыпытка разде-
лить сеть данных на экспериментальную и производственную части, исполь-
зуя различные методы для обеспечения надежности обеих частей сети. Они
включают в себя развертывание резервных связей между ключевыми устрой-
ствами и создание альтернативных топологий для обеспечения, хотя и ценой

снижения пропускной способности части сети, доступность всех устройств в
сети передачи данных.
   В последней части представляется система мониторинга состояния эле-
ментов сети и самих конечных устройств. Выбор этой системы идет в свя-
зи с ее простотой с точки зрения как пользователя, так и администратора.
Это обеспечивает мониторинг инфраструктуры в пределах лаборатории. На
последнем этапе идет работа с обеспечением резервного копирования конфи-
гураций всех элементов, составляющих функциональную единицу как про-
изводственной инфраструктуры, так и экспериментальных элементов. На ос-
новании тестирования (особенно надежности и безопасности) можно считать
новую сетевую структуру функциональной и надежной.


